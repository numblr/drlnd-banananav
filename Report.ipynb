{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we summarize the implementation details and training results of the agent implemented in this repository.\n",
    "\n",
    "For the ease of readability we start with an overview over the implemented algorithm in the first section, and continue with a detailed walk trhough the implementation in the [Implementation](#1.-Implementation) section.\n",
    "\n",
    "## 1. Algorithm and Results\n",
    "\n",
    "To learn the Q-function that is used in the BananaAgent to select actions, two variants of the [Q-learning](https://en.wikipedia.org/wiki/Q-learning)) algorithm with a deep neural network (DNN) based function approximator are implemented:\n",
    "\n",
    "- Q-learning with a DNN as approximator  for the Q-function using experience replay ([DQN](https://www.nature.com/articles/nature14236))\n",
    "- Double Q-learning with a DNN as approximator using experience replay ([DDQN](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12389/11847)).\n",
    "\n",
    "### Network architectures\n",
    "\n",
    "Two different architectures of DNNs as function approximators were examined:\n",
    "\n",
    "- a *simple* variant with two hidden layers of 64 units each:\n",
    "![Simple DNN](resources/simple_dnn.png)\n",
    "- a more advanced architecture that is extended with two additional hidden layers with 16 and 8 units at the input side of the DNN. This two layers are intended to work similar to the encoder part of an [autoencoder](https://en.wikipedia.org/wiki/Autoencoder) architecture and extract features from the raw state:\n",
    "![AutoEnc DNN](resources/autoenc_dnn.png)\n",
    "\n",
    "### Hyperparameter choices\n",
    "\n",
    "For Q-Learning algorithm a discount rate close to one (0.99) was chosen, as it is expected that an action of the agent will result in a reward only after several future steps. As expected, the choice of low discount rates resulted in a notable decrease of performance.\n",
    "The size of the memory for experience replay was choosen to hold about 100 episodes (of 300 steps each), and every 4 steps 4 batches of 64 samples were drawn from the replay memory.\n",
    "During execution of the episodes the agent used an epsilon-greedy policy, with a start value of 1.0 (high exploration), gradually declining to a minimum value of 0.01 (high exploitation) within about 1000 episodes.\n",
    "The target Q-function in DQN and DDQN was updated with a soft-update (θ_target = τ*θ_local + (1 - τ)*θ_target) with a weight τ=1e-3 after every processed batch.\n",
    "For weight updates a constant learning learning rate of 1e-4 turned out to deliver good results.\n",
    "\n",
    "### Performance\n",
    "The following plot displays the performance for the different algorithm and network architecture choices. The average final score of each episode, averaged over the last 100 episodes is drawn against the number of episodes executed for learning:\n",
    "![Scores](results/multi_model.scores.png)\n",
    "As seem from the plot, the target performance of an average score of +13 is achieved by almost all combinations of algorithm and model within about 500 episodes. Clearly the worst performance is delivered by the DQN algorithm in combination with the autoencoder-like network architecture.\n",
    "\n",
    "For the autoencoder-like model:\n",
    "\n",
    "DQN|DDQN\n",
    "-|-\n",
    "![DQN_Scores](results/dqn_model.scores.png) | ![DDQN_Scores](results/ddqn_model.scores.png)\n",
    "Scores|Scores\n",
    "![DQN_Loss](results/dqn_model.losses.png) | ![DDQN_Loss](results/ddqn_model.losses.png)\n",
    "Loss|Loss\n",
    "\n",
    "For the autoencoder-like model:\n",
    "\n",
    "DQN|DDQN\n",
    "-|-\n",
    "![DQN_Scores](results/dqn_simple_model.scores.png) | ![DDQN_Scores](results/ddqn_simple_model.scores.png)\n",
    "Scores|Scores\n",
    "![DQN_Loss](results/dqn_simple_model.losses.png) | ![DDQN_Loss](results/ddqn_simple_model.losses.png)\n",
    "Loss|Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementation\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pkg_resources\n",
    "import random\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from unityagents.exception import UnityEnvironmentException\n",
    "\n",
    "from banananav.environment import PLATFORM_PATHS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment\n",
    "\n",
    "The environment in which the agent operates is based on a predefined [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) environment was installed in [banananav/resources/](../tree/banananav/resources/) folder during the setup described in the [README](file/README.md).\n",
    "\n",
    "To navigate the environment the [environment.py module](files/banananav/environment.py) provides a `BananaAgent` class that chooses an action for a given state of the environment based on a provided Q-Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s BananaAgent banananav/environment.py\n",
    "class BananaAgent:\n",
    "    \"\"\"Agent based on a Q-function.\"\"\"\n",
    "\n",
    "    def __init__(self, Q, action_size, epsilon=0.0):\n",
    "        \"\"\"Initialize the agent.\n",
    "\n",
    "        Args:\n",
    "            Q: Q-function that is callable with a state and returns a 1-dim\n",
    "                array-like containing the q-values for each action.\n",
    "            action_size: The number of available actions.\n",
    "            epsilon: propability for the agent to choose the action uniformly\n",
    "                from the available actions instead of based on the Q-function,\n",
    "                defaults to 0.0.\n",
    "        \"\"\"\n",
    "        self._Q = Q\n",
    "        self._action_size = action_size\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Select an action for the given state.\n",
    "\n",
    "        Args:\n",
    "            state: The state to choose the action for.\n",
    "        Returns:\n",
    "            An int representing the action.\n",
    "        \"\"\"\n",
    "        if not torch.is_tensor(state):\n",
    "            try:\n",
    "                state = torch.from_numpy(state)\n",
    "            except:\n",
    "                state = torch.from_numpy(np.array(state, dtype=np.float))\n",
    "\n",
    "        state = state.float()\n",
    "\n",
    "        if self._epsilon == 0.0 or random.uniform(0, 1) > self._epsilon:\n",
    "            with torch.no_grad():\n",
    "                return torch.argmax(self._Q(state)).item()\n",
    "\n",
    "        return np.random.randint(self._action_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and a `BananaEnv` class that provides an interface that allows to navigate the environment with an instance of the `BananaAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s BananaEnv banananav/environment.py\n",
    "class BananaEnv:\n",
    "    \"\"\"Banana collection environment.\n",
    "\n",
    "    The environment accepts actions and provides states and rewards in response.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        for path in PLATFORM_PATHS:\n",
    "            try:\n",
    "                unity_resource = pkg_resources.resource_filename('banananav', 'resources/' + path)\n",
    "                self._env = UnityEnvironment(file_name=unity_resource)\n",
    "                print(\"Environment loaded from \" + path)\n",
    "                break\n",
    "            except UnityEnvironmentException as e:\n",
    "                print(\"Attempted to load \" + path + \":\")\n",
    "                print(e)\n",
    "                print(\"\")\n",
    "                pass\n",
    "\n",
    "        if not hasattr(self, '_env'):\n",
    "            raise Exception(\"No unity environment found, setup the environment as described in the README.\")\n",
    "\n",
    "        # get the default brain\n",
    "        self._brain_name = self._env.brain_names[0]\n",
    "        self._brain = self._env.brains[self._brain_name]\n",
    "\n",
    "        self._info = None\n",
    "        self._score = None\n",
    "\n",
    "    def generate_episode(self, agent, max_steps=None, train_mode=False):\n",
    "        \"\"\"Create a generator for and episode driven by an actor.\n",
    "        Args:\n",
    "            actor: An actor that provides the next action for a given state.\n",
    "            max_steps: Maximum number of steps (int) to take in the episode. If\n",
    "                None, the episode is generated until a terminal state is reached.\n",
    "\n",
    "        Returns:\n",
    "            A generator providing a tuple of the current state, the action taken,\n",
    "            the obtained reward, the next state and a flag whether the next\n",
    "            state is terminal or not.\n",
    "        \"\"\"\n",
    "        state = self.reset(train_mode=train_mode)\n",
    "        is_terminal = False\n",
    "        count = 0\n",
    "\n",
    "        while not is_terminal and (max_steps is None or count < max_steps):\n",
    "            action = agent.act(state)\n",
    "            reward, next_state, is_terminal = self.step(action)\n",
    "\n",
    "            step_data = (state, action, reward, next_state, is_terminal)\n",
    "\n",
    "            state = next_state\n",
    "            count += 1\n",
    "\n",
    "            yield step_data\n",
    "\n",
    "    def reset(self, train_mode=False):\n",
    "        \"\"\"Reset and initiate a new episode in the environment.\n",
    "\n",
    "        Args:\n",
    "            train_mode: Indicate if the environment should be initiated in\n",
    "                training mode or not.\n",
    "\n",
    "        Returns:\n",
    "            The initial state of the episode (np.array).\n",
    "        \"\"\"\n",
    "        if self._info is not None and not self._info.local_done[0]:\n",
    "            raise Exception(\"Env is active, call terminate first\")\n",
    "\n",
    "        self._info = self._env.reset(train_mode=train_mode)[self._brain_name]\n",
    "        self._score = 0\n",
    "\n",
    "        return self._info.vector_observations[0]\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Execute an action.\n",
    "\n",
    "        Args:\n",
    "            action: An int representing the actionself.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the reward (float), the next state (np.array) and\n",
    "            a boolean indicating if the next state is terminal or not.\n",
    "        \"\"\"\n",
    "        if self._info is None:\n",
    "            raise Exception(\"Env is not active, call reset first\")\n",
    "\n",
    "        self._info = self._env.step(action)[self._brain_name]\n",
    "        next_state = self._info.vector_observations[0]\n",
    "        reward = self._info.rewards[0]\n",
    "        is_terminal = self._info.local_done[0]\n",
    "        self._score += reward\n",
    "\n",
    "        return reward, next_state, is_terminal\n",
    "\n",
    "    def terminate(self):\n",
    "        self._info = None\n",
    "        self._score = None\n",
    "\n",
    "    def close(self):\n",
    "        self._env.close()\n",
    "        self._info = None\n",
    "\n",
    "    def get_score(self):\n",
    "        \"\"\"Return the cumulative reward of the current episode.\"\"\"\n",
    "        return self._score\n",
    "\n",
    "    def get_action_size(self):\n",
    "        return self._brain.vector_action_space_size\n",
    "\n",
    "    def get_state_size(self):\n",
    "        return self._brain.vector_observation_space_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded from Banana.app\n",
      "'state size: 37'\n",
      "'state size: 4'\n"
     ]
    }
   ],
   "source": [
    "### RUN THIS CELL ONLY ONCE!! ###\n",
    "env = BananaEnv()\n",
    "pprint(\"state size: \" + str(env.get_state_size()))\n",
    "pprint(\"state size: \" + str(env.get_action_size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'============= Current step: 0'\n",
      "'state:'\n",
      "array([1.        , 0.        , 0.        , 0.        , 0.84408134,\n",
      "       0.        , 0.        , 1.        , 0.        , 0.0748472 ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.25755   ,\n",
      "       1.        , 0.        , 0.        , 0.        , 0.74177343,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.25854847,\n",
      "       0.        , 0.        , 1.        , 0.        , 0.09355672,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.31969345,\n",
      "       0.        , 0.        ])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34574997,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.08556978,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.26330134,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.90327591,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.2643221 ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.10695964,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.32683259,\n",
      "        0.        , -7.81049442])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 1'\n",
      "'state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34574997,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.08556978,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.26330134,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.90327591,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.2643221 ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.10695964,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.32683259,\n",
      "        0.        , -7.81049442])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([  1.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.33389047,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.10400748,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.27372321,   0.        ,\n",
      "         1.        ,   0.        ,   0.        ,   0.92001921,\n",
      "         0.        ,   1.        ,   0.        ,   0.        ,\n",
      "         0.27478445,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.13000619,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.33976912,   0.        ,\n",
      "       -10.5166626 ])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 2'\n",
      "'state:'\n",
      "array([  1.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.33389047,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.10400748,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.27372321,   0.        ,\n",
      "         1.        ,   0.        ,   0.        ,   0.92001921,\n",
      "         0.        ,   1.        ,   0.        ,   0.        ,\n",
      "         0.27478445,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.13000619,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.33976912,   0.        ,\n",
      "       -10.5166626 ])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.41293901e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.25456721e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.85944790e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.39653754e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        2.87053376e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.56806216e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.54939610e-01, -4.76837158e-07,\n",
      "       -1.16585550e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 3'\n",
      "'state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.41293901e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.25456721e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.85944790e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.39653754e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        2.87053376e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.56806216e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.54939610e-01, -4.76837158e-07,\n",
      "       -1.16585550e+01])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.49792719e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.48925006e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.98925906e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.60508406e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.00084829e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.56798851e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.71052921e-01, -4.76837158e-07,\n",
      "       -1.21403875e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 4'\n",
      "'state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.49792719e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.48925006e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.98925906e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.60508406e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.00084829e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.56798851e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.71052921e-01, -4.76837158e-07,\n",
      "       -1.21403875e+01])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.73447743e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.12227517e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.81877744e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.13437968e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.78085756e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.87564063e-01, -9.53674316e-07,\n",
      "       -1.23437004e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 5'\n",
      "'state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.73447743e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.12227517e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.81877744e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.13437968e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.78085756e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.87564063e-01, -9.53674316e-07,\n",
      "       -1.23437004e+01])\n",
      "'action: 0'\n",
      "'next state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.79221481e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.15355480e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.86902952e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.16578090e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.83091533e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.91446769e-01, -1.78813934e-07,\n",
      "        1.67893946e+00])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'============= Current step: 6'\n",
      "'state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.79221481e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.15355480e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.86902952e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.16578090e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.83091533e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.91446769e-01, -1.78813934e-07,\n",
      "        1.67893946e+00])\n",
      "'action: 0'\n",
      "'next state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.66466892e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.08445632e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.75801826e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.09641421e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.72033262e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.82869601e-01, -4.76837158e-07,\n",
      "        8.37670422e+00])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 7'\n",
      "'state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.66466892e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.08445632e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.75801826e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.09641421e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.72033262e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.82869601e-01, -4.76837158e-07,\n",
      "        8.37670422e+00])\n",
      "'action: 0'\n",
      "'next state:'\n",
      "array([1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.48881036e-01, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 1.46534532e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 2.97647148e-01, 0.00000000e+00,\n",
      "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.58453655e-01,\n",
      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.98801064e-01, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 9.54752147e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.69465560e-01, 4.76837158e-07,\n",
      "       1.07555799e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 8'\n",
      "'state:'\n",
      "array([1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.48881036e-01, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 1.46534532e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 2.97647148e-01, 0.00000000e+00,\n",
      "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.58453655e-01,\n",
      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.98801064e-01, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 9.54752147e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.69465560e-01, 4.76837158e-07,\n",
      "       1.07555799e+01])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34794271,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.14402579,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29628792,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95627016,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29743659,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95257705,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.36777839,\n",
      "        0.        , -3.02163815])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 9'\n",
      "'state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34794271,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.14402579,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29628792,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95627016,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29743659,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95257705,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.36777839,\n",
      "        0.        , -3.02163815])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.53818238e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.57777429e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.03738028e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.68239009e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.04915547e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.64499652e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.77026141e-01, -1.43051147e-06,\n",
      "       -8.28599930e+00])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n"
     ]
    }
   ],
   "source": [
    "dummy_Q = lambda s: (torch.arange(4) == s[0]).float()\n",
    "agent = BananaAgent(dummy_Q, 4)\n",
    "\n",
    "for step, step_data in enumerate(env.generate_episode(agent, max_steps=10)):\n",
    "    state, action, reward, next_state, is_terminal = step_data\n",
    "    pprint(\"============= Current step: \" + str(step))\n",
    "    pprint(\"state:\")\n",
    "    pprint(state)\n",
    "    pprint(\"action: \" + str(action))\n",
    "    pprint(\"next state:\")\n",
    "    pprint(next_state)\n",
    "    pprint(\"reward:\" + str(reward))\n",
    "    pprint(\"is terminal state: \" + str(is_terminal))\n",
    "    \n",
    "    \n",
    "env.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Deep Q-Learning algorithm and model\n",
    "\n",
    "To learn the Q-function that is used in the `BananaAgent` to select actions, two variants of the Q-Learning algorithm with a deep neural network (DNN) based function approximator are implemented:\n",
    "- Q-learning with a DNN as approximator (DQN) for the Q-function using experience replay, and\n",
    "- Double Q-learning with a DNN as approximator (DDQN)  using experience replay.\n",
    "For a brief overview of the Q-Learning algorithm see e.g. [Q-learning](https://en.wikipedia.org/wiki/Q-learning).\n",
    "\n",
    "In addition to this algorithm variants two different architectures of DNNs as function approximators are implemented,\n",
    "- a simple variant with two hidden layers of 64 units each, and\n",
    "- a more advanced architecture that is extended with two additional hidden layers with 16 and 8 units at the input side of the DNN. This two layers are intended to work similar the encoder part of an [autoencoder architecture](https://en.wikipedia.org/wiki/Autoencoder) and extract a smaller number of features from the raw state. \n",
    "\n",
    "#### Model implementation\n",
    "\n",
    "The DNN models are implemented as PyTorch modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load banananav/qmodel.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BananaQModel(nn.Module):\n",
    "    \"\"\"Q Function Approximator with autoencode-like step.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Args:\n",
    "            state_size: Dimension of each state (int)\n",
    "            action_size: number of actions (int)\n",
    "        \"\"\"\n",
    "        super(BananaQModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.fc5 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        return self.fc5(x)\n",
    "\n",
    "class SimpleBananaQModel(nn.Module):\n",
    "    \"\"\"Q Function Approximator.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Args:\n",
    "            state_size: Dimension of each state (int)\n",
    "            action_size: number of actions (int)\n",
    "        \"\"\"\n",
    "        super(SimpleBananaQModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-learing algorithm implementation\n",
    "\n",
    "The DQN algorithm is implemented in the `DeepQLearner` class, which also takes care of the episode creation needed for the learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banananav.replaymemory import ReplayMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load -s DeepQLearner banananav/training.py\n",
    "class DeepQLearner():\n",
    "    \"\"\"Implementation of the DQN learning algorithm with experience replay.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env=None, model=BananaQModel, memory=ReplayMemory(int(3e4)),\n",
    "            batch_steps=4, batch_size=64, batch_repeat=4,\n",
    "            lr=1e-4, decay=0.001,\n",
    "            epsilon_start=1.0, epsilon_min=0.01, epsilon_decay=0.995,\n",
    "            gamma=0.99, tau=1e-3):\n",
    "        self._memory = memory\n",
    "        # Don't instantiate as default as the constructor already starts the unity environment\n",
    "        self._env = env if env is not None else BananaEnv()\n",
    "\n",
    "        self._state_size = self._env.get_state_size()\n",
    "        self._actions = self._env.get_action_size()\n",
    "\n",
    "        self._batch_steps = batch_steps\n",
    "        self._batch_size = batch_size\n",
    "        self._batch_repeat = batch_repeat\n",
    "\n",
    "        self._epsilon_start=epsilon_start\n",
    "        self._epsilon_min=epsilon_min\n",
    "        self._epsilon_decay=epsilon_decay\n",
    "        self._gamma = gamma\n",
    "        self._tau = tau\n",
    "\n",
    "        self._qnetwork_local = model(self._state_size, self._actions).to(device)\n",
    "        self._qnetwork_target = model(self._state_size, self._actions).to(device)\n",
    "        self._optimizer = optim.Adam(self._qnetwork_local.parameters(), lr=lr,\n",
    "            amsgrad=True)\n",
    "\n",
    "        self._qnetwork_local.eval()\n",
    "        self._qnetwork_target.eval()\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Store the learning result.\n",
    "\n",
    "        Store the parameters of the current Q-function approximation to the given path.\n",
    "        \"\"\"\n",
    "        torch.save(self._qnetwork_local.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"Load learning results.\n",
    "\n",
    "        Load the parameters from the given path into the current and target\n",
    "        Q-function approximator.\n",
    "        \"\"\"\n",
    "        self._qnetwork_local.load_state_dict(torch.load(path))\n",
    "        self._qnetwork_target.load_state_dict(torch.load(path))\n",
    "        self._qnetwork_local.to(device)\n",
    "        self._qnetwork_target.to(device)\n",
    "\n",
    "    def get_agent(self, epsilon=0.0):\n",
    "        \"\"\"Return an agent based on the parameters of the current Q-function approximation.\n",
    "        \"\"\"\n",
    "        return BananaAgent(self._qnetwork_local, self._env.get_action_size(),\n",
    "                epsilon=epsilon)\n",
    "\n",
    "    def train(self, num_episodes=100):\n",
    "        episodes = ( self._env.generate_episode(\n",
    "                        self.get_agent(self._get_epsilon(cnt)), train_mode=True)\n",
    "                for cnt in range(num_episodes) )\n",
    "        steps = ( (cnt, step_cnt, step_data)\n",
    "                for cnt, episode in enumerate(episodes)\n",
    "                for step_cnt, step_data in enumerate(episode) )\n",
    "\n",
    "        for episode, step, step_data in steps:\n",
    "            self._memory.add(*step_data)\n",
    "\n",
    "            if (step % self._batch_steps == 0 or self._is_terminal(step_data)) \\\n",
    "                    and self._memory.size() >= self._batch_size:\n",
    "                for i in range(1 if self._memory.size() < 1000 else self._batch_repeat):\n",
    "                    loss = self._train_from_memory()\n",
    "                    self._update_target()\n",
    "                yield loss, self._env.get_score(), self._is_terminal(step_data)\n",
    "\n",
    "    def _get_epsilon(self, cnt):\n",
    "        return max(self._epsilon_min, self._epsilon_decay ** cnt * self._epsilon_start)\n",
    "\n",
    "    def _train_from_memory(self):\n",
    "        self._qnetwork_local.train()\n",
    "\n",
    "        batch = self._memory.sample(self._batch_size)\n",
    "        loss = self._calculate_loss(*zip(*batch))\n",
    "\n",
    "        self._optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "\n",
    "        self._qnetwork_local.eval()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _calculate_loss(self, states, actions, rewards, next_states, is_terminal):\n",
    "        states, next_states, rewards, is_terminal = self._to_tensor(states, next_states, rewards, is_terminal)\n",
    "        actions = self._to_tensor(actions, dtype=torch.long)[0]\n",
    "\n",
    "        rewards = rewards.unsqueeze(1)\n",
    "        is_terminal = is_terminal.unsqueeze(1)\n",
    "        actions = actions.unsqueeze(1)\n",
    "\n",
    "        Q_target_next = self._qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        Q_target = rewards + (self._gamma * Q_target_next * (1 - is_terminal))\n",
    "        Q_predicted = self._qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        loss = F.mse_loss(Q_target, Q_predicted)\n",
    "\n",
    "        # Validate dimensions\n",
    "        assert Q_predicted.size()[0] == states.size()[0]\n",
    "        assert Q_predicted.size()[1] == 1\n",
    "        assert Q_predicted.size() == Q_target_next.size() == Q_target.size() \\\n",
    "                == rewards.size() == is_terminal.size() == actions.size()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _update_target(self):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        \"\"\"\n",
    "        parameters = zip(self._qnetwork_target.parameters(), self._qnetwork_local.parameters())\n",
    "\n",
    "        for target_param, local_param in parameters:\n",
    "            update = self._tau * local_param.data + (1.0 - self._tau) * target_param.data\n",
    "            target_param.data.copy_(update)\n",
    "\n",
    "    def _is_terminal(self, state_data):\n",
    "        return state_data[-1]\n",
    "\n",
    "    def _get_reward(self, state_data):\n",
    "        return state_data[2]\n",
    "\n",
    "    def _to_tensor(self, *arrays, dtype=torch.float):\n",
    "        return tuple(torch.tensor(a).to(device, dtype=dtype) for a in arrays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is sub-classed by `DoubleDeepQLearner` with the modified loss calculation for the Double Q-Learning algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s DoubleDeepQLearner banananav/training.py\n",
    "class DoubleDeepQLearner(DeepQLearner):\n",
    "    \"\"\"Implementation of the Double-DQN learning algorithm with experience replay.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env=None, model=BananaQModel, memory=ReplayMemory(int(3e4)),\n",
    "            batch_steps=4, batch_size=64, batch_repeat=4,\n",
    "            lr=1e-4, decay=0.001,\n",
    "            epsilon_start=1.0, epsilon_min=0.01, epsilon_decay=0.995,\n",
    "            gamma=0.99, tau=1e-3):\n",
    "        super(DoubleDeepQLearner, self).__init__(env=env, model=model, memory=memory,\n",
    "                batch_steps=batch_steps, batch_size=batch_size, batch_repeat=batch_repeat,\n",
    "                lr=lr, decay=decay,\n",
    "                epsilon_start=epsilon_start, epsilon_min=epsilon_min, epsilon_decay=epsilon_decay,\n",
    "                gamma=gamma, tau=tau)\n",
    "\n",
    "    def _calculate_loss(self, states, actions, rewards, next_states, is_terminal):\n",
    "        states, next_states, rewards, is_terminal = self._to_tensor(states, next_states, rewards, is_terminal)\n",
    "        actions = self._to_tensor(actions, dtype=torch.long)[0]\n",
    "\n",
    "        rewards = rewards.unsqueeze(1)\n",
    "        is_terminal = is_terminal.unsqueeze(1)\n",
    "        actions = actions.unsqueeze(1)\n",
    "\n",
    "        Q_local_next_choices = self._qnetwork_local(next_states).max(1)[1].unsqueeze(1)\n",
    "        Q_target_next = self._qnetwork_target(next_states).detach().gather(1, Q_local_next_choices)\n",
    "        Q_target = rewards + (self._gamma * Q_target_next * (1 - is_terminal))\n",
    "        Q_predicted = self._qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        loss = F.mse_loss(Q_target, Q_predicted)\n",
    "\n",
    "        # Validate dimensions\n",
    "        assert Q_local_next_choices.size() == actions.size()\n",
    "        assert Q_predicted.size()[0] == states.size()[0]\n",
    "        assert Q_predicted.size()[1] == 1\n",
    "        assert Q_predicted.size() == Q_target_next.size() == Q_target.size() \\\n",
    "                == rewards.size() == is_terminal.size() == actions.size()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Execute learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkb/anaconda3/envs/drlnd/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [------------------------------------------------------------] loss: +3.678E-05 / score: +1.000(+1/+1/+1)\n",
      "2/0 [------------------------------------------------------------] loss: +1.525E-02 / score: +1.500(+1/+2/+2))\n",
      "3/0 [------------------------------------------------------------] loss: +1.589E-05 / score: +0.667(-1/-1/+2))\n",
      "4/0 [------------------------------------------------------------] loss: +1.550E-02 / score: +0.500(-1/+0/+2))\n",
      "5/0 [------------------------------------------------------------] loss: +1.606E-04 / score: -0.200(-3/-3/+2))\n",
      "6/0 [------------------------------------------------------------] loss: +1.491E-02 / score: +0.000(-3/+1/+2))\n",
      "7/0 [------------------------------------------------------------] loss: +3.039E-05 / score: +0.000(-3/+0/+2))\n",
      "8/0 [------------------------------------------------------------] loss: +2.500E-05 / score: +0.000(-3/+0/+2))\n",
      "9/0 [------------------------------------------------------------] loss: +1.734E-05 / score: -0.111(-3/-1/+2))\n",
      "10/0 [------------------------------------------------------------] loss: +6.382E-05 / score: +0.100(-3/+2/+2)\n",
      "11/0 [------------------------------------------------------------] loss: +5.553E-05 / score: +0.091(-3/+0/+2))\n",
      "12/0 [------------------------------------------------------------] loss: +5.213E-05 / score: +0.083(-3/+0/+2))\n",
      "13/0 [------------------------------------------------------------] loss: +1.519E-02 / score: +0.077(-3/+0/+2))\n",
      "14/0 [------------------------------------------------------------] loss: +1.171E-04 / score: +0.143(-3/+1/+2))\n",
      "15/0 [------------------------------------------------------------] loss: +1.413E-04 / score: +0.333(-3/+3/+3))\n",
      "16/0 [------------------------------------------------------------] loss: +1.567E-02 / score: +0.250(-3/-1/+3))\n",
      "17/0 [------------------------------------------------------------] loss: +1.491E-02 / score: +0.118(-3/-2/+3))\n",
      "18/0 [------------------------------------------------------------] loss: +8.902E-05 / score: +0.111(-3/+0/+3))\n",
      "19/0 [------------------------------------------------------------] loss: +1.545E-02 / score: +0.053(-3/-1/+3))\n",
      "20/0 [------------------------------------------------------------] loss: +3.321E-04 / score: +0.050(-3/+0/+3))\n",
      "21/0 [------------------------------------------------------------] loss: +2.612E-04 / score: +0.048(-3/+0/+3))\n",
      "22/0 [------------------------------------------------------------] loss: +1.725E-04 / score: +0.045(-3/+0/+3))\n",
      "23/0 [------------------------------------------------------------] loss: +1.619E-02 / score: +0.087(-3/+1/+3))\n",
      "24/0 [------------------------------------------------------------] loss: +1.496E-04 / score: +0.125(-3/+1/+3))\n",
      "25/0 [------------------------------------------------------------] loss: +3.222E-04 / score: +0.080(-3/-1/+3))\n",
      "26/0 [------------------------------------------------------------] loss: +2.137E-04 / score: +0.192(-3/+3/+3))\n",
      "27/0 [------------------------------------------------------------] loss: +1.521E-04 / score: +0.185(-3/+0/+3))\n",
      "28/0 [------------------------------------------------------------] loss: +2.274E-04 / score: +0.214(-3/+1/+3))\n",
      "29/0 [------------------------------------------------------------] loss: +1.564E-02 / score: +0.241(-3/+1/+3))\n",
      "30/0 [------------------------------------------------------------] loss: +1.586E-02 / score: +0.233(-3/+0/+3))\n",
      "31/0 [------------------------------------------------------------] loss: +3.575E-04 / score: +0.290(-3/+2/+3))\n",
      "32/0 [------------------------------------------------------------] loss: +2.458E-04 / score: +0.281(-3/+0/+3))\n",
      "33/0 [------------------------------------------------------------] loss: +1.555E-02 / score: +0.212(-3/-2/+3))\n",
      "34/0 [------------------------------------------------------------] loss: +1.405E-02 / score: +0.235(-3/+1/+3))\n",
      "35/0 [------------------------------------------------------------] loss: +2.548E-04 / score: +0.229(-3/+0/+3))\n",
      "36/0 [------------------------------------------------------------] loss: +1.239E-03 / score: +0.194(-3/-1/+3))\n",
      "37/0 [------------------------------------------------------------] loss: +4.079E-04 / score: +0.162(-3/-1/+3))\n",
      "38/0 [------------------------------------------------------------] loss: +4.354E-04 / score: +0.184(-3/+1/+3))\n",
      "39/0 [------------------------------------------------------------] loss: +4.371E-04 / score: +0.205(-3/+1/+3))\n",
      "40/0 [------------------------------------------------------------] loss: +1.483E-02 / score: +0.275(-3/+3/+3))\n",
      "41/0 [------------------------------------------------------------] loss: +2.474E-04 / score: +0.317(-3/+2/+3))\n",
      "42/0 [------------------------------------------------------------] loss: +1.543E-02 / score: +0.310(-3/+0/+3))\n",
      "43/0 [------------------------------------------------------------] loss: +4.305E-04 / score: +0.326(-3/+1/+3))\n",
      "44/0 [------------------------------------------------------------] loss: +1.586E-02 / score: +0.318(-3/+0/+3))\n",
      "45/0 [------------------------------------------------------------] loss: +2.143E-04 / score: +0.333(-3/+1/+3))\n",
      "46/0 [------------------------------------------------------------] loss: +8.531E-04 / score: +0.326(-3/+0/+3))\n",
      "47/0 [------------------------------------------------------------] loss: +1.820E-03 / score: +0.340(-3/+1/+3))\n",
      "48/0 [------------------------------------------------------------] loss: +5.706E-04 / score: +0.354(-3/+1/+3))\n",
      "49/0 [------------------------------------------------------------] loss: +1.551E-03 / score: +0.367(-3/+1/+3))\n",
      "50/0 [------------------------------------------------------------] loss: +8.629E-04 / score: +0.380(-3/+1/+3))\n",
      "51/0 [------------------------------------------------------------] loss: +2.116E-03 / score: +0.412(-3/+2/+3))\n",
      "52/0 [------------------------------------------------------------] loss: +1.930E-03 / score: +0.404(-3/+0/+3))\n",
      "53/0 [------------------------------------------------------------] loss: +2.074E-02 / score: +0.377(-3/-1/+3))\n",
      "54/0 [------------------------------------------------------------] loss: +8.455E-03 / score: +0.444(-3/+4/+4))\n",
      "55/0 [------------------------------------------------------------] loss: +4.584E-03 / score: +0.491(-3/+3/+4))\n",
      "56/0 [------------------------------------------------------------] loss: +1.230E-02 / score: +0.518(-3/+2/+4))\n",
      "57/0 [------------------------------------------------------------] loss: +4.737E-03 / score: +0.509(-3/+0/+4))\n",
      "58/0 [------------------------------------------------------------] loss: +1.190E-02 / score: +0.500(-3/+0/+4))\n",
      "59/0 [------------------------------------------------------------] loss: +1.642E-02 / score: +0.525(-3/+2/+4))\n",
      "60/0 [------------------------------------------------------------] loss: +2.510E-03 / score: +0.550(-3/+2/+4))\n",
      "61/0 [------------------------------------------------------------] loss: +8.577E-04 / score: +0.541(-3/+0/+4))\n",
      "62/0 [------------------------------------------------------------] loss: +1.051E-02 / score: +0.548(-3/+1/+4))\n",
      "63/0 [------------------------------------------------------------] loss: +2.204E-02 / score: +0.556(-3/+1/+4))\n",
      "64/0 [------------------------------------------------------------] loss: +2.777E-03 / score: +0.562(-3/+1/+4))\n",
      "65/0 [------------------------------------------------------------] loss: +8.536E-03 / score: +0.554(-3/+0/+4))\n",
      "66/0 [------------------------------------------------------------] loss: +3.596E-03 / score: +0.561(-3/+1/+4))\n",
      "67/0 [------------------------------------------------------------] loss: +9.428E-03 / score: +0.582(-3/+2/+4))\n",
      "68/0 [------------------------------------------------------------] loss: +4.757E-03 / score: +0.603(-3/+2/+4))\n",
      "69/0 [------------------------------------------------------------] loss: +2.006E-02 / score: +0.609(-3/+1/+4))\n",
      "70/0 [------------------------------------------------------------] loss: +5.857E-03 / score: +0.643(-3/+3/+4))\n",
      "71/0 [------------------------------------------------------------] loss: +2.831E-02 / score: +0.676(-3/+3/+4))\n",
      "72/0 [------------------------------------------------------------] loss: +2.677E-02 / score: +0.681(-3/+1/+4))\n",
      "73/0 [------------------------------------------------------------] loss: +2.146E-02 / score: +0.712(-3/+3/+4))\n",
      "74/0 [------------------------------------------------------------] loss: +3.614E-02 / score: +0.770(-3/+5/+5))\n",
      "75/0 [------------------------------------------------------------] loss: +1.867E-02 / score: +0.787(-3/+2/+5))\n",
      "76/0 [------------------------------------------------------------] loss: +1.509E-02 / score: +0.789(-3/+1/+5))\n",
      "77/0 [------------------------------------------------------------] loss: +1.156E-02 / score: +0.818(-3/+3/+5))\n",
      "78/0 [------------------------------------------------------------] loss: +1.208E-02 / score: +0.808(-3/+0/+5))\n",
      "79/0 [------------------------------------------------------------] loss: +1.639E-02 / score: +0.810(-3/+1/+5))\n",
      "80/0 [------------------------------------------------------------] loss: +5.722E-03 / score: +0.825(-3/+2/+5))\n",
      "81/0 [------------------------------------------------------------] loss: +1.642E-02 / score: +0.815(-3/+0/+5))\n",
      "82/0 [------------------------------------------------------------] loss: +1.725E-02 / score: +0.817(-3/+1/+5))\n",
      "83/0 [------------------------------------------------------------] loss: +1.217E-02 / score: +0.855(-3/+4/+5))\n",
      "84/0 [------------------------------------------------------------] loss: +6.825E-03 / score: +0.881(-3/+3/+5))\n",
      "85/0 [------------------------------------------------------------] loss: +2.491E-02 / score: +0.894(-3/+2/+5))\n",
      "86/0 [------------------------------------------------------------] loss: +1.354E-02 / score: +0.907(-3/+2/+5))\n",
      "87/0 [------------------------------------------------------------] loss: +8.686E-03 / score: +0.897(-3/+0/+5))\n",
      "88/0 [------------------------------------------------------------] loss: +2.562E-02 / score: +0.943(-3/+5/+5))\n",
      "89/0 [------------------------------------------------------------] loss: +5.278E-03 / score: +0.933(-3/+0/+5))\n",
      "90/0 [------------------------------------------------------------] loss: +1.214E-02 / score: +0.933(-3/+1/+5))\n",
      "91/0 [------------------------------------------------------------] loss: +1.396E-02 / score: +0.956(-3/+3/+5))\n",
      "92/0 [------------------------------------------------------------] loss: +2.150E-02 / score: +0.989(-3/+4/+5))\n",
      "93/0 [------------------------------------------------------------] loss: +3.739E-02 / score: +0.989(-3/+1/+5))\n",
      "94/0 [------------------------------------------------------------] loss: +4.141E-03 / score: +1.011(-3/+3/+5))\n",
      "95/0 [------------------------------------------------------------] loss: +2.180E-02 / score: +1.000(-3/+0/+5))\n",
      "96/0 [------------------------------------------------------------] loss: +1.224E-02 / score: +1.000(-3/+1/+5))\n",
      "97/0 [------------------------------------------------------------] loss: +1.482E-02 / score: +1.031(-3/+4/+5))\n",
      "98/0 [------------------------------------------------------------] loss: +2.701E-02 / score: +1.031(-3/+1/+5))\n",
      "99/0 [------------------------------------------------------------] loss: +2.416E-02 / score: +1.020(-3/+0/+5))\n",
      "100/0 [------------------------------------------------------------] loss: +1.134E-02 / score: +1.050(-3/+4/+5)\n",
      "101/0 [------------------------------------------------------------] loss: +7.805E-03 / score: +1.070(-3/+3/+5))\n",
      "102/0 [------------------------------------------------------------] loss: +5.347E-03 / score: +1.070(-3/+2/+5))\n",
      "103/0 [------------------------------------------------------------] loss: +4.926E-03 / score: +1.110(-3/+3/+5))\n",
      "104/0 [------------------------------------------------------------] loss: +1.755E-02 / score: +1.150(-3/+4/+5))\n",
      "105/0 [------------------------------------------------------------] loss: +1.672E-02 / score: +1.200(-2/+2/+5))\n",
      "106/0 [------------------------------------------------------------] loss: +1.678E-02 / score: +1.200(-2/+1/+5))\n",
      "107/0 [------------------------------------------------------------] loss: +1.008E-02 / score: +1.240(-2/+4/+5))\n",
      "108/0 [------------------------------------------------------------] loss: +2.312E-02 / score: +1.290(-2/+5/+5))\n",
      "109/0 [------------------------------------------------------------] loss: +1.172E-02 / score: +1.330(-2/+3/+5))\n",
      "110/0 [------------------------------------------------------------] loss: +4.388E-02 / score: +1.310(-2/+0/+5))\n",
      "111/0 [------------------------------------------------------------] loss: +2.554E-02 / score: +1.340(-2/+3/+5))\n",
      "112/0 [------------------------------------------------------------] loss: +1.601E-02 / score: +1.380(-2/+4/+5))\n",
      "113/0 [------------------------------------------------------------] loss: +2.027E-02 / score: +1.400(-2/+2/+5))\n",
      "114/0 [------------------------------------------------------------] loss: +2.400E-02 / score: +1.420(-2/+3/+5))\n",
      "115/0 [------------------------------------------------------------] loss: +1.759E-02 / score: +1.420(-2/+3/+5))\n",
      "116/0 [------------------------------------------------------------] loss: +2.443E-02 / score: +1.480(-2/+5/+5))\n",
      "117/0 [------------------------------------------------------------] loss: +3.182E-02 / score: +1.530(-2/+3/+5))\n",
      "118/0 [------------------------------------------------------------] loss: +9.408E-03 / score: +1.570(-2/+4/+5))\n",
      "119/0 [------------------------------------------------------------] loss: +2.097E-02 / score: +1.580(-2/+0/+5))\n",
      "120/0 [------------------------------------------------------------] loss: +2.556E-02 / score: +1.630(-2/+5/+5))\n",
      "121/0 [------------------------------------------------------------] loss: +1.987E-02 / score: +1.670(-2/+4/+5))\n",
      "122/0 [------------------------------------------------------------] loss: +2.048E-02 / score: +1.710(-2/+4/+5))\n",
      "123/0 [------------------------------------------------------------] loss: +1.616E-02 / score: +1.750(-2/+5/+5))\n",
      "124/0 [------------------------------------------------------------] loss: +3.672E-02 / score: +1.770(-2/+3/+5))\n",
      "125/0 [------------------------------------------------------------] loss: +9.783E-03 / score: +1.840(-2/+6/+6))\n",
      "126/0 [------------------------------------------------------------] loss: +1.867E-02 / score: +1.830(-2/+2/+6))\n",
      "127/0 [------------------------------------------------------------] loss: +9.008E-03 / score: +1.920(-2/+9/+9))\n",
      "128/0 [------------------------------------------------------------] loss: +1.948E-02 / score: +1.910(-2/+0/+9))\n",
      "129/0 [------------------------------------------------------------] loss: +1.741E-02 / score: +1.930(-2/+3/+9))\n",
      "130/0 [------------------------------------------------------------] loss: +1.547E-02 / score: +1.980(-2/+5/+9))\n",
      "131/0 [------------------------------------------------------------] loss: +1.714E-02 / score: +1.990(-2/+3/+9))\n",
      "132/0 [------------------------------------------------------------] loss: +3.027E-02 / score: +1.990(-2/+0/+9))\n",
      "133/0 [------------------------------------------------------------] loss: +2.273E-02 / score: +2.050(-1/+4/+9))\n",
      "134/0 [------------------------------------------------------------] loss: +2.245E-02 / score: +2.060(-1/+2/+9))\n",
      "135/0 [------------------------------------------------------------] loss: +2.958E-02 / score: +2.130(-1/+7/+9))\n",
      "136/0 [------------------------------------------------------------] loss: +1.636E-02 / score: +2.170(-1/+3/+9))\n",
      "137/0 [------------------------------------------------------------] loss: +4.297E-02 / score: +2.240(-1/+6/+9))\n",
      "138/0 [------------------------------------------------------------] loss: +9.727E-03 / score: +2.270(-1/+4/+9))\n",
      "139/0 [------------------------------------------------------------] loss: +3.249E-02 / score: +2.290(-1/+3/+9))\n",
      "140/0 [------------------------------------------------------------] loss: +1.252E-02 / score: +2.280(-1/+2/+9))\n",
      "141/0 [------------------------------------------------------------] loss: +3.791E-02 / score: +2.280(-1/+2/+9))\n",
      "142/0 [------------------------------------------------------------] loss: +1.417E-02 / score: +2.300(-1/+2/+9))\n",
      "143/0 [------------------------------------------------------------] loss: +2.753E-02 / score: +2.330(-1/+4/+9))\n",
      "144/0 [------------------------------------------------------------] loss: +1.296E-02 / score: +2.330(-1/+0/+9))\n",
      "145/0 [------------------------------------------------------------] loss: +2.675E-02 / score: +2.380(-1/+6/+9))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/0 [------------------------------------------------------------] loss: +2.832E-02 / score: +2.440(-1/+6/+9))\n",
      "147/0 [------------------------------------------------------------] loss: +3.769E-02 / score: +2.450(-1/+2/+9))\n",
      "148/0 [------------------------------------------------------------] loss: +2.502E-02 / score: +2.480(-1/+4/+9))\n",
      "149/0 [------------------------------------------------------------] loss: +1.480E-02 / score: +2.480(-1/+1/+9))\n",
      "150/0 [------------------------------------------------------------] loss: +1.746E-02 / score: +2.510(-1/+4/+9))\n",
      "151/0 [------------------------------------------------------------] loss: +3.105E-02 / score: +2.520(-1/+3/+9))\n",
      "152/0 [------------------------------------------------------------] loss: +2.233E-02 / score: +2.530(-1/+1/+9))\n",
      "153/0 [------------------------------------------------------------] loss: +2.832E-02 / score: +2.600(+0/+6/+9))\n",
      "154/0 [------------------------------------------------------------] loss: +1.552E-02 / score: +2.570(+0/+1/+9))\n",
      "155/0 [------------------------------------------------------------] loss: +1.865E-02 / score: +2.530(-1/-1/+9))\n",
      "156/0 [------------------------------------------------------------] loss: +1.482E-02 / score: +2.620(-1/+11/+11)\n",
      "157/0 [------------------------------------------------------------] loss: +2.092E-02 / score: +2.640(-1/+2/+11)1)\n",
      "158/0 [------------------------------------------------------------] loss: +3.063E-02 / score: +2.680(-1/+4/+11))\n",
      "159/0 [------------------------------------------------------------] loss: +8.246E-02 / score: +2.700(-1/+4/+11))\n",
      "160/0 [------------------------------------------------------------] loss: +3.339E-02 / score: +2.730(-1/+5/+11))\n",
      "161/0 [------------------------------------------------------------] loss: +1.143E-02 / score: +2.770(-1/+4/+11))\n",
      "162/0 [------------------------------------------------------------] loss: +4.215E-02 / score: +2.770(-1/+1/+11))\n",
      "163/0 [------------------------------------------------------------] loss: +1.910E-02 / score: +2.820(-1/+6/+11))\n",
      "164/0 [------------------------------------------------------------] loss: +8.306E-03 / score: +2.860(-1/+5/+11))\n",
      "165/0 [------------------------------------------------------------] loss: +4.796E-02 / score: +2.840(-2/-2/+11))\n",
      "166/0 [------------------------------------------------------------] loss: +5.104E-02 / score: +2.870(-2/+4/+11))\n",
      "167/0 [------------------------------------------------------------] loss: +6.196E-02 / score: +2.890(-2/+4/+11))\n",
      "168/0 [------------------------------------------------------------] loss: +3.661E-02 / score: +2.910(-2/+4/+11))\n",
      "169/0 [------------------------------------------------------------] loss: +5.232E-02 / score: +2.950(-2/+5/+11))\n",
      "170/0 [------------------------------------------------------------] loss: +1.378E-02 / score: +2.960(-2/+4/+11))\n",
      "171/0 [------------------------------------------------------------] loss: +4.886E-02 / score: +3.000(-2/+7/+11))\n",
      "172/0 [------------------------------------------------------------] loss: +1.415E-02 / score: +2.990(-2/+0/+11))\n",
      "173/0 [------------------------------------------------------------] loss: +1.452E-02 / score: +2.970(-2/+1/+11))\n",
      "174/0 [------------------------------------------------------------] loss: +8.362E-02 / score: +2.930(-2/+1/+11))\n",
      "175/0 [------------------------------------------------------------] loss: +5.176E-02 / score: +2.930(-2/+2/+11))\n",
      "176/0 [------------------------------------------------------------] loss: +2.029E-02 / score: +2.980(-2/+6/+11))\n",
      "177/0 [------------------------------------------------------------] loss: +1.603E-02 / score: +3.020(-2/+7/+11))\n",
      "178/0 [------------------------------------------------------------] loss: +1.130E-02 / score: +3.050(-2/+3/+11))\n",
      "179/0 [------------------------------------------------------------] loss: +2.325E-02 / score: +3.020(-2/-2/+11))\n",
      "180/0 [------------------------------------------------------------] loss: +4.101E-02 / score: +3.040(-2/+4/+11))\n",
      "181/0 [------------------------------------------------------------] loss: +1.946E-02 / score: +3.100(-2/+6/+11))\n",
      "182/0 [------------------------------------------------------------] loss: +6.935E-03 / score: +3.080(-2/-1/+11))\n",
      "183/0 [------------------------------------------------------------] loss: +2.551E-02 / score: +3.090(-2/+5/+11))\n",
      "184/0 [------------------------------------------------------------] loss: +2.748E-02 / score: +3.100(-2/+4/+11))\n",
      "185/0 [------------------------------------------------------------] loss: +1.495E-02 / score: +3.150(-2/+7/+11))\n",
      "186/0 [------------------------------------------------------------] loss: +2.560E-02 / score: +3.180(-2/+5/+11))\n",
      "187/0 [------------------------------------------------------------] loss: +1.311E-02 / score: +3.230(-2/+5/+11))\n",
      "188/0 [------------------------------------------------------------] loss: +2.441E-02 / score: +3.240(-2/+6/+11))\n",
      "189/0 [------------------------------------------------------------] loss: +1.145E-02 / score: +3.330(-2/+9/+11))\n",
      "190/0 [------------------------------------------------------------] loss: +1.365E-02 / score: +3.380(-2/+6/+11))\n",
      "191/0 [------------------------------------------------------------] loss: +1.189E-01 / score: +3.370(-2/+2/+11))\n",
      "192/0 [------------------------------------------------------------] loss: +2.056E-02 / score: +3.370(-2/+4/+11))\n",
      "193/0 [------------------------------------------------------------] loss: +2.053E-02 / score: +3.370(-2/+1/+11))\n",
      "194/0 [------------------------------------------------------------] loss: +2.360E-02 / score: +3.390(-2/+5/+11))\n",
      "195/0 [------------------------------------------------------------] loss: +2.081E-02 / score: +3.430(-2/+4/+11))\n",
      "196/0 [------------------------------------------------------------] loss: +9.481E-03 / score: +3.480(-2/+6/+11))\n",
      "197/0 [------------------------------------------------------------] loss: +4.345E-02 / score: +3.550(-2/+11/+11)\n",
      "198/0 [------------------------------------------------------------] loss: +2.784E-02 / score: +3.580(-2/+4/+11)1)\n",
      "199/0 [------------------------------------------------------------] loss: +1.340E-02 / score: +3.640(-2/+6/+11))\n",
      "200/0 [------------------------------------------------------------] loss: +4.867E-02 / score: +3.710(-2/+11/+11)\n",
      "201/0 [------------------------------------------------------------] loss: +3.866E-02 / score: +3.730(-2/+5/+11)1)\n",
      "202/0 [------------------------------------------------------------] loss: +2.504E-02 / score: +3.770(-2/+6/+11))\n",
      "203/0 [------------------------------------------------------------] loss: +1.142E-02 / score: +3.770(-2/+3/+11))\n",
      "204/0 [------------------------------------------------------------] loss: +3.494E-02 / score: +3.770(-2/+4/+11))\n",
      "205/0 [------------------------------------------------------------] loss: +2.790E-02 / score: +3.850(-2/+10/+11)\n",
      "206/0 [------------------------------------------------------------] loss: +1.401E-02 / score: +3.930(-2/+9/+11)1)\n",
      "207/0 [------------------------------------------------------------] loss: +5.555E-03 / score: +3.990(-2/+10/+11)\n",
      "208/0 [------------------------------------------------------------] loss: +6.175E-02 / score: +4.000(-2/+6/+11)1)\n",
      "209/0 [------------------------------------------------------------] loss: +6.279E-02 / score: +4.030(-2/+6/+11))\n",
      "210/0 [------------------------------------------------------------] loss: +1.119E-02 / score: +4.090(-2/+6/+11))\n",
      "211/0 [------------------------------------------------------------] loss: +2.392E-02 / score: +4.160(-2/+10/+11)\n",
      "212/0 [------------------------------------------------------------] loss: +1.443E-02 / score: +4.180(-2/+6/+11)1)\n",
      "213/0 [------------------------------------------------------------] loss: +1.270E-02 / score: +4.290(-2/+13/+13)\n",
      "214/0 [------------------------------------------------------------] loss: +1.701E-02 / score: +4.320(-2/+6/+13)3)\n",
      "215/0 [------------------------------------------------------------] loss: +1.022E-01 / score: +4.380(-2/+9/+13))\n",
      "216/0 [------------------------------------------------------------] loss: +4.835E-02 / score: +4.450(-2/+12/+13)\n",
      "217/0 [------------------------------------------------------------] loss: +1.632E-02 / score: +4.480(-2/+6/+13)3)\n",
      "218/0 [------------------------------------------------------------] loss: +1.751E-02 / score: +4.500(-2/+6/+13))\n",
      "219/0 [------------------------------------------------------------] loss: +2.870E-02 / score: +4.580(-2/+8/+13))\n",
      "220/0 [------------------------------------------------------------] loss: +6.816E-02 / score: +4.580(-2/+5/+13))\n",
      "221/0 [------------------------------------------------------------] loss: +2.181E-02 / score: +4.630(-2/+9/+13))\n",
      "222/0 [------------------------------------------------------------] loss: +3.606E-02 / score: +4.630(-2/+4/+13))\n",
      "223/0 [------------------------------------------------------------] loss: +2.973E-02 / score: +4.690(-2/+11/+13)\n",
      "224/0 [------------------------------------------------------------] loss: +8.835E-03 / score: +4.720(-2/+6/+13)3)\n",
      "225/0 [------------------------------------------------------------] loss: +2.046E-02 / score: +4.720(-2/+6/+13))\n",
      "226/0 [------------------------------------------------------------] loss: +1.740E-02 / score: +4.750(-2/+5/+13))\n",
      "227/0 [------------------------------------------------------------] loss: +2.855E-02 / score: +4.750(-2/+9/+13))\n",
      "228/0 [------------------------------------------------------------] loss: +2.053E-02 / score: +4.800(-2/+5/+13))\n",
      "229/0 [------------------------------------------------------------] loss: +8.295E-03 / score: +4.840(-2/+7/+13))\n",
      "230/0 [------------------------------------------------------------] loss: +3.529E-02 / score: +4.860(-2/+7/+13))\n",
      "231/0 [------------------------------------------------------------] loss: +5.160E-02 / score: +4.900(-2/+7/+13))\n",
      "232/0 [------------------------------------------------------------] loss: +8.981E-03 / score: +4.980(-2/+8/+13))\n",
      "233/0 [------------------------------------------------------------] loss: +1.065E-02 / score: +5.040(-2/+10/+13)\n",
      "234/0 [------------------------------------------------------------] loss: +1.867E-02 / score: +5.080(-2/+6/+13)3)\n",
      "235/0 [------------------------------------------------------------] loss: +1.316E-02 / score: +5.120(-2/+11/+13)\n",
      "236/0 [------------------------------------------------------------] loss: +2.167E-02 / score: +5.190(-2/+10/+13))\n",
      "237/0 [------------------------------------------------------------] loss: +8.645E-02 / score: +5.200(-2/+7/+13)3)\n",
      "238/0 [------------------------------------------------------------] loss: +1.246E-01 / score: +5.240(-2/+8/+13))\n",
      "239/0 [------------------------------------------------------------] loss: +1.328E-02 / score: +5.260(-2/+5/+13))\n",
      "240/0 [------------------------------------------------------------] loss: +2.123E-02 / score: +5.320(-2/+8/+13))\n",
      "241/0 [------------------------------------------------------------] loss: +2.533E-02 / score: +5.400(-2/+10/+13)\n",
      "242/0 [------------------------------------------------------------] loss: +1.264E-02 / score: +5.500(-2/+12/+13))\n",
      "243/0 [------------------------------------------------------------] loss: +1.060E-02 / score: +5.510(-2/+5/+13)3)\n",
      "244/0 [------------------------------------------------------------] loss: +1.028E-01 / score: +5.570(-2/+6/+13))\n",
      "245/0 [------------------------------------------------------------] loss: +3.022E-02 / score: +5.630(-2/+12/+13)\n",
      "246/0 [------------------------------------------------------------] loss: +1.451E-02 / score: +5.660(-2/+9/+13)3)\n",
      "247/0 [------------------------------------------------------------] loss: +1.476E-02 / score: +5.750(-2/+11/+13)\n",
      "248/0 [------------------------------------------------------------] loss: +5.792E-02 / score: +5.840(-2/+13/+13))\n",
      "249/0 [------------------------------------------------------------] loss: +1.468E-02 / score: +5.890(-2/+6/+13)3)\n",
      "250/0 [------------------------------------------------------------] loss: +1.349E-02 / score: +5.910(-2/+6/+13))\n",
      "251/0 [------------------------------------------------------------] loss: +1.148E-02 / score: +5.960(-2/+8/+13))\n",
      "252/0 [------------------------------------------------------------] loss: +1.641E-02 / score: +6.000(-2/+5/+13))\n",
      "253/0 [------------------------------------------------------------] loss: +2.420E-02 / score: +5.990(-2/+5/+13))\n",
      "254/0 [------------------------------------------------------------] loss: +2.122E-02 / score: +6.030(-2/+5/+13))\n",
      "255/0 [------------------------------------------------------------] loss: +8.073E-02 / score: +6.120(-2/+8/+13))\n",
      "256/0 [------------------------------------------------------------] loss: +1.771E-02 / score: +6.140(-2/+13/+13)\n",
      "257/0 [------------------------------------------------------------] loss: +1.277E-02 / score: +6.210(-2/+9/+13)3)\n",
      "258/0 [------------------------------------------------------------] loss: +4.956E-02 / score: +6.260(-2/+9/+13))\n",
      "259/0 [------------------------------------------------------------] loss: +7.050E-02 / score: +6.310(-2/+9/+13))\n",
      "260/0 [------------------------------------------------------------] loss: +2.633E-02 / score: +6.400(-2/+14/+14)\n",
      "261/0 [------------------------------------------------------------] loss: +1.048E-02 / score: +6.450(-2/+9/+14)4)\n",
      "262/0 [------------------------------------------------------------] loss: +3.808E-02 / score: +6.520(-2/+8/+14))\n",
      "263/0 [------------------------------------------------------------] loss: +2.574E-02 / score: +6.540(-2/+8/+14))\n",
      "264/0 [------------------------------------------------------------] loss: +1.630E-02 / score: +6.560(-2/+7/+14))\n",
      "265/0 [------------------------------------------------------------] loss: +1.959E-02 / score: +6.730(-2/+15/+15)\n",
      "266/0 [------------------------------------------------------------] loss: +1.528E-02 / score: +6.790(-2/+10/+15))\n",
      "267/0 [------------------------------------------------------------] loss: +2.139E-02 / score: +6.820(-2/+7/+15)5)\n",
      "268/0 [------------------------------------------------------------] loss: +1.608E-02 / score: +6.880(-2/+10/+15)\n",
      "269/0 [------------------------------------------------------------] loss: +1.444E-02 / score: +6.950(-2/+12/+15))\n",
      "270/0 [------------------------------------------------------------] loss: +1.892E-02 / score: +7.040(-2/+13/+15))\n",
      "271/0 [------------------------------------------------------------] loss: +2.608E-02 / score: +7.070(-2/+10/+15))\n",
      "272/0 [------------------------------------------------------------] loss: +3.021E-02 / score: +7.130(-2/+6/+15)5)\n",
      "273/0 [------------------------------------------------------------] loss: +1.618E-02 / score: +7.190(-2/+7/+15))\n",
      "274/0 [------------------------------------------------------------] loss: +4.514E-02 / score: +7.290(-2/+11/+15)\n",
      "275/0 [------------------------------------------------------------] loss: +2.613E-02 / score: +7.380(-2/+11/+15))\n",
      "276/0 [------------------------------------------------------------] loss: +6.469E-02 / score: +7.450(-2/+13/+15))\n",
      "277/0 [------------------------------------------------------------] loss: +2.192E-02 / score: +7.460(-2/+8/+15)5)\n",
      "278/0 [------------------------------------------------------------] loss: +1.073E-02 / score: +7.510(-2/+8/+15))\n",
      "279/0 [------------------------------------------------------------] loss: +2.221E-02 / score: +7.570(-1/+4/+15))\n",
      "280/0 [------------------------------------------------------------] loss: +2.364E-02 / score: +7.600(-1/+7/+15))\n",
      "281/0 [------------------------------------------------------------] loss: +1.349E-02 / score: +7.670(-1/+13/+15)\n",
      "282/0 [------------------------------------------------------------] loss: +5.698E-02 / score: +7.770(+1/+9/+15)5)\n",
      "283/0 [------------------------------------------------------------] loss: +3.129E-02 / score: +7.840(+1/+12/+15)\n",
      "284/0 [------------------------------------------------------------] loss: +1.700E-02 / score: +7.890(+1/+9/+15)5)\n",
      "285/0 [------------------------------------------------------------] loss: +1.627E-02 / score: +7.910(+1/+9/+15))\n",
      "286/0 [------------------------------------------------------------] loss: +2.454E-01 / score: +7.980(+1/+12/+15)\n",
      "287/0 [------------------------------------------------------------] loss: +2.611E-02 / score: +8.040(+1/+11/+15))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/0 [------------------------------------------------------------] loss: +1.756E-02 / score: +8.070(+1/+9/+15)5)\n",
      "289/0 [------------------------------------------------------------] loss: +1.153E-01 / score: +8.060(+1/+8/+15))\n",
      "290/0 [------------------------------------------------------------] loss: +5.122E-02 / score: +8.160(+1/+16/+16)\n",
      "291/0 [------------------------------------------------------------] loss: +1.418E-01 / score: +8.240(+1/+10/+16))\n",
      "292/0 [------------------------------------------------------------] loss: +1.529E-02 / score: +8.290(+1/+9/+16)6)\n",
      "293/0 [------------------------------------------------------------] loss: +1.064E-02 / score: +8.420(+3/+14/+16)\n",
      "294/0 [------------------------------------------------------------] loss: +1.756E-02 / score: +8.460(+3/+9/+16)6)\n",
      "295/0 [------------------------------------------------------------] loss: +3.290E-02 / score: +8.500(+3/+8/+16))\n",
      "296/0 [------------------------------------------------------------] loss: +3.094E-02 / score: +8.570(+3/+13/+16)\n",
      "297/0 [------------------------------------------------------------] loss: +1.153E-02 / score: +8.550(+3/+9/+16)6)\n",
      "298/0 [------------------------------------------------------------] loss: +2.130E-01 / score: +8.560(+3/+5/+16))\n",
      "299/0 [------------------------------------------------------------] loss: +3.142E-02 / score: +8.660(+3/+16/+16)\n",
      "300/0 [------------------------------------------------------------] loss: +1.760E-02 / score: +8.650(+3/+10/+16))\n",
      "301/0 [------------------------------------------------------------] loss: +2.423E-02 / score: +8.730(+3/+13/+16))\n",
      "302/0 [------------------------------------------------------------] loss: +1.558E-02 / score: +8.750(+3/+8/+16)6)\n",
      "303/0 [------------------------------------------------------------] loss: +1.642E-01 / score: +8.870(+4/+15/+16)\n",
      "304/0 [------------------------------------------------------------] loss: +2.367E-02 / score: +8.920(+4/+9/+16)6)\n",
      "305/0 [------------------------------------------------------------] loss: +1.673E-02 / score: +8.920(+4/+10/+16)\n",
      "306/0 [------------------------------------------------------------] loss: +1.059E-01 / score: +8.920(+4/+9/+16)6)\n",
      "307/0 [------------------------------------------------------------] loss: +2.129E-02 / score: +8.950(+4/+13/+16)\n",
      "308/0 [------------------------------------------------------------] loss: +9.642E-03 / score: +9.020(+4/+13/+16))\n",
      "309/0 [------------------------------------------------------------] loss: +4.421E-02 / score: +9.040(+4/+8/+16)6)\n",
      "310/0 [------------------------------------------------------------] loss: +3.945E-02 / score: +9.100(+4/+12/+16)\n",
      "311/0 [------------------------------------------------------------] loss: +1.189E-01 / score: +9.060(+4/+6/+16)6)\n",
      "312/0 [------------------------------------------------------------] loss: +1.992E-02 / score: +9.140(+4/+14/+16)\n",
      "313/0 [------------------------------------------------------------] loss: +3.270E-02 / score: +9.100(+4/+9/+16)6)\n",
      "314/0 [------------------------------------------------------------] loss: +2.175E-02 / score: +9.190(+4/+15/+16)\n",
      "315/0 [------------------------------------------------------------] loss: +4.592E-02 / score: +9.160(+4/+6/+16)6)\n",
      "316/0 [------------------------------------------------------------] loss: +2.867E-02 / score: +9.160(+4/+12/+16)\n",
      "317/0 [------------------------------------------------------------] loss: +1.092E-01 / score: +9.250(+4/+15/+16))\n",
      "318/0 [------------------------------------------------------------] loss: +2.125E-02 / score: +9.320(+4/+13/+16))\n",
      "319/0 [------------------------------------------------------------] loss: +4.620E-02 / score: +9.350(+4/+11/+16))\n",
      "320/0 [------------------------------------------------------------] loss: +1.385E-01 / score: +9.470(+4/+17/+17))\n",
      "321/0 [------------------------------------------------------------] loss: +1.401E-02 / score: +9.530(+4/+15/+17))\n",
      "322/0 [------------------------------------------------------------] loss: +2.287E-02 / score: +9.650(+4/+16/+17))\n",
      "323/0 [------------------------------------------------------------] loss: +3.311E-02 / score: +9.630(+4/+9/+17)7)\n",
      "324/0 [------------------------------------------------------------] loss: +8.472E-03 / score: +9.630(+4/+6/+17))\n",
      "325/0 [------------------------------------------------------------] loss: +2.999E-02 / score: +9.720(+4/+15/+17)\n",
      "326/0 [------------------------------------------------------------] loss: +9.788E-02 / score: +9.790(+4/+12/+17))\n",
      "327/0 [------------------------------------------------------------] loss: +1.698E-02 / score: +9.820(+4/+12/+17))\n",
      "328/0 [------------------------------------------------------------] loss: +1.792E-02 / score: +9.840(+4/+7/+17)7)\n",
      "329/0 [------------------------------------------------------------] loss: +1.378E-02 / score: +9.900(+4/+13/+17)\n",
      "330/0 [------------------------------------------------------------] loss: +2.484E-02 / score: +9.860(+3/+3/+17)7)\n",
      "331/0 [------------------------------------------------------------] loss: +3.601E-02 / score: +9.920(+3/+13/+17)\n",
      "332/0 [------------------------------------------------------------] loss: +1.826E-02 / score: +9.940(+3/+10/+17))\n",
      "333/0 [------------------------------------------------------------] loss: +9.136E-03 / score: +10.010(+3/+17/+17)\n",
      "334/0 [------------------------------------------------------------] loss: +2.250E-02 / score: +10.040(+3/+9/+17)7)\n",
      "335/0 [------------------------------------------------------------] loss: +2.426E-02 / score: +10.050(+3/+12/+17)\n",
      "336/0 [------------------------------------------------------------] loss: +1.795E-02 / score: +10.100(+3/+15/+17))\n",
      "337/0 [------------------------------------------------------------] loss: +2.599E-02 / score: +10.100(+3/+7/+17)7)\n",
      "338/0 [------------------------------------------------------------] loss: +1.188E-02 / score: +10.140(+3/+12/+17)\n",
      "339/0 [------------------------------------------------------------] loss: +1.803E-02 / score: +10.230(+3/+14/+17))\n",
      "340/0 [------------------------------------------------------------] loss: +1.678E-02 / score: +10.270(+3/+12/+17))\n",
      "341/0 [------------------------------------------------------------] loss: +1.629E-02 / score: +10.270(+3/+10/+17))\n",
      "342/0 [------------------------------------------------------------] loss: +1.344E-02 / score: +10.230(+3/+8/+17)7)\n",
      "343/0 [------------------------------------------------------------] loss: +1.551E-02 / score: +10.300(+3/+12/+17)\n",
      "344/0 [------------------------------------------------------------] loss: +2.712E-02 / score: +10.340(+3/+10/+17))\n",
      "345/0 [------------------------------------------------------------] loss: +2.057E-02 / score: +10.350(+3/+13/+17))\n",
      "346/0 [------------------------------------------------------------] loss: +2.297E-02 / score: +10.320(+3/+6/+17)7)\n",
      "347/0 [------------------------------------------------------------] loss: +1.540E-02 / score: +10.300(+3/+9/+17))\n",
      "348/0 [------------------------------------------------------------] loss: +1.885E-02 / score: +10.300(+3/+13/+17)\n",
      "349/0 [------------------------------------------------------------] loss: +2.581E-02 / score: +10.330(+3/+9/+17)7)\n",
      "350/0 [------------------------------------------------------------] loss: +1.794E-02 / score: +10.380(+3/+11/+17)\n",
      "351/0 [------------------------------------------------------------] loss: +2.831E-02 / score: +10.360(+3/+6/+17)7)\n",
      "352/0 [------------------------------------------------------------] loss: +1.079E-01 / score: +10.430(+3/+12/+17)\n",
      "353/0 [------------------------------------------------------------] loss: +1.114E-02 / score: +10.520(+3/+14/+17))\n",
      "354/0 [------------------------------------------------------------] loss: +2.088E-01 / score: +10.590(+3/+12/+17))\n",
      "355/0 [------------------------------------------------------------] loss: +1.766E-01 / score: +10.630(+3/+12/+17))\n",
      "356/0 [------------------------------------------------------------] loss: +8.057E-03 / score: +10.590(+3/+9/+17)7)\n",
      "357/0 [------------------------------------------------------------] loss: +3.174E-02 / score: +10.650(+3/+15/+17)\n",
      "358/0 [------------------------------------------------------------] loss: +1.582E-02 / score: +10.670(+3/+11/+17))\n",
      "359/0 [------------------------------------------------------------] loss: +1.981E-02 / score: +10.660(+3/+8/+17)7)\n",
      "360/0 [------------------------------------------------------------] loss: +1.702E-02 / score: +10.660(+3/+14/+17)\n",
      "361/0 [------------------------------------------------------------] loss: +2.119E-02 / score: +10.650(+3/+8/+17)7)\n",
      "362/0 [------------------------------------------------------------] loss: +1.159E-01 / score: +10.730(+3/+16/+17)\n",
      "363/0 [------------------------------------------------------------] loss: +3.612E-02 / score: +10.800(+3/+15/+17))\n",
      "364/0 [------------------------------------------------------------] loss: +2.172E-01 / score: +10.880(+3/+15/+17))\n",
      "365/0 [------------------------------------------------------------] loss: +2.012E-02 / score: +10.870(+3/+14/+17))\n",
      "366/0 [------------------------------------------------------------] loss: +3.218E-02 / score: +10.980(+3/+21/+21))\n",
      "367/0 [------------------------------------------------------------] loss: +1.787E-01 / score: +11.010(+3/+10/+21))\n",
      "368/0 [------------------------------------------------------------] loss: +2.100E-02 / score: +10.980(+3/+7/+21)1)\n",
      "369/0 [------------------------------------------------------------] loss: +1.442E-02 / score: +10.980(+3/+12/+21)\n",
      "370/0 [------------------------------------------------------------] loss: +1.807E-02 / score: +11.000(+3/+15/+21))\n",
      "371/0 [------------------------------------------------------------] loss: +3.084E-02 / score: +11.010(+3/+11/+21))\n",
      "372/0 [------------------------------------------------------------] loss: +3.059E-02 / score: +11.080(+3/+13/+21))\n",
      "373/0 [------------------------------------------------------------] loss: +3.121E-02 / score: +11.060(+3/+5/+21)1)\n",
      "374/0 [------------------------------------------------------------] loss: +2.399E-02 / score: +11.080(+3/+13/+21)\n",
      "375/0 [------------------------------------------------------------] loss: +1.176E-01 / score: +11.090(+3/+12/+21))\n",
      "376/0 [------------------------------------------------------------] loss: +1.085E-01 / score: +11.050(+3/+9/+21)1)\n",
      "377/0 [------------------------------------------------------------] loss: +3.562E-02 / score: +11.130(+3/+16/+21)\n",
      "378/0 [------------------------------------------------------------] loss: +2.426E-02 / score: +11.160(+3/+11/+21))\n",
      "379/0 [------------------------------------------------------------] loss: +1.457E-02 / score: +11.260(+3/+14/+21))\n",
      "380/0 [------------------------------------------------------------] loss: +9.076E-03 / score: +11.330(+3/+14/+21))\n",
      "381/0 [------------------------------------------------------------] loss: +1.843E-02 / score: +11.300(+3/+10/+21))\n",
      "382/0 [------------------------------------------------------------] loss: +1.056E-02 / score: +11.320(+3/+11/+21))\n",
      "383/0 [------------------------------------------------------------] loss: +1.238E-01 / score: +11.320(+3/+12/+21))\n",
      "384/0 [------------------------------------------------------------] loss: +5.284E-02 / score: +11.350(+3/+12/+21))\n",
      "385/0 [------------------------------------------------------------] loss: +1.704E-02 / score: +11.420(+3/+16/+21))\n",
      "386/0 [------------------------------------------------------------] loss: +2.721E-02 / score: +11.440(+3/+14/+21))\n",
      "387/0 [------------------------------------------------------------] loss: +2.049E-02 / score: +11.430(+3/+10/+21))\n",
      "388/0 [------------------------------------------------------------] loss: +5.392E-02 / score: +11.480(+3/+14/+21))\n",
      "389/0 [------------------------------------------------------------] loss: +2.721E-02 / score: +11.580(+3/+18/+21))\n",
      "390/0 [------------------------------------------------------------] loss: +1.574E-02 / score: +11.610(+3/+19/+21))\n",
      "391/0 [------------------------------------------------------------] loss: +5.693E-02 / score: +11.640(+3/+13/+21))\n",
      "392/0 [------------------------------------------------------------] loss: +1.288E-02 / score: +11.680(+3/+13/+21))\n",
      "393/0 [------------------------------------------------------------] loss: +3.571E-02 / score: +11.700(+3/+16/+21))\n",
      "394/0 [------------------------------------------------------------] loss: +1.739E-02 / score: +11.730(+3/+12/+21))\n",
      "395/0 [------------------------------------------------------------] loss: +1.341E-01 / score: +11.700(+3/+5/+21)1)\n",
      "396/0 [------------------------------------------------------------] loss: +2.526E-02 / score: +11.640(+3/+7/+21))\n",
      "397/0 [------------------------------------------------------------] loss: +2.473E-02 / score: +11.690(+3/+14/+21)\n",
      "398/0 [------------------------------------------------------------] loss: +7.429E-03 / score: +11.810(+3/+17/+21))\n",
      "399/0 [------------------------------------------------------------] loss: +2.092E-02 / score: +11.730(+3/+8/+21)1)\n",
      "400/0 [------------------------------------------------------------] loss: +1.350E-02 / score: +11.660(+3/+3/+21))\n",
      "401/0 [------------------------------------------------------------] loss: +9.693E-03 / score: +11.630(+3/+10/+21)\n",
      "402/0 [------------------------------------------------------------] loss: +2.027E-01 / score: +11.600(+3/+5/+21)1)\n",
      "403/0 [------------------------------------------------------------] loss: +3.298E-02 / score: +11.640(+3/+19/+21)\n",
      "404/0 [------------------------------------------------------------] loss: +2.869E-02 / score: +11.690(+3/+14/+21))\n",
      "405/0 [------------------------------------------------------------] loss: +1.916E-02 / score: +11.720(+3/+13/+21))\n",
      "406/0 [------------------------------------------------------------] loss: +2.326E-02 / score: +11.790(+3/+16/+21))\n",
      "407/0 [------------------------------------------------------------] loss: +4.232E-02 / score: +11.770(+3/+11/+21))\n",
      "408/0 [------------------------------------------------------------] loss: +1.254E-02 / score: +11.810(+3/+17/+21))\n",
      "409/0 [------------------------------------------------------------] loss: +1.027E-02 / score: +11.850(+3/+12/+21))\n",
      "410/0 [------------------------------------------------------------] loss: +2.484E-02 / score: +11.840(+3/+11/+21))\n",
      "411/0 [------------------------------------------------------------] loss: +5.613E-02 / score: +11.900(+3/+12/+21))\n",
      "412/0 [------------------------------------------------------------] loss: +1.754E-02 / score: +11.920(+3/+16/+21))\n",
      "413/0 [------------------------------------------------------------] loss: +1.179E-01 / score: +11.950(+3/+12/+21))\n",
      "414/0 [------------------------------------------------------------] loss: +2.212E-02 / score: +11.920(+3/+12/+21))\n",
      "415/0 [------------------------------------------------------------] loss: +2.422E-02 / score: +11.990(+3/+13/+21))\n",
      "416/0 [------------------------------------------------------------] loss: +3.405E-02 / score: +12.010(+3/+14/+21))\n",
      "417/0 [------------------------------------------------------------] loss: +2.496E-02 / score: +11.960(+3/+10/+21))\n",
      "418/0 [------------------------------------------------------------] loss: +1.805E-01 / score: +11.930(+3/+10/+21))\n",
      "419/0 [------------------------------------------------------------] loss: +1.586E-01 / score: +11.980(+3/+16/+21))\n",
      "420/0 [------------------------------------------------------------] loss: +1.359E-02 / score: +11.950(+3/+14/+21))\n",
      "421/0 [------------------------------------------------------------] loss: +2.689E-02 / score: +11.920(+3/+12/+21))\n",
      "422/0 [------------------------------------------------------------] loss: +3.603E-01 / score: +11.850(+3/+9/+21)1)\n",
      "423/0 [------------------------------------------------------------] loss: +2.591E-01 / score: +11.850(+3/+9/+21))\n",
      "424/0 [------------------------------------------------------------] loss: +1.440E-01 / score: +11.910(+3/+12/+21)\n",
      "425/0 [------------------------------------------------------------] loss: +1.424E-02 / score: +11.840(+3/+8/+21)1)\n",
      "426/0 [------------------------------------------------------------] loss: +1.365E-01 / score: +11.860(+3/+14/+21)\n",
      "427/0 [------------------------------------------------------------] loss: +2.107E-02 / score: +11.850(+3/+11/+21))\n",
      "428/0 [------------------------------------------------------------] loss: +2.394E-02 / score: +11.900(+3/+12/+21))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/0 [------------------------------------------------------------] loss: +1.973E-02 / score: +11.900(+3/+13/+21))\n",
      "430/0 [------------------------------------------------------------] loss: +1.632E-02 / score: +12.000(+3/+13/+21))\n",
      "431/0 [------------------------------------------------------------] loss: +1.749E-02 / score: +12.010(+3/+14/+21))\n",
      "432/0 [------------------------------------------------------------] loss: +1.740E-02 / score: +12.080(+3/+17/+21))\n",
      "433/0 [------------------------------------------------------------] loss: +1.579E-02 / score: +12.060(+3/+15/+21))\n",
      "434/0 [------------------------------------------------------------] loss: +3.038E-02 / score: +12.100(+3/+13/+21))\n",
      "435/0 [------------------------------------------------------------] loss: +1.857E-02 / score: +12.080(+3/+10/+21))\n",
      "436/0 [------------------------------------------------------------] loss: +1.709E-02 / score: +12.120(+3/+19/+21))\n",
      "437/0 [------------------------------------------------------------] loss: +2.203E-02 / score: +12.180(+3/+13/+21))\n",
      "438/0 [------------------------------------------------------------] loss: +1.599E-02 / score: +12.190(+3/+13/+21))\n",
      "439/0 [------------------------------------------------------------] loss: +1.927E-02 / score: +12.200(+3/+15/+21))\n",
      "440/0 [------------------------------------------------------------] loss: +1.943E-02 / score: +12.220(+3/+14/+21))\n",
      "441/0 [------------------------------------------------------------] loss: +3.683E-02 / score: +12.280(+3/+16/+21))\n",
      "442/0 [------------------------------------------------------------] loss: +2.679E-02 / score: +12.330(+3/+13/+21))\n",
      "443/0 [------------------------------------------------------------] loss: +2.293E-01 / score: +12.360(+3/+15/+21))\n",
      "444/0 [------------------------------------------------------------] loss: +1.954E-01 / score: +12.430(+3/+17/+21))\n",
      "445/0 [------------------------------------------------------------] loss: +2.345E-02 / score: +12.430(+3/+13/+21))\n",
      "446/0 [------------------------------------------------------------] loss: +1.487E-01 / score: +12.490(+3/+12/+21))\n",
      "447/0 [------------------------------------------------------------] loss: +1.770E-02 / score: +12.550(+3/+15/+21))\n",
      "448/0 [------------------------------------------------------------] loss: +2.507E-01 / score: +12.450(+3/+3/+21)1)\n",
      "449/0 [------------------------------------------------------------] loss: +3.712E-02 / score: +12.520(+3/+16/+21)\n",
      "450/0 [------------------------------------------------------------] loss: +5.843E-02 / score: +12.580(+3/+17/+21))\n",
      "451/0 [------------------------------------------------------------] loss: +8.782E-03 / score: +12.680(+3/+16/+21))\n",
      "452/0 [------------------------------------------------------------] loss: +2.234E-02 / score: +12.710(+3/+15/+21))\n",
      "453/0 [------------------------------------------------------------] loss: +1.712E-02 / score: +12.650(+3/+8/+21)1)\n",
      "454/0 [------------------------------------------------------------] loss: +3.918E-02 / score: +12.660(+3/+13/+21)\n",
      "455/0 [------------------------------------------------------------] loss: +1.810E-02 / score: +12.660(+3/+12/+21))\n",
      "456/0 [------------------------------------------------------------] loss: +2.473E-02 / score: +12.680(+3/+11/+21))\n",
      "457/0 [------------------------------------------------------------] loss: +9.582E-03 / score: +12.680(+3/+15/+21))\n",
      "458/0 [------------------------------------------------------------] loss: +9.923E-03 / score: +12.770(+3/+20/+21))\n",
      "459/0 [------------------------------------------------------------] loss: +3.276E-02 / score: +12.870(+3/+18/+21))\n",
      "460/0 [------------------------------------------------------------] loss: +2.319E-01 / score: +12.870(+3/+14/+21))\n",
      "461/0 [------------------------------------------------------------] loss: +3.504E-02 / score: +12.940(+3/+15/+21))\n",
      "462/0 [------------------------------------------------------------] loss: +1.267E-02 / score: +12.930(+3/+15/+21))\n",
      "463/0 [------------------------------------------------------------] loss: +7.416E-03 / score: +12.970(+3/+19/+21))\n",
      "464/0 [------------------------------------------------------------] loss: +3.459E-02 / score: +12.990(+3/+17/+21))\n",
      "465/0 [------------------------------------------------------------] loss: +1.251E-02 / score: +13.010(+3/+16/+21))\n",
      "466/0 [------------------------------------------------------------] loss: +3.559E-02 / score: +12.950(+3/+15/+20))\n",
      "467/0 [------------------------------------------------------------] loss: +2.197E-02 / score: +12.970(+3/+12/+20))\n",
      "468/0 [------------------------------------------------------------] loss: +1.053E-02 / score: +13.060(+3/+16/+20))\n",
      "469/0 [------------------------------------------------------------] loss: +1.775E-01 / score: +13.060(+3/+12/+20))\n",
      "470/0 [------------------------------------------------------------] loss: +1.991E-02 / score: +13.070(+3/+16/+20))\n",
      "471/0 [------------------------------------------------------------] loss: +3.391E-02 / score: +13.080(+3/+12/+20))\n",
      "472/0 [------------------------------------------------------------] loss: +2.013E-02 / score: +13.090(+3/+14/+20))\n",
      "473/0 [------------------------------------------------------------] loss: +1.473E-02 / score: +13.210(+3/+17/+20))\n",
      "474/0 [------------------------------------------------------------] loss: +2.418E-01 / score: +13.190(+3/+11/+20))\n",
      "475/0 [------------------------------------------------------------] loss: +2.799E-01 / score: +13.220(+3/+15/+20))\n",
      "476/0 [------------------------------------------------------------] loss: +3.170E-01 / score: +13.230(+3/+10/+20))\n",
      "477/0 [------------------------------------------------------------] loss: +1.292E-01 / score: +13.220(+3/+15/+20))\n",
      "478/0 [------------------------------------------------------------] loss: +2.005E-02 / score: +13.240(+3/+13/+20))\n",
      "479/0 [------------------------------------------------------------] loss: +1.380E-02 / score: +13.190(+3/+9/+20)0)\n",
      "480/0 [------------------------------------------------------------] loss: +1.683E-02 / score: +13.190(+3/+14/+20)\n",
      "481/0 [------------------------------------------------------------] loss: +1.525E-01 / score: +13.290(+3/+20/+20))\n",
      "482/0 [------------------------------------------------------------] loss: +1.244E-02 / score: +13.310(+3/+13/+20))\n",
      "483/0 [------------------------------------------------------------] loss: +1.445E-02 / score: +13.320(+3/+13/+20))\n",
      "484/0 [------------------------------------------------------------] loss: +3.057E-02 / score: +13.340(+3/+14/+20))\n",
      "485/0 [------------------------------------------------------------] loss: +2.467E-01 / score: +13.280(+3/+10/+20))\n",
      "486/0 [------------------------------------------------------------] loss: +4.970E-02 / score: +13.260(+3/+12/+20))\n",
      "487/0 [------------------------------------------------------------] loss: +3.907E-02 / score: +13.370(+3/+21/+21))\n",
      "488/0 [------------------------------------------------------------] loss: +1.678E-02 / score: +13.430(+3/+20/+21))\n",
      "489/0 [------------------------------------------------------------] loss: +1.659E-01 / score: +13.430(+3/+18/+21))\n",
      "490/0 [------------------------------------------------------------] loss: +1.738E-02 / score: +13.350(+3/+11/+21))\n",
      "491/0 [------------------------------------------------------------] loss: +1.311E-02 / score: +13.390(+3/+17/+21))\n",
      "492/0 [------------------------------------------------------------] loss: +3.749E-02 / score: +13.350(+3/+9/+21)1)\n",
      "493/0 [------------------------------------------------------------] loss: +1.523E-01 / score: +13.360(+3/+17/+21)\n",
      "494/0 [------------------------------------------------------------] loss: +1.136E-02 / score: +13.390(+3/+15/+21))\n",
      "495/0 [------------------------------------------------------------] loss: +1.785E-02 / score: +13.520(+3/+18/+21))\n",
      "496/0 [------------------------------------------------------------] loss: +2.393E-01 / score: +13.580(+3/+13/+21))\n",
      "497/0 [------------------------------------------------------------] loss: +3.425E-02 / score: +13.560(+3/+12/+21))\n",
      "498/0 [------------------------------------------------------------] loss: +1.605E-01 / score: +13.520(+3/+13/+21))\n",
      "499/0 [------------------------------------------------------------] loss: +3.931E-01 / score: +13.630(+3/+19/+21))\n",
      "500/0 [------------------------------------------------------------] loss: +1.518E-02 / score: +13.690(+3/+9/+21)1)\n",
      "501/0 [------------------------------------------------------------] loss: +1.196E-02 / score: +13.690(+3/+10/+21)\n",
      "502/0 [------------------------------------------------------------] loss: +1.451E-02 / score: +13.800(+3/+16/+21))\n",
      "503/0 [------------------------------------------------------------] loss: +9.816E-03 / score: +13.740(+3/+13/+21))\n",
      "504/0 [------------------------------------------------------------] loss: +3.690E-02 / score: +13.750(+3/+15/+21))\n",
      "505/0 [------------------------------------------------------------] loss: +2.401E-02 / score: +13.700(+3/+8/+21)1)\n",
      "506/0 [------------------------------------------------------------] loss: +1.227E-02 / score: +13.640(+3/+10/+21)\n",
      "507/0 [------------------------------------------------------------] loss: +7.402E-03 / score: +13.640(+3/+11/+21))\n",
      "508/0 [------------------------------------------------------------] loss: +8.523E-03 / score: +13.640(+3/+17/+21))\n",
      "509/0 [------------------------------------------------------------] loss: +4.323E-02 / score: +13.630(+3/+11/+21))\n",
      "510/0 [------------------------------------------------------------] loss: +1.445E-02 / score: +13.670(+3/+15/+21))\n",
      "511/0 [------------------------------------------------------------] loss: +1.376E-02 / score: +13.720(+3/+17/+21))\n",
      "512/0 [------------------------------------------------------------] loss: +2.653E-01 / score: +13.700(+3/+14/+21))\n",
      "513/0 [------------------------------------------------------------] loss: +5.544E-02 / score: +13.710(+3/+13/+21))\n",
      "514/0 [------------------------------------------------------------] loss: +1.374E-02 / score: +13.740(+3/+15/+21))\n",
      "515/0 [------------------------------------------------------------] loss: +4.831E-02 / score: +13.770(+3/+16/+21))\n",
      "516/0 [------------------------------------------------------------] loss: +2.519E-01 / score: +13.780(+3/+15/+21))\n",
      "517/0 [------------------------------------------------------------] loss: +2.119E-02 / score: +13.790(+3/+11/+21))\n",
      "518/0 [------------------------------------------------------------] loss: +3.118E-02 / score: +13.900(+3/+21/+21))\n",
      "519/0 [------------------------------------------------------------] loss: +4.180E-02 / score: +13.860(+3/+12/+21))\n",
      "520/0 [------------------------------------------------------------] loss: +2.422E-01 / score: +13.820(+3/+10/+21))\n",
      "521/0 [------------------------------------------------------------] loss: +1.913E-02 / score: +13.730(+3/+3/+21)1)\n",
      "522/0 [------------------------------------------------------------] loss: +2.327E-01 / score: +13.780(+3/+14/+21)\n",
      "523/0 [------------------------------------------------------------] loss: +8.393E-03 / score: +13.790(+3/+10/+21))\n",
      "524/0 [------------------------------------------------------------] loss: +8.959E-03 / score: +13.850(+3/+18/+21))\n",
      "525/0 [------------------------------------------------------------] loss: +2.892E-02 / score: +13.870(+3/+10/+21))\n",
      "526/0 [------------------------------------------------------------] loss: +4.862E-02 / score: +13.900(+3/+17/+21))\n",
      "527/0 [------------------------------------------------------------] loss: +1.655E-02 / score: +13.900(+3/+11/+21))\n",
      "528/0 [------------------------------------------------------------] loss: +1.625E-01 / score: +13.920(+3/+14/+21))\n",
      "529/0 [------------------------------------------------------------] loss: +8.857E-02 / score: +13.960(+3/+17/+21))\n",
      "530/0 [------------------------------------------------------------] loss: +1.688E-01 / score: +13.960(+3/+13/+21))\n",
      "531/0 [------------------------------------------------------------] loss: +1.063E-02 / score: +13.980(+3/+16/+21))\n",
      "532/0 [------------------------------------------------------------] loss: +9.318E-03 / score: +13.960(+3/+15/+21))\n",
      "533/0 [------------------------------------------------------------] loss: +3.090E-02 / score: +13.960(+3/+15/+21))\n",
      "534/0 [------------------------------------------------------------] loss: +3.171E-02 / score: +13.950(+3/+12/+21))\n",
      "535/0 [------------------------------------------------------------] loss: +4.478E-02 / score: +13.980(+3/+13/+21))\n",
      "536/0 [------------------------------------------------------------] loss: +4.224E-02 / score: +13.910(+3/+12/+21))\n",
      "537/0 [------------------------------------------------------------] loss: +2.785E-02 / score: +13.940(+3/+16/+21))\n",
      "538/0 [------------------------------------------------------------] loss: +1.454E-02 / score: +13.980(+3/+17/+21))\n",
      "539/0 [------------------------------------------------------------] loss: +2.031E-02 / score: +14.020(+3/+19/+21))\n",
      "540/0 [------------------------------------------------------------] loss: +3.161E-01 / score: +14.020(+3/+14/+21))\n",
      "541/0 [------------------------------------------------------------] loss: +2.386E-02 / score: +14.000(+3/+14/+21))\n",
      "542/0 [------------------------------------------------------------] loss: +1.682E-02 / score: +14.050(+3/+18/+21))\n",
      "543/0 [------------------------------------------------------------] loss: +1.929E-02 / score: +13.970(+3/+7/+21)1)\n",
      "544/0 [------------------------------------------------------------] loss: +1.615E-02 / score: +13.940(+3/+14/+21)\n",
      "545/0 [------------------------------------------------------------] loss: +9.333E-03 / score: +13.960(+3/+15/+21))\n",
      "546/0 [------------------------------------------------------------] loss: +4.039E-01 / score: +14.020(+3/+18/+21))\n",
      "547/0 [------------------------------------------------------------] loss: +4.085E-02 / score: +14.000(+3/+13/+21))\n",
      "548/0 [------------------------------------------------------------] loss: +2.071E-02 / score: +14.110(+3/+14/+21))\n",
      "549/0 [------------------------------------------------------------] loss: +6.111E-03 / score: +14.150(+3/+20/+21))\n",
      "550/0 [------------------------------------------------------------] loss: +1.842E-01 / score: +14.130(+3/+15/+21))\n",
      "551/0 [------------------------------------------------------------] loss: +3.302E-02 / score: +14.070(+3/+10/+21))\n",
      "552/0 [------------------------------------------------------------] loss: +2.860E-01 / score: +14.080(+3/+16/+21))\n",
      "553/0 [------------------------------------------------------------] loss: +7.131E-03 / score: +14.090(+3/+9/+21)1)\n",
      "554/0 [------------------------------------------------------------] loss: +4.159E-02 / score: +14.100(+3/+14/+21)\n",
      "555/0 [------------------------------------------------------------] loss: +3.661E-02 / score: +14.140(+3/+16/+21))\n",
      "556/0 [------------------------------------------------------------] loss: +1.144E-02 / score: +14.200(+3/+17/+21))\n",
      "557/0 [------------------------------------------------------------] loss: +2.570E-02 / score: +14.210(+3/+16/+21))\n",
      "558/0 [------------------------------------------------------------] loss: +1.772E-02 / score: +14.120(+3/+11/+21))\n",
      "559/0 [------------------------------------------------------------] loss: +1.645E-02 / score: +14.110(+3/+17/+21))\n",
      "560/0 [------------------------------------------------------------] loss: +1.915E-02 / score: +14.130(+3/+16/+21))\n",
      "561/0 [------------------------------------------------------------] loss: +2.142E-02 / score: +14.170(+3/+19/+21))\n",
      "562/0 [------------------------------------------------------------] loss: +1.857E-01 / score: +14.200(+3/+18/+21))\n",
      "563/0 [------------------------------------------------------------] loss: +1.711E-01 / score: +14.130(+3/+12/+21))\n",
      "564/0 [------------------------------------------------------------] loss: +2.793E-01 / score: +14.170(+3/+21/+21))\n",
      "565/0 [------------------------------------------------------------] loss: +1.023E-02 / score: +14.140(+3/+13/+21))\n",
      "566/0 [------------------------------------------------------------] loss: +2.796E-02 / score: +14.130(+3/+14/+21))\n",
      "567/0 [------------------------------------------------------------] loss: +2.327E-02 / score: +14.170(+3/+16/+21))\n",
      "568/0 [------------------------------------------------------------] loss: +4.669E-03 / score: +14.100(+3/+9/+21)1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/0 [------------------------------------------------------------] loss: +2.566E-01 / score: +14.170(+3/+19/+21)\n",
      "570/0 [------------------------------------------------------------] loss: +4.968E-02 / score: +14.170(+3/+16/+21))\n",
      "571/0 [------------------------------------------------------------] loss: +1.754E-02 / score: +14.210(+3/+16/+21))\n",
      "572/0 [------------------------------------------------------------] loss: +1.629E-02 / score: +14.280(+3/+21/+21))\n",
      "573/0 [------------------------------------------------------------] loss: +2.946E-01 / score: +14.270(+3/+16/+21))\n",
      "574/0 [------------------------------------------------------------] loss: +2.797E-02 / score: +14.230(+3/+7/+21)1)\n",
      "575/0 [------------------------------------------------------------] loss: +3.131E-01 / score: +14.220(+3/+14/+21)\n",
      "576/0 [------------------------------------------------------------] loss: +4.530E-02 / score: +14.250(+3/+13/+21))\n",
      "577/0 [------------------------------------------------------------] loss: +3.745E-02 / score: +14.270(+3/+17/+21))\n",
      "578/0 [------------------------------------------------------------] loss: +1.168E-02 / score: +14.300(+3/+16/+21))\n",
      "579/0 [------------------------------------------------------------] loss: +2.099E-02 / score: +14.380(+3/+17/+21))\n",
      "580/0 [------------------------------------------------------------] loss: +4.761E-02 / score: +14.380(+3/+14/+21))\n",
      "581/0 [------------------------------------------------------------] loss: +5.305E-02 / score: +14.290(+3/+11/+21))\n",
      "582/0 [------------------------------------------------------------] loss: +2.982E-02 / score: +14.300(+3/+14/+21))\n",
      "583/0 [------------------------------------------------------------] loss: +2.798E-02 / score: +14.300(+3/+13/+21))\n",
      "584/0 [------------------------------------------------------------] loss: +2.055E-01 / score: +14.350(+3/+19/+21))\n",
      "585/0 [------------------------------------------------------------] loss: +2.788E-02 / score: +14.400(+3/+15/+21))\n",
      "586/0 [------------------------------------------------------------] loss: +2.441E-02 / score: +14.470(+3/+19/+21))\n",
      "587/0 [------------------------------------------------------------] loss: +3.134E-01 / score: +14.410(+3/+15/+21))\n",
      "588/0 [------------------------------------------------------------] loss: +3.457E-02 / score: +14.310(+3/+10/+21))\n",
      "589/0 [------------------------------------------------------------] loss: +1.744E-01 / score: +14.310(+3/+18/+21))\n",
      "590/0 [------------------------------------------------------------] loss: +3.638E-02 / score: +14.330(+3/+13/+21))\n",
      "591/0 [------------------------------------------------------------] loss: +3.143E-02 / score: +14.360(+3/+20/+21))\n",
      "592/0 [------------------------------------------------------------] loss: +4.675E-02 / score: +14.430(+3/+16/+21))\n",
      "593/0 [------------------------------------------------------------] loss: +2.249E-01 / score: +14.370(+3/+11/+21))\n",
      "594/0 [------------------------------------------------------------] loss: +2.716E-02 / score: +14.390(+3/+17/+21))\n",
      "595/0 [------------------------------------------------------------] loss: +2.411E-01 / score: +14.390(+3/+18/+21))\n",
      "596/0 [------------------------------------------------------------] loss: +1.847E-02 / score: +14.380(+3/+12/+21))\n",
      "597/0 [------------------------------------------------------------] loss: +2.772E-01 / score: +14.430(+3/+17/+21))\n",
      "598/0 [------------------------------------------------------------] loss: +2.463E-01 / score: +14.440(+3/+14/+21))\n",
      "599/0 [------------------------------------------------------------] loss: +2.665E-02 / score: +14.420(+3/+17/+21))\n",
      "600/0 [------------------------------------------------------------] loss: +1.967E-02 / score: +14.480(+3/+15/+21))\n",
      "601/0 [------------------------------------------------------------] loss: +2.039E-02 / score: +14.530(+3/+15/+21))\n",
      "602/0 [------------------------------------------------------------] loss: +3.063E-02 / score: +14.510(+3/+14/+21))\n",
      "603/0 [------------------------------------------------------------] loss: +1.376E-02 / score: +14.470(+3/+9/+21)1)\n",
      "604/0 [------------------------------------------------------------] loss: +1.780E-02 / score: +14.530(+3/+21/+21)\n",
      "605/0 [------------------------------------------------------------] loss: +4.796E-02 / score: +14.610(+3/+16/+21))\n",
      "606/0 [------------------------------------------------------------] loss: +5.942E-02 / score: +14.680(+3/+17/+21))\n",
      "607/0 [------------------------------------------------------------] loss: +4.140E-02 / score: +14.670(+3/+10/+21))\n",
      "608/0 [------------------------------------------------------------] loss: +1.680E-02 / score: +14.750(+3/+25/+25))\n",
      "609/0 [------------------------------------------------------------] loss: +1.723E-02 / score: +14.770(+3/+13/+25))\n",
      "610/0 [------------------------------------------------------------] loss: +3.413E-02 / score: +14.830(+3/+21/+25))\n",
      "611/0 [------------------------------------------------------------] loss: +2.459E-01 / score: +14.850(+3/+19/+25))\n",
      "612/0 [------------------------------------------------------------] loss: +2.755E-01 / score: +14.910(+3/+20/+25))\n",
      "613/0 [------------------------------------------------------------] loss: +1.331E-02 / score: +14.960(+3/+18/+25))\n",
      "614/0 [------------------------------------------------------------] loss: +1.180E-02 / score: +14.940(+3/+13/+25))\n",
      "615/0 [------------------------------------------------------------] loss: +9.544E-03 / score: +14.900(+3/+12/+25))\n",
      "616/0 [------------------------------------------------------------] loss: +2.583E-01 / score: +14.880(+3/+13/+25))\n",
      "617/0 [------------------------------------------------------------] loss: +1.820E-01 / score: +14.930(+3/+16/+25))\n",
      "618/0 [------------------------------------------------------------] loss: +3.632E-01 / score: +14.900(+3/+18/+25))\n",
      "619/0 [------------------------------------------------------------] loss: +2.808E-02 / score: +14.900(+3/+12/+25))\n",
      "620/0 [------------------------------------------------------------] loss: +1.209E-02 / score: +14.940(+3/+14/+25))\n",
      "621/0 [------------------------------------------------------------] loss: +4.755E-02 / score: +15.060(+7/+15/+25))\n",
      "622/0 [------------------------------------------------------------] loss: +2.943E-02 / score: +15.090(+7/+17/+25))\n",
      "623/0 [------------------------------------------------------------] loss: +1.917E-02 / score: +15.120(+7/+13/+25))\n",
      "624/0 [------------------------------------------------------------] loss: +3.314E-02 / score: +15.100(+7/+16/+25))\n",
      "625/0 [------------------------------------------------------------] loss: +1.273E-02 / score: +15.160(+7/+16/+25))\n",
      "626/0 [------------------------------------------------------------] loss: +1.806E-02 / score: +15.150(+7/+16/+25))\n",
      "627/0 [------------------------------------------------------------] loss: +1.881E-02 / score: +15.220(+7/+18/+25))\n",
      "628/0 [------------------------------------------------------------] loss: +2.194E-02 / score: +15.240(+7/+16/+25))\n",
      "629/0 [------------------------------------------------------------] loss: +3.497E-01 / score: +15.220(+7/+15/+25))\n",
      "630/0 [------------------------------------------------------------] loss: +2.743E-02 / score: +15.270(+7/+18/+25))\n",
      "631/0 [------------------------------------------------------------] loss: +2.088E-01 / score: +15.240(+7/+13/+25))\n",
      "632/0 [------------------------------------------------------------] loss: +2.766E-02 / score: +15.230(+7/+14/+25))\n",
      "633/0 [------------------------------------------------------------] loss: +4.872E-02 / score: +15.210(+7/+13/+25))\n",
      "634/0 [------------------------------------------------------------] loss: +1.720E-02 / score: +15.240(+7/+15/+25))\n",
      "635/0 [------------------------------------------------------------] loss: +2.427E-01 / score: +15.250(+7/+14/+25))\n",
      "636/0 [------------------------------------------------------------] loss: +3.058E-02 / score: +15.280(+7/+15/+25))\n",
      "637/0 [------------------------------------------------------------] loss: +3.522E-02 / score: +15.310(+7/+19/+25))\n",
      "638/0 [------------------------------------------------------------] loss: +3.055E-02 / score: +15.290(+7/+15/+25))\n",
      "639/0 [------------------------------------------------------------] loss: +3.019E-02 / score: +15.240(+7/+14/+25))\n",
      "640/0 [------------------------------------------------------------] loss: +3.770E-02 / score: +15.270(+7/+17/+25))\n",
      "641/0 [------------------------------------------------------------] loss: +1.918E-02 / score: +15.280(+7/+15/+25))\n",
      "642/0 [------------------------------------------------------------] loss: +2.078E-02 / score: +15.250(+7/+15/+25))\n",
      "643/0 [------------------------------------------------------------] loss: +3.656E-02 / score: +15.330(+7/+15/+25))\n",
      "644/0 [------------------------------------------------------------] loss: +2.550E-01 / score: +15.230(+4/+4/+25)5)\n",
      "645/0 [------------------------------------------------------------] loss: +7.669E-03 / score: +15.230(+4/+15/+25)\n",
      "646/0 [------------------------------------------------------------] loss: +3.473E-01 / score: +15.170(+4/+12/+25))\n",
      "647/0 [------------------------------------------------------------] loss: +4.160E-02 / score: +15.200(+4/+16/+25))\n",
      "648/0 [------------------------------------------------------------] loss: +1.702E-02 / score: +15.180(+4/+12/+25))\n",
      "649/0 [------------------------------------------------------------] loss: +2.744E-02 / score: +15.150(+4/+17/+25))\n",
      "650/0 [------------------------------------------------------------] loss: +2.321E-02 / score: +15.140(+4/+14/+25))\n",
      "651/0 [------------------------------------------------------------] loss: +1.574E-02 / score: +15.170(+4/+13/+25))\n",
      "652/0 [------------------------------------------------------------] loss: +1.324E-02 / score: +15.150(+4/+14/+25))\n",
      "653/0 [------------------------------------------------------------] loss: +3.007E-02 / score: +15.220(+4/+16/+25))\n",
      "654/0 [------------------------------------------------------------] loss: +2.083E-02 / score: +15.220(+4/+14/+25))\n",
      "655/0 [------------------------------------------------------------] loss: +3.339E-02 / score: +15.190(+4/+13/+25))\n",
      "656/0 [------------------------------------------------------------] loss: +1.148E-02 / score: +15.160(+4/+14/+25))\n",
      "657/0 [------------------------------------------------------------] loss: +2.810E-01 / score: +15.130(+4/+13/+25))\n",
      "658/0 [------------------------------------------------------------] loss: +2.009E-02 / score: +15.170(+4/+15/+25))\n",
      "659/0 [------------------------------------------------------------] loss: +3.914E-02 / score: +15.090(+4/+9/+25)5)\n",
      "660/0 [------------------------------------------------------------] loss: +2.271E-02 / score: +15.070(+4/+14/+25)\n",
      "661/0 [------------------------------------------------------------] loss: +4.060E-01 / score: +15.060(+4/+18/+25))\n",
      "662/0 [------------------------------------------------------------] loss: +2.494E-02 / score: +15.000(+4/+12/+25))\n",
      "663/0 [------------------------------------------------------------] loss: +3.525E-02 / score: +15.060(+4/+18/+25))\n",
      "664/0 [------------------------------------------------------------] loss: +1.658E-02 / score: +15.020(+4/+17/+25))\n",
      "665/0 [------------------------------------------------------------] loss: +1.453E-02 / score: +14.950(+4/+6/+25)5)\n",
      "666/0 [------------------------------------------------------------] loss: +3.706E-02 / score: +14.970(+4/+16/+25)\n",
      "667/0 [------------------------------------------------------------] loss: +1.977E-01 / score: +14.910(+4/+10/+25))\n",
      "668/0 [------------------------------------------------------------] loss: +4.294E-02 / score: +15.010(+4/+19/+25))\n",
      "669/0 [------------------------------------------------------------] loss: +2.098E-02 / score: +14.980(+4/+16/+25))\n",
      "670/0 [------------------------------------------------------------] loss: +1.004E-02 / score: +14.980(+4/+16/+25))\n",
      "671/0 [------------------------------------------------------------] loss: +4.060E-01 / score: +14.990(+4/+17/+25))\n",
      "672/0 [------------------------------------------------------------] loss: +1.185E-02 / score: +14.920(+4/+14/+25))\n",
      "673/0 [------------------------------------------------------------] loss: +1.499E-02 / score: +14.910(+4/+15/+25))\n",
      "674/0 [------------------------------------------------------------] loss: +2.244E-02 / score: +15.060(+4/+22/+25))\n",
      "675/0 [------------------------------------------------------------] loss: +2.540E-02 / score: +15.110(+4/+19/+25))\n",
      "676/0 [------------------------------------------------------------] loss: +1.453E-02 / score: +15.170(+4/+19/+25))\n",
      "677/0 [------------------------------------------------------------] loss: +3.281E-01 / score: +15.170(+4/+17/+25))\n",
      "678/0 [------------------------------------------------------------] loss: +2.546E-02 / score: +15.200(+4/+19/+25))\n",
      "679/0 [------------------------------------------------------------] loss: +1.413E-02 / score: +15.190(+4/+16/+25))\n",
      "680/0 [------------------------------------------------------------] loss: +5.181E-01 / score: +15.220(+4/+17/+25))\n",
      "681/0 [------------------------------------------------------------] loss: +1.580E-02 / score: +15.240(+4/+13/+25))\n",
      "682/0 [------------------------------------------------------------] loss: +1.964E-01 / score: +15.240(+4/+14/+25))\n",
      "683/0 [------------------------------------------------------------] loss: +3.131E-01 / score: +15.250(+4/+14/+25))\n",
      "684/0 [------------------------------------------------------------] loss: +4.166E-02 / score: +15.160(+4/+10/+25))\n",
      "685/0 [------------------------------------------------------------] loss: +1.386E-02 / score: +15.180(+4/+17/+25))\n",
      "686/0 [------------------------------------------------------------] loss: +1.651E-02 / score: +15.140(+4/+15/+25))\n",
      "687/0 [------------------------------------------------------------] loss: +1.592E-02 / score: +15.170(+4/+18/+25))\n",
      "688/0 [------------------------------------------------------------] loss: +3.383E-02 / score: +15.220(+4/+15/+25))\n",
      "689/0 [------------------------------------------------------------] loss: +2.555E-01 / score: +15.140(+4/+10/+25))\n",
      "690/0 [------------------------------------------------------------] loss: +4.174E-02 / score: +15.190(+4/+18/+25))\n",
      "691/0 [------------------------------------------------------------] loss: +4.408E-02 / score: +15.150(+4/+16/+25))\n",
      "692/0 [------------------------------------------------------------] loss: +3.364E-02 / score: +15.150(+4/+16/+25))\n",
      "693/0 [------------------------------------------------------------] loss: +5.636E-03 / score: +15.210(+4/+17/+25))\n",
      "694/0 [------------------------------------------------------------] loss: +5.398E-01 / score: +15.230(+4/+19/+25))\n",
      "695/0 [------------------------------------------------------------] loss: +1.254E-02 / score: +15.270(+4/+22/+25))\n",
      "696/0 [------------------------------------------------------------] loss: +5.696E-02 / score: +15.300(+4/+15/+25))\n",
      "697/0 [------------------------------------------------------------] loss: +2.033E-02 / score: +15.260(+4/+13/+25))\n",
      "698/0 [------------------------------------------------------------] loss: +3.862E-02 / score: +15.150(+3/+3/+25)5)\n",
      "699/0 [------------------------------------------------------------] loss: +2.649E-02 / score: +15.130(+3/+15/+25)\n",
      "700/0 [------------------------------------------------------------] loss: +3.043E-02 / score: +15.100(+3/+12/+25))\n",
      "701/0 [------------------------------------------------------------] loss: +2.844E-01 / score: +15.140(+3/+19/+25))\n",
      "702/0 [------------------------------------------------------------] loss: +3.316E-02 / score: +15.180(+3/+18/+25))\n",
      "703/0 [------------------------------------------------------------] loss: +1.559E-02 / score: +15.200(+3/+11/+25))\n",
      "704/0 [------------------------------------------------------------] loss: +3.916E-02 / score: +15.180(+3/+19/+25))\n",
      "705/0 [------------------------------------------------------------] loss: +4.100E-02 / score: +15.180(+3/+16/+25))\n",
      "706/0 [------------------------------------------------------------] loss: +1.814E-02 / score: +15.180(+3/+17/+25))\n",
      "707/0 [------------------------------------------------------------] loss: +3.292E-02 / score: +15.290(+3/+21/+25))\n",
      "708/0 [------------------------------------------------------------] loss: +2.831E-02 / score: +15.240(+3/+20/+22))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709/0 [------------------------------------------------------------] loss: +2.809E-02 / score: +15.230(+3/+12/+22))\n",
      "710/0 [------------------------------------------------------------] loss: +7.119E-02 / score: +15.140(+3/+12/+22))\n",
      "711/0 [------------------------------------------------------------] loss: +2.934E-02 / score: +15.080(+3/+13/+22))\n",
      "712/0 [------------------------------------------------------------] loss: +3.675E-02 / score: +14.960(+3/+8/+22)2)\n",
      "713/0 [------------------------------------------------------------] loss: +2.262E-02 / score: +14.840(+3/+6/+22))\n",
      "714/0 [------------------------------------------------------------] loss: +2.463E-02 / score: +14.900(+3/+19/+22)\n",
      "715/0 [------------------------------------------------------------] loss: +5.747E-02 / score: +14.960(+3/+18/+22))\n",
      "716/0 [------------------------------------------------------------] loss: +2.895E-01 / score: +14.930(+3/+10/+22))\n",
      "717/0 [------------------------------------------------------------] loss: +1.212E-02 / score: +14.950(+3/+18/+22))\n",
      "718/0 [------------------------------------------------------------] loss: +3.588E-02 / score: +14.860(+3/+9/+22)2)\n",
      "719/0 [------------------------------------------------------------] loss: +1.501E-02 / score: +14.900(+3/+16/+22)\n",
      "720/0 [------------------------------------------------------------] loss: +2.284E-02 / score: +14.950(+3/+19/+22))\n",
      "721/0 [------------------------------------------------------------] loss: +3.098E-01 / score: +14.920(+3/+12/+22))\n",
      "722/0 [------------------------------------------------------------] loss: +3.274E-01 / score: +14.880(+3/+13/+22))\n",
      "723/0 [------------------------------------------------------------] loss: +2.822E-02 / score: +14.880(+3/+13/+22))\n",
      "724/0 [------------------------------------------------------------] loss: +1.501E-02 / score: +14.850(+3/+13/+22))\n",
      "725/0 [------------------------------------------------------------] loss: +3.315E-02 / score: +14.780(+3/+9/+22)2)\n",
      "726/0 [------------------------------------------------------------] loss: +1.520E-02 / score: +14.780(+3/+16/+22)\n",
      "727/0 [------------------------------------------------------------] loss: +4.520E-02 / score: +14.750(+3/+15/+22))\n",
      "728/0 [------------------------------------------------------------] loss: +3.583E-01 / score: +14.740(+3/+15/+22))\n",
      "729/0 [------------------------------------------------------------] loss: +1.590E-02 / score: +14.730(+3/+14/+22))\n",
      "730/0 [------------------------------------------------------------] loss: +1.946E-02 / score: +14.690(+3/+14/+22))\n",
      "731/0 [------------------------------------------------------------] loss: +2.352E-02 / score: +14.720(+3/+16/+22))\n",
      "732/0 [------------------------------------------------------------] loss: +1.250E-02 / score: +14.750(+3/+17/+22))\n",
      "733/0 [------------------------------------------------------------] loss: +2.008E-02 / score: +14.770(+3/+15/+22))\n",
      "734/0 [------------------------------------------------------------] loss: +3.035E-02 / score: +14.790(+3/+17/+22))\n",
      "735/0 [------------------------------------------------------------] loss: +2.477E-02 / score: +14.810(+3/+16/+22))\n",
      "736/0 [------------------------------------------------------------] loss: +7.033E-03 / score: +14.790(+3/+13/+22))\n",
      "737/0 [------------------------------------------------------------] loss: +3.549E-02 / score: +14.740(+3/+14/+22))\n",
      "738/0 [------------------------------------------------------------] loss: +3.302E-02 / score: +14.760(+3/+17/+22))\n",
      "739/0 [------------------------------------------------------------] loss: +3.226E-02 / score: +14.820(+3/+20/+22))\n",
      "740/0 [------------------------------------------------------------] loss: +2.385E-02 / score: +14.800(+3/+15/+22))\n",
      "741/0 [------------------------------------------------------------] loss: +1.212E-02 / score: +14.820(+3/+17/+22))\n",
      "742/0 [------------------------------------------------------------] loss: +1.613E-02 / score: +14.850(+3/+18/+22))\n",
      "743/0 [------------------------------------------------------------] loss: +1.472E-02 / score: +14.870(+3/+17/+22))\n",
      "744/0 [------------------------------------------------------------] loss: +1.704E-02 / score: +15.020(+3/+19/+22))\n",
      "745/0 [------------------------------------------------------------] loss: +6.979E-03 / score: +15.040(+3/+17/+22))\n",
      "746/0 [------------------------------------------------------------] loss: +1.761E-02 / score: +15.110(+3/+19/+22))\n",
      "747/0 [------------------------------------------------------------] loss: +5.217E-02 / score: +15.100(+3/+15/+22))\n",
      "748/0 [------------------------------------------------------------] loss: +1.793E-02 / score: +15.220(+3/+24/+24))\n",
      "749/0 [------------------------------------------------------------] loss: +9.984E-03 / score: +15.200(+3/+15/+24))\n",
      "750/0 [------------------------------------------------------------] loss: +3.544E-02 / score: +15.220(+3/+16/+24))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from banananav.util import print_progress, plot\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "env.terminate()\n",
    "\n",
    "## Select DeepQLearner or DoubleDeepQLearner here, using\n",
    "## BananaQModel or SimpleBananaQModel\n",
    "learner = DeepQLearner(env=env, model=BananaQModel)\n",
    "\n",
    "scores = ()\n",
    "losses = ()\n",
    "\n",
    "episode_cnt = 0\n",
    "episode_step = 0\n",
    "for cnt, data in enumerate(learner.train(750)):\n",
    "    episode_step += 1\n",
    "    loss, score, terminal = data\n",
    "\n",
    "    if terminal:\n",
    "        scores += (score, )\n",
    "        losses += (loss.item(), )\n",
    "        episode_cnt += 1\n",
    "        episode_step = 0\n",
    "\n",
    "    print_progress(episode_cnt, episode_step, loss, scores)\n",
    "    if terminal:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can plot the scores and loss. The plots contain multiple graphs averaged over different window sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(scores)\n",
    "plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkb/anaconda3/envs/drlnd/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== step: 0\n",
      "score:    0.0\n",
      "=== step: 1\n",
      "score:    0.0\n",
      "=== step: 2\n",
      "score:    0.0\n",
      "=== step: 3\n",
      "score:    0.0\n",
      "=== step: 4\n",
      "score:    0.0\n",
      "=== step: 5\n",
      "score:    0.0\n",
      "=== step: 6\n",
      "score:    0.0\n",
      "=== step: 7\n",
      "score:    0.0\n",
      "=== step: 8\n",
      "score:    0.0\n",
      "=== step: 9\n",
      "score:    0.0\n",
      "=== step: 10\n",
      "score:    0.0\n",
      "=== step: 11\n",
      "score:    0.0\n",
      "=== step: 12\n",
      "score:    0.0\n",
      "=== step: 13\n",
      "score:    0.0\n",
      "=== step: 14\n",
      "score:    0.0\n",
      "=== step: 15\n",
      "score:    0.0\n",
      "=== step: 16\n",
      "score:    0.0\n",
      "=== step: 17\n",
      "score:    0.0\n",
      "=== step: 18\n",
      "score:    0.0\n",
      "=== step: 19\n",
      "score:    0.0\n",
      "=== step: 20\n",
      "score:    1.0\n",
      "=== step: 21\n",
      "score:    1.0\n",
      "=== step: 22\n",
      "score:    1.0\n",
      "=== step: 23\n",
      "score:    1.0\n",
      "=== step: 24\n",
      "score:    1.0\n",
      "=== step: 25\n",
      "score:    1.0\n",
      "=== step: 26\n",
      "score:    1.0\n",
      "=== step: 27\n",
      "score:    1.0\n",
      "=== step: 28\n",
      "score:    1.0\n",
      "=== step: 29\n",
      "score:    1.0\n",
      "=== step: 30\n",
      "score:    1.0\n",
      "=== step: 31\n",
      "score:    1.0\n",
      "=== step: 32\n",
      "score:    1.0\n",
      "=== step: 33\n",
      "score:    1.0\n",
      "=== step: 34\n",
      "score:    1.0\n",
      "=== step: 35\n",
      "score:    1.0\n",
      "=== step: 36\n",
      "score:    1.0\n",
      "=== step: 37\n",
      "score:    1.0\n",
      "=== step: 38\n",
      "score:    2.0\n",
      "=== step: 39\n",
      "score:    2.0\n",
      "=== step: 40\n",
      "score:    2.0\n",
      "=== step: 41\n",
      "score:    2.0\n",
      "=== step: 42\n",
      "score:    2.0\n",
      "=== step: 43\n",
      "score:    2.0\n",
      "=== step: 44\n",
      "score:    2.0\n",
      "=== step: 45\n",
      "score:    2.0\n",
      "=== step: 46\n",
      "score:    2.0\n",
      "=== step: 47\n",
      "score:    2.0\n",
      "=== step: 48\n",
      "score:    2.0\n",
      "=== step: 49\n",
      "score:    2.0\n",
      "=== step: 50\n",
      "score:    2.0\n",
      "=== step: 51\n",
      "score:    2.0\n",
      "=== step: 52\n",
      "score:    2.0\n",
      "=== step: 53\n",
      "score:    2.0\n",
      "=== step: 54\n",
      "score:    2.0\n",
      "=== step: 55\n",
      "score:    3.0\n",
      "=== step: 56\n",
      "score:    3.0\n",
      "=== step: 57\n",
      "score:    3.0\n",
      "=== step: 58\n",
      "score:    3.0\n",
      "=== step: 59\n",
      "score:    3.0\n",
      "=== step: 60\n",
      "score:    3.0\n",
      "=== step: 61\n",
      "score:    3.0\n",
      "=== step: 62\n",
      "score:    3.0\n",
      "=== step: 63\n",
      "score:    3.0\n",
      "=== step: 64\n",
      "score:    3.0\n",
      "=== step: 65\n",
      "score:    3.0\n",
      "=== step: 66\n",
      "score:    3.0\n",
      "=== step: 67\n",
      "score:    3.0\n",
      "=== step: 68\n",
      "score:    3.0\n",
      "=== step: 69\n",
      "score:    3.0\n",
      "=== step: 70\n",
      "score:    3.0\n",
      "=== step: 71\n",
      "score:    3.0\n",
      "=== step: 72\n",
      "score:    3.0\n",
      "=== step: 73\n",
      "score:    3.0\n",
      "=== step: 74\n",
      "score:    3.0\n",
      "=== step: 75\n",
      "score:    3.0\n",
      "=== step: 76\n",
      "score:    3.0\n",
      "=== step: 77\n",
      "score:    3.0\n",
      "=== step: 78\n",
      "score:    3.0\n",
      "=== step: 79\n",
      "score:    3.0\n",
      "=== step: 80\n",
      "score:    3.0\n",
      "=== step: 81\n",
      "score:    3.0\n",
      "=== step: 82\n",
      "score:    3.0\n",
      "=== step: 83\n",
      "score:    3.0\n",
      "=== step: 84\n",
      "score:    3.0\n",
      "=== step: 85\n",
      "score:    3.0\n",
      "=== step: 86\n",
      "score:    3.0\n",
      "=== step: 87\n",
      "score:    3.0\n",
      "=== step: 88\n",
      "score:    3.0\n",
      "=== step: 89\n",
      "score:    3.0\n",
      "=== step: 90\n",
      "score:    3.0\n",
      "=== step: 91\n",
      "score:    3.0\n",
      "=== step: 92\n",
      "score:    3.0\n",
      "=== step: 93\n",
      "score:    3.0\n",
      "=== step: 94\n",
      "score:    4.0\n",
      "=== step: 95\n",
      "score:    4.0\n",
      "=== step: 96\n",
      "score:    4.0\n",
      "=== step: 97\n",
      "score:    4.0\n",
      "=== step: 98\n",
      "score:    4.0\n",
      "=== step: 99\n",
      "score:    4.0\n",
      "=== step: 100\n",
      "score:    4.0\n",
      "=== step: 101\n",
      "score:    4.0\n",
      "=== step: 102\n",
      "score:    4.0\n",
      "=== step: 103\n",
      "score:    4.0\n",
      "=== step: 104\n",
      "score:    5.0\n",
      "=== step: 105\n",
      "score:    5.0\n",
      "=== step: 106\n",
      "score:    5.0\n",
      "=== step: 107\n",
      "score:    5.0\n",
      "=== step: 108\n",
      "score:    5.0\n",
      "=== step: 109\n",
      "score:    5.0\n",
      "=== step: 110\n",
      "score:    5.0\n",
      "=== step: 111\n",
      "score:    5.0\n",
      "=== step: 112\n",
      "score:    5.0\n",
      "=== step: 113\n",
      "score:    5.0\n",
      "=== step: 114\n",
      "score:    5.0\n",
      "=== step: 115\n",
      "score:    5.0\n",
      "=== step: 116\n",
      "score:    5.0\n",
      "=== step: 117\n",
      "score:    5.0\n",
      "=== step: 118\n",
      "score:    5.0\n",
      "=== step: 119\n",
      "score:    5.0\n",
      "=== step: 120\n",
      "score:    5.0\n",
      "=== step: 121\n",
      "score:    5.0\n",
      "=== step: 122\n",
      "score:    5.0\n",
      "=== step: 123\n",
      "score:    5.0\n",
      "=== step: 124\n",
      "score:    5.0\n",
      "=== step: 125\n",
      "score:    5.0\n",
      "=== step: 126\n",
      "score:    6.0\n",
      "=== step: 127\n",
      "score:    6.0\n",
      "=== step: 128\n",
      "score:    6.0\n",
      "=== step: 129\n",
      "score:    6.0\n",
      "=== step: 130\n",
      "score:    6.0\n",
      "=== step: 131\n",
      "score:    6.0\n",
      "=== step: 132\n",
      "score:    6.0\n",
      "=== step: 133\n",
      "score:    6.0\n",
      "=== step: 134\n",
      "score:    6.0\n",
      "=== step: 135\n",
      "score:    6.0\n",
      "=== step: 136\n",
      "score:    6.0\n",
      "=== step: 137\n",
      "score:    6.0\n",
      "=== step: 138\n",
      "score:    6.0\n",
      "=== step: 139\n",
      "score:    7.0\n",
      "=== step: 140\n",
      "score:    7.0\n",
      "=== step: 141\n",
      "score:    7.0\n",
      "=== step: 142\n",
      "score:    7.0\n",
      "=== step: 143\n",
      "score:    7.0\n",
      "=== step: 144\n",
      "score:    7.0\n",
      "=== step: 145\n",
      "score:    7.0\n",
      "=== step: 146\n",
      "score:    7.0\n",
      "=== step: 147\n",
      "score:    7.0\n",
      "=== step: 148\n",
      "score:    7.0\n",
      "=== step: 149\n",
      "score:    7.0\n",
      "=== step: 150\n",
      "score:    7.0\n",
      "=== step: 151\n",
      "score:    7.0\n",
      "=== step: 152\n",
      "score:    7.0\n",
      "=== step: 153\n",
      "score:    7.0\n",
      "=== step: 154\n",
      "score:    7.0\n",
      "=== step: 155\n",
      "score:    7.0\n",
      "=== step: 156\n",
      "score:    7.0\n",
      "=== step: 157\n",
      "score:    7.0\n",
      "=== step: 158\n",
      "score:    7.0\n",
      "=== step: 159\n",
      "score:    7.0\n",
      "=== step: 160\n",
      "score:    7.0\n",
      "=== step: 161\n",
      "score:    7.0\n",
      "=== step: 162\n",
      "score:    7.0\n",
      "=== step: 163\n",
      "score:    7.0\n",
      "=== step: 164\n",
      "score:    7.0\n",
      "=== step: 165\n",
      "score:    7.0\n",
      "=== step: 166\n",
      "score:    8.0\n",
      "=== step: 167\n",
      "score:    8.0\n",
      "=== step: 168\n",
      "score:    8.0\n",
      "=== step: 169\n",
      "score:    8.0\n",
      "=== step: 170\n",
      "score:    8.0\n",
      "=== step: 171\n",
      "score:    8.0\n",
      "=== step: 172\n",
      "score:    8.0\n",
      "=== step: 173\n",
      "score:    8.0\n",
      "=== step: 174\n",
      "score:    8.0\n",
      "=== step: 175\n",
      "score:    8.0\n",
      "=== step: 176\n",
      "score:    8.0\n",
      "=== step: 177\n",
      "score:    8.0\n",
      "=== step: 178\n",
      "score:    8.0\n",
      "=== step: 179\n",
      "score:    8.0\n",
      "=== step: 180\n",
      "score:    8.0\n",
      "=== step: 181\n",
      "score:    8.0\n",
      "=== step: 182\n",
      "score:    8.0\n",
      "=== step: 183\n",
      "score:    8.0\n",
      "=== step: 184\n",
      "score:    8.0\n",
      "=== step: 185\n",
      "score:    8.0\n",
      "=== step: 186\n",
      "score:    8.0\n",
      "=== step: 187\n",
      "score:    8.0\n",
      "=== step: 188\n",
      "score:    9.0\n",
      "=== step: 189\n",
      "score:    9.0\n",
      "=== step: 190\n",
      "score:    9.0\n",
      "=== step: 191\n",
      "score:    9.0\n",
      "=== step: 192\n",
      "score:    9.0\n",
      "=== step: 193\n",
      "score:    9.0\n",
      "=== step: 194\n",
      "score:    9.0\n",
      "=== step: 195\n",
      "score:    9.0\n",
      "=== step: 196\n",
      "score:    9.0\n",
      "=== step: 197\n",
      "score:    9.0\n",
      "=== step: 198\n",
      "score:    9.0\n",
      "=== step: 199\n",
      "score:    10.0\n",
      "=== step: 200\n",
      "score:    10.0\n",
      "=== step: 201\n",
      "score:    10.0\n",
      "=== step: 202\n",
      "score:    10.0\n",
      "=== step: 203\n",
      "score:    10.0\n",
      "=== step: 204\n",
      "score:    10.0\n",
      "=== step: 205\n",
      "score:    10.0\n",
      "=== step: 206\n",
      "score:    10.0\n",
      "=== step: 207\n",
      "score:    11.0\n",
      "=== step: 208\n",
      "score:    11.0\n",
      "=== step: 209\n",
      "score:    11.0\n",
      "=== step: 210\n",
      "score:    11.0\n",
      "=== step: 211\n",
      "score:    11.0\n",
      "=== step: 212\n",
      "score:    11.0\n",
      "=== step: 213\n",
      "score:    11.0\n",
      "=== step: 214\n",
      "score:    11.0\n",
      "=== step: 215\n",
      "score:    11.0\n",
      "=== step: 216\n",
      "score:    11.0\n",
      "=== step: 217\n",
      "score:    11.0\n",
      "=== step: 218\n",
      "score:    11.0\n",
      "=== step: 219\n",
      "score:    11.0\n",
      "=== step: 220\n",
      "score:    11.0\n",
      "=== step: 221\n",
      "score:    11.0\n",
      "=== step: 222\n",
      "score:    11.0\n",
      "=== step: 223\n",
      "score:    11.0\n",
      "=== step: 224\n",
      "score:    11.0\n",
      "=== step: 225\n",
      "score:    12.0\n",
      "=== step: 226\n",
      "score:    12.0\n",
      "=== step: 227\n",
      "score:    12.0\n",
      "=== step: 228\n",
      "score:    12.0\n",
      "=== step: 229\n",
      "score:    12.0\n",
      "=== step: 230\n",
      "score:    12.0\n",
      "=== step: 231\n",
      "score:    12.0\n",
      "=== step: 232\n",
      "score:    12.0\n",
      "=== step: 233\n",
      "score:    12.0\n",
      "=== step: 234\n",
      "score:    12.0\n",
      "=== step: 235\n",
      "score:    12.0\n",
      "=== step: 236\n",
      "score:    12.0\n",
      "=== step: 237\n",
      "score:    12.0\n",
      "=== step: 238\n",
      "score:    12.0\n",
      "=== step: 239\n",
      "score:    12.0\n",
      "=== step: 240\n",
      "score:    12.0\n",
      "=== step: 241\n",
      "score:    12.0\n",
      "=== step: 242\n",
      "score:    12.0\n",
      "=== step: 243\n",
      "score:    12.0\n",
      "=== step: 244\n",
      "score:    12.0\n",
      "=== step: 245\n",
      "score:    12.0\n",
      "=== step: 246\n",
      "score:    12.0\n",
      "=== step: 247\n",
      "score:    12.0\n",
      "=== step: 248\n",
      "score:    12.0\n",
      "=== step: 249\n",
      "score:    12.0\n",
      "=== step: 250\n",
      "score:    12.0\n",
      "=== step: 251\n",
      "score:    12.0\n",
      "=== step: 252\n",
      "score:    12.0\n",
      "=== step: 253\n",
      "score:    12.0\n",
      "=== step: 254\n",
      "score:    12.0\n",
      "=== step: 255\n",
      "score:    13.0\n",
      "=== step: 256\n",
      "score:    13.0\n",
      "=== step: 257\n",
      "score:    13.0\n",
      "=== step: 258\n",
      "score:    13.0\n",
      "=== step: 259\n",
      "score:    13.0\n",
      "=== step: 260\n",
      "score:    13.0\n",
      "=== step: 261\n",
      "score:    13.0\n",
      "=== step: 262\n",
      "score:    13.0\n",
      "=== step: 263\n",
      "score:    13.0\n",
      "=== step: 264\n",
      "score:    13.0\n",
      "=== step: 265\n",
      "score:    13.0\n",
      "=== step: 266\n",
      "score:    13.0\n",
      "=== step: 267\n",
      "score:    14.0\n",
      "=== step: 268\n",
      "score:    14.0\n",
      "=== step: 269\n",
      "score:    14.0\n",
      "=== step: 270\n",
      "score:    14.0\n",
      "=== step: 271\n",
      "score:    14.0\n",
      "=== step: 272\n",
      "score:    14.0\n",
      "=== step: 273\n",
      "score:    14.0\n",
      "=== step: 274\n",
      "score:    14.0\n",
      "=== step: 275\n",
      "score:    14.0\n",
      "=== step: 276\n",
      "score:    14.0\n",
      "=== step: 277\n",
      "score:    14.0\n",
      "=== step: 278\n",
      "score:    14.0\n",
      "=== step: 279\n",
      "score:    14.0\n",
      "=== step: 280\n",
      "score:    14.0\n",
      "=== step: 281\n",
      "score:    14.0\n",
      "=== step: 282\n",
      "score:    15.0\n",
      "=== step: 283\n",
      "score:    15.0\n",
      "=== step: 284\n",
      "score:    15.0\n",
      "=== step: 285\n",
      "score:    15.0\n",
      "=== step: 286\n",
      "score:    15.0\n",
      "=== step: 287\n",
      "score:    15.0\n",
      "=== step: 288\n",
      "score:    15.0\n",
      "=== step: 289\n",
      "score:    15.0\n",
      "=== step: 290\n",
      "score:    15.0\n",
      "=== step: 291\n",
      "score:    15.0\n",
      "=== step: 292\n",
      "score:    15.0\n",
      "=== step: 293\n",
      "score:    15.0\n",
      "=== step: 294\n",
      "score:    15.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== step: 295\n",
      "score:    15.0\n",
      "=== step: 296\n",
      "score:    15.0\n",
      "=== step: 297\n",
      "score:    15.0\n",
      "=== step: 298\n",
      "score:    16.0\n",
      "=== step: 299\n",
      "score:    16.0\n"
     ]
    }
   ],
   "source": [
    "replay_agent = learner.get_agent()\n",
    "episode = env.generate_episode(replay_agent)\n",
    "for count, step_data in enumerate(episode):\n",
    "    print(\"=== step: \" + str(count))\n",
    "    print(\"score:    \" + str(env.get_score()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
