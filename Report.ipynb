{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN/DDQN Reinforcement Learning Agent for Navigation \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we briefly summarize the implementation details and training results of the agent implemented in this repository.\n",
    "\n",
    "For the ease of readability we start with an overview of the implemented algorithms and the achieved results in the first section, and continue with a detailed walk through the [Implementation](#1.-Implementation) in the section thereafter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm and Results\n",
    "\n",
    "In the following sections we give a brief overview of the general setup and the implemented algorithms. A detailed introduction to Markov Decision Processes and Reinforcement learning can be found e.g. in [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html). For further details also see the referenced articles.\n",
    "\n",
    "### 1.1 General setting\n",
    "\n",
    "The agent navigates in a predefined environment that represents a square world were it has to collect bananas. A reward $r$ of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana. Thus, the goal of your agent is to collect as many yellow bananas as possible while avoiding blue bananas.\n",
    "\n",
    "The problem is formalized as a *Markov Decision Process* (MDP), where the state space of the agent's environment is represented by a 37 dimensional vector $s$ of real numbers and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction. Given this information, the agent has to learn how to best select actions. Four discrete actions $a$ are available, corresponding to:\n",
    "\n",
    "    0 - move forward.\n",
    "    1 - move backward.\n",
    "    2 - turn left.\n",
    "    3 - turn right.\n",
    "\n",
    "The task is episodic, and the environment is considered solved if the agent is able to achieve an average score of +13 over 100 consecutive episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Q-Learning algorithm and implemented variants\n",
    "\n",
    "In [Q-learning](https://en.wikipedia.org/wiki/Q-learning) we try to approximate the optimal action-value function $Q^*(s, a)$, i.e. the expected overall discounted reward following an optimal policy $\\pi^*$, of the Markov Decision Process:\n",
    "$$\n",
    "Q(s,a) \\approx Q^*_{\\pi*}(s,a) = \\mathbb{E}_{\\pi^*} \\left[\\sum_{i=0}^{\\infty} \\gamma^i r_i \\right],\n",
    "$$\n",
    "where $\\gamma$ is a discount rate that determines the weight of future return values, i.e. how far the agent looks into the future. Based on the approixmator $Q(s,a)$ the agent can derive a policy $\\pi$ by choosing the action with the optimal value in each state.\n",
    "\n",
    "For our problem we will use parameterized function approximators $Q(s, a, \\theta)$ based on deep neural networks (DNN). To optimize this function approximators $Q(s, a, \\theta)$ we will minimize loss functions (see below) that are based on the *Bellman optimality equation*\n",
    "$$\n",
    "Q^*(s, a) = \\mathbb{E} \\left[R_{t+1} + \\gamma \\max_{a'} Q^*(S_{t+1}, a') \\, \\big |  \\, S_t=s, A_t=a \\right],\n",
    "$$\n",
    "which provides a condition that the optimal value function $Q^*(s,a)$ must satisfy. \n",
    "\n",
    "#### Learning algorithm\n",
    "\n",
    "The learning follows an iterative algorithm which can be described on a high level as:\n",
    "- Initialize Q\n",
    "- for i episodes:\n",
    "    - derive a ($\\epsilon$-greedy) policy $\\pi$ from $Q$\n",
    "    - generate experience $s_0, a_0, r_0, s_1, a_1, \\dots$ from an episode using $\\pi$\n",
    "    - optimize $\\theta$ from the experience to reduce the loss\n",
    "\n",
    "In this repository two variants of function approximation based Q-Learning algorithms are implemented:\n",
    "\n",
    "#### DQN\n",
    "This is a variant of Q-learning with a DNN as approximator for the Q-function, using a *fixed target* and *experience replay*. In this variant the following loss function is minimized: \n",
    "$$\n",
    "L^{\\scriptscriptstyle \\rm DQN}(\\theta) = \\mathbb{E}_{s_t,a_t,s_{t+1},a_{t+1}} \\left[r_{t+1} + \\gamma \\max_{a_{t+1}} Q(s_{t+1}, a_{t+1}, \\theta') - Q(s_t,a_t, \\theta) \\right].\n",
    "$$\n",
    "This loss function uses a second parameter $\\theta'$ (*fixed target*) that is temporarily fixed during the learning process, or is, like in our implementation, updated at a lower pace by a soft-update function $θ' \\leftarrow \\tau\\theta + (1 - \\tau)\\theta'$. During the optimization process a technique called *experience replay* is applied, which means that states experienced during the exectution of the Markov process are stored in a replay memory and sampled independently from this memory during learning. Both techniques improve the stability of the learning algorithm, for a more detailed description see [this paper](https://www.nature.com/articles/nature14236).\n",
    "#### DDQN\n",
    "In Double Q-learning (*DDQN*), the loss function of the DQN algorithm is slightly modified to decouple the choice of the optimal action from the estimation of the actual value of the Q-function by using different approximators for the Q-function's value and the action selection at timestep $t+1$ (note the different parameters $\\theta$ and $\\theta'$):\n",
    "$$\n",
    "L^{\\scriptscriptstyle \\rm DDQN}(\\theta) = \\mathbb{E}_{s_t,a_t,s_{t+1},a_{t+1}} \\left[r_{t+1} + \\gamma Q(s_{t+1}, \\max_{a_{t+1}}Q(s_{t+1},a_{t+1}, \\theta), \\theta') - Q(s_t,a_t, \\theta) \\right],\n",
    "$$\n",
    "to address issues that the DQN algorithm experiences with regard to overestimating the actual value of the Q function. Further details can be found [here](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12389/11847).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Network architectures\n",
    "\n",
    "Two different architectures of DNNs as function approximators were examined:\n",
    "\n",
    "- a *simple* variant with two hidden layers of 64 units each:\n",
    "![Simple DNN](resources/simple_dnn.png)\n",
    "- a more advanced architecture that is extended with two additional hidden layers with 16 and 8 units at the input side of the DNN. This two layers are intended to work similar to the encoder part of an [autoencoder](https://en.wikipedia.org/wiki/Autoencoder) architecture and extract features from the raw state:\n",
    "![AutoEnc DNN](resources/autoenc_dnn.png)\n",
    "\n",
    "### 1.4 Hyperparameter choices\n",
    "\n",
    "For all implemented algorithm and model architectures the same set of the following hyper-parameters was used:\n",
    "\n",
    "- A discount rate $\\gamma=0.99$ close to one was chosen, as it is expected that an action of the agent will result in a reward only after several future steps. As expected, the choice of low discount rates resulted in a notable decrease of performance.\n",
    "- The size of the memory for experience replay was choosen to hold about 100 episodes (of 300 steps each), and every 4 steps 4 randomly chosen batches of 64 samples were drawn from the replay memory.\n",
    "- During execution of the episodes the agent used an $\\epsilon$-greedy policy, with a start value if $\\epsilon = 1.0$ (high exploration), gradually declining to a minimum value of 0.01 (high exploitation) within about 1000 episodes.\n",
    "- The target parameters $\\theta'$ of the Q-function in DQN and DDQN were updated with a soft-update weight parameter of $\\tau = 10^{-3}$ after every processed batch.\n",
    "- For weight updates a constant learning learning rate of $10^{-4}$ turned out to deliver good results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Performance\n",
    "The following plot displays the performance for the different algorithm and network architecture choices. The average final score of each episode, averaged over the last 100 episodes is drawn against the number of episodes executed for learning:\n",
    "![Scores](results/multi_model.scores.png)\n",
    "As seen from the plot, the target performance of an average score of +13 is achieved by all combinations of algorithm and model within about 500-600 episodes. The best final performance with an average score of 17.4 averaged over 100 episodes is delivered by the auto-encoder like DNN architecture in combination with the DDQN algorithm, though all variants get close to this value at some point.\n",
    "\n",
    "Overall, all the implemented variants perform very simmilar, and the main performance improvements that were taken to achieve the above result were improvements of the hyper-parameter choices, especially for learning rate, batch size and the replay memory size. With this in mind a clear statement on the difference in performance of the various implemented variants is not justified from the observed results, as the choosen hyper-parameters might as well be more optimal for some of the variants than for others. \n",
    "\n",
    "Finally we also include a plot of the episode scores and the loss. Notable is that the loss in fact increases during the learning process, which comes from the fact that the loss is calculated against a constantly changing target $Q(s,a,\\theta')$.\n",
    "\n",
    "Scores | Losses\n",
    "-|-\n",
    "![DDQN_Scores](results/ddqn_simple_model.scores.png)| ![DDQN_Loss](results/ddqn_simple_model.losses.png)\n",
    "\n",
    "The loss values in the above plot are the loss of the last learning step in each episode (due to a mistake in the code). A similar, but a bit more sensible plot with the average loss of each episode can be found at the bottom of this notebook.\n",
    "\n",
    "#### Result files\n",
    "\n",
    "Results of the executed learning process, in particular the paramters for the trained DNNs can be found in the [results/](../tree/results) folder. The agent with the trained parameters can be executed from the command line invoking the *banananavigation.py* script with the *--replay* option as described in the [README](../tree/README.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Further Improvements\n",
    "\n",
    "Considering the high fluctuations in the above plots both for scores and losses the following ways could be explored to achieve further performance improvements:\n",
    "\n",
    "One route to explore could be further hyper-parameter improvements to stabilize the learning in the later phase. This could be a gradually decreasing learning rate/increasing batch size, a progressive increase of the discount factor or a progressive increase of the soft-update weight $\\tau$ .\n",
    "\n",
    "Given the high variance of the loss, another direction could be to improve the sampling from the replay memory using [prioritized experienced replay](https://arxiv.org/abs/1511.05952), which puts more focus on experience points that result in high loss values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation\n",
    "\n",
    "In this section we provide a detailed walk through the implementation. To reproduce the above results, however, run the \n",
    "banananavigation script from the command line as described in the README without command line parameters.\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pkg_resources\n",
    "import random\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from unityagents.exception import UnityEnvironmentException\n",
    "\n",
    "from banananav.environment import PLATFORM_PATHS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Environment\n",
    "\n",
    "The environment in which the agent operates is based on a predefined [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) environment was installed in [banananav/resources/](../tree/banananav/resources/) folder during the setup described in the [README](../tree/README.md).\n",
    "\n",
    "To navigate the environment the [environment.py module](../tree/banananav) provides a `BananaAgent` class that chooses an action for a given state of the environment based on a provided Q-Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s BananaAgent banananav/environment.py\n",
    "class BananaAgent:\n",
    "    \"\"\"Agent based on a Q-function.\"\"\"\n",
    "\n",
    "    def __init__(self, Q, action_size, epsilon=0.0):\n",
    "        \"\"\"Initialize the agent.\n",
    "\n",
    "        Args:\n",
    "            Q: Q-function that is callable with a state and returns a 1-dim\n",
    "                array-like containing the q-values for each action.\n",
    "            action_size: The number of available actions.\n",
    "            epsilon: propability for the agent to choose the action uniformly\n",
    "                from the available actions instead of based on the Q-function,\n",
    "                defaults to 0.0.\n",
    "        \"\"\"\n",
    "        self._Q = Q\n",
    "        self._action_size = action_size\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Select an action for the given state.\n",
    "\n",
    "        Args:\n",
    "            state: The state to choose the action for.\n",
    "        Returns:\n",
    "            An int representing the action.\n",
    "        \"\"\"\n",
    "        if not torch.is_tensor(state):\n",
    "            try:\n",
    "                state = torch.from_numpy(state)\n",
    "            except:\n",
    "                state = torch.from_numpy(np.array(state, dtype=np.float))\n",
    "\n",
    "        state = state.float()\n",
    "\n",
    "        if self._epsilon == 0.0 or random.uniform(0, 1) > self._epsilon:\n",
    "            with torch.no_grad():\n",
    "                return torch.argmax(self._Q(state)).item()\n",
    "\n",
    "        return np.random.randint(self._action_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and a `BananaEnv` class that provides an interface that allows to navigate the environment with an instance of the `BananaAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s BananaEnv banananav/environment.py\n",
    "class BananaEnv:\n",
    "    \"\"\"Banana collection environment.\n",
    "\n",
    "    The environment accepts actions and provides states and rewards in response.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        for path in PLATFORM_PATHS:\n",
    "            try:\n",
    "                unity_resource = pkg_resources.resource_filename('banananav', 'resources/' + path)\n",
    "                self._env = UnityEnvironment(file_name=unity_resource)\n",
    "                print(\"Environment loaded from \" + path)\n",
    "                break\n",
    "            except UnityEnvironmentException as e:\n",
    "                print(\"Attempted to load \" + path + \":\")\n",
    "                print(e)\n",
    "                print(\"\")\n",
    "                pass\n",
    "\n",
    "        if not hasattr(self, '_env'):\n",
    "            raise Exception(\"No unity environment found, setup the environment as described in the README.\")\n",
    "\n",
    "        # get the default brain\n",
    "        self._brain_name = self._env.brain_names[0]\n",
    "        self._brain = self._env.brains[self._brain_name]\n",
    "\n",
    "        self._info = None\n",
    "        self._score = None\n",
    "\n",
    "    def generate_episode(self, agent, max_steps=None, train_mode=False):\n",
    "        \"\"\"Create a generator for and episode driven by an actor.\n",
    "        Args:\n",
    "            actor: An actor that provides the next action for a given state.\n",
    "            max_steps: Maximum number of steps (int) to take in the episode. If\n",
    "                None, the episode is generated until a terminal state is reached.\n",
    "\n",
    "        Returns:\n",
    "            A generator providing a tuple of the current state, the action taken,\n",
    "            the obtained reward, the next state and a flag whether the next\n",
    "            state is terminal or not.\n",
    "        \"\"\"\n",
    "        state = self.reset(train_mode=train_mode)\n",
    "        is_terminal = False\n",
    "        count = 0\n",
    "\n",
    "        while not is_terminal and (max_steps is None or count < max_steps):\n",
    "            action = agent.act(state)\n",
    "            reward, next_state, is_terminal = self.step(action)\n",
    "\n",
    "            step_data = (state, action, reward, next_state, is_terminal)\n",
    "\n",
    "            state = next_state\n",
    "            count += 1\n",
    "\n",
    "            yield step_data\n",
    "\n",
    "    def reset(self, train_mode=False):\n",
    "        \"\"\"Reset and initiate a new episode in the environment.\n",
    "\n",
    "        Args:\n",
    "            train_mode: Indicate if the environment should be initiated in\n",
    "                training mode or not.\n",
    "\n",
    "        Returns:\n",
    "            The initial state of the episode (np.array).\n",
    "        \"\"\"\n",
    "        if self._info is not None and not self._info.local_done[0]:\n",
    "            raise Exception(\"Env is active, call terminate first\")\n",
    "\n",
    "        self._info = self._env.reset(train_mode=train_mode)[self._brain_name]\n",
    "        self._score = 0\n",
    "\n",
    "        return self._info.vector_observations[0]\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Execute an action.\n",
    "\n",
    "        Args:\n",
    "            action: An int representing the actionself.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the reward (float), the next state (np.array) and\n",
    "            a boolean indicating if the next state is terminal or not.\n",
    "        \"\"\"\n",
    "        if self._info is None:\n",
    "            raise Exception(\"Env is not active, call reset first\")\n",
    "\n",
    "        self._info = self._env.step(action)[self._brain_name]\n",
    "        next_state = self._info.vector_observations[0]\n",
    "        reward = self._info.rewards[0]\n",
    "        is_terminal = self._info.local_done[0]\n",
    "        self._score += reward\n",
    "\n",
    "        return reward, next_state, is_terminal\n",
    "\n",
    "    def terminate(self):\n",
    "        self._info = None\n",
    "        self._score = None\n",
    "\n",
    "    def close(self):\n",
    "        self._env.close()\n",
    "        self._info = None\n",
    "\n",
    "    def get_score(self):\n",
    "        \"\"\"Return the cumulative reward of the current episode.\"\"\"\n",
    "        return self._score\n",
    "\n",
    "    def get_action_size(self):\n",
    "        return self._brain.vector_action_space_size\n",
    "\n",
    "    def get_state_size(self):\n",
    "        return self._brain.vector_observation_space_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment loaded from Banana.app\n",
      "'state size: 37'\n",
      "'state size: 4'\n"
     ]
    }
   ],
   "source": [
    "### RUN THIS CELL ONLY ONCE!! ###\n",
    "env = BananaEnv()\n",
    "pprint(\"state size: \" + str(env.get_state_size()))\n",
    "pprint(\"state size: \" + str(env.get_action_size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the environment let us run a view steps with a random agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'============= Current step: 0'\n",
      "'state:'\n",
      "array([1.        , 0.        , 0.        , 0.        , 0.84408134,\n",
      "       0.        , 0.        , 1.        , 0.        , 0.0748472 ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.25755   ,\n",
      "       1.        , 0.        , 0.        , 0.        , 0.74177343,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.25854847,\n",
      "       0.        , 0.        , 1.        , 0.        , 0.09355672,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.31969345,\n",
      "       0.        , 0.        ])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34574997,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.08556978,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.26330134,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.90327591,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.2643221 ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.10695964,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.32683259,\n",
      "        0.        , -7.81049442])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 1'\n",
      "'state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34574997,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.08556978,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.26330134,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.90327591,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.2643221 ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.10695964,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.32683259,\n",
      "        0.        , -7.81049442])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([  1.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.33389047,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.10400748,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.27372321,   0.        ,\n",
      "         1.        ,   0.        ,   0.        ,   0.92001921,\n",
      "         0.        ,   1.        ,   0.        ,   0.        ,\n",
      "         0.27478445,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.13000619,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.33976912,   0.        ,\n",
      "       -10.5166626 ])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 2'\n",
      "'state:'\n",
      "array([  1.        ,   0.        ,   0.        ,   0.        ,\n",
      "         0.33389047,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.10400748,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.27372321,   0.        ,\n",
      "         1.        ,   0.        ,   0.        ,   0.92001921,\n",
      "         0.        ,   1.        ,   0.        ,   0.        ,\n",
      "         0.27478445,   0.        ,   0.        ,   1.        ,\n",
      "         0.        ,   0.13000619,   0.        ,   1.        ,\n",
      "         0.        ,   0.        ,   0.33976912,   0.        ,\n",
      "       -10.5166626 ])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.41293901e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.25456721e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.85944790e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.39653754e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        2.87053376e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.56806216e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.54939610e-01, -4.76837158e-07,\n",
      "       -1.16585550e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 3'\n",
      "'state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.41293901e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.25456721e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.85944790e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.39653754e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        2.87053376e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.56806216e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.54939610e-01, -4.76837158e-07,\n",
      "       -1.16585550e+01])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.49792719e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.48925006e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.98925906e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.60508406e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.00084829e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.56798851e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.71052921e-01, -4.76837158e-07,\n",
      "       -1.21403875e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 4'\n",
      "'state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.49792719e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.48925006e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  2.98925906e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.60508406e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.00084829e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.56798851e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.71052921e-01, -4.76837158e-07,\n",
      "       -1.21403875e+01])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.73447743e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.12227517e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.81877744e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.13437968e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.78085756e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.87564063e-01, -9.53674316e-07,\n",
      "       -1.23437004e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 5'\n",
      "'state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.73447743e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.12227517e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.81877744e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.13437968e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.78085756e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.87564063e-01, -9.53674316e-07,\n",
      "       -1.23437004e+01])\n",
      "'action: 0'\n",
      "'next state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.79221481e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.15355480e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.86902952e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.16578090e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.83091533e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.91446769e-01, -1.78813934e-07,\n",
      "        1.67893946e+00])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'============= Current step: 6'\n",
      "'state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.79221481e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.15355480e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.86902952e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.16578090e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.83091533e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.91446769e-01, -1.78813934e-07,\n",
      "        1.67893946e+00])\n",
      "'action: 0'\n",
      "'next state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.66466892e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.08445632e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.75801826e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.09641421e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.72033262e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.82869601e-01, -4.76837158e-07,\n",
      "        8.37670422e+00])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 7'\n",
      "'state:'\n",
      "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.66466892e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.08445632e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.75801826e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.09641421e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.72033262e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.82869601e-01, -4.76837158e-07,\n",
      "        8.37670422e+00])\n",
      "'action: 0'\n",
      "'next state:'\n",
      "array([1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.48881036e-01, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 1.46534532e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 2.97647148e-01, 0.00000000e+00,\n",
      "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.58453655e-01,\n",
      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.98801064e-01, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 9.54752147e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.69465560e-01, 4.76837158e-07,\n",
      "       1.07555799e+01])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 8'\n",
      "'state:'\n",
      "array([1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.48881036e-01, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 1.46534532e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 2.97647148e-01, 0.00000000e+00,\n",
      "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.58453655e-01,\n",
      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.98801064e-01, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 9.54752147e-01, 0.00000000e+00, 1.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.69465560e-01, 4.76837158e-07,\n",
      "       1.07555799e+01])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34794271,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.14402579,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29628792,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95627016,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29743659,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95257705,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.36777839,\n",
      "        0.        , -3.02163815])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n",
      "'============= Current step: 9'\n",
      "'state:'\n",
      "array([ 1.        ,  0.        ,  0.        ,  0.        ,  0.34794271,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.14402579,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29628792,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95627016,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.29743659,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.95257705,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.36777839,\n",
      "        0.        , -3.02163815])\n",
      "'action: 1'\n",
      "'next state:'\n",
      "array([ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.53818238e-01,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  1.57777429e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.03738028e-01,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  9.68239009e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        3.04915547e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  9.64499652e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  3.77026141e-01, -1.43051147e-06,\n",
      "       -8.28599930e+00])\n",
      "'reward:0.0'\n",
      "'is terminal state: False'\n"
     ]
    }
   ],
   "source": [
    "dummy_Q = lambda s: (torch.arange(4) == s[0]).float()\n",
    "agent = BananaAgent(dummy_Q, 4)\n",
    "\n",
    "for step, step_data in enumerate(env.generate_episode(agent, max_steps=10)):\n",
    "    state, action, reward, next_state, is_terminal = step_data\n",
    "    pprint(\"============= Current step: \" + str(step))\n",
    "    pprint(\"state:\")\n",
    "    pprint(state)\n",
    "    pprint(\"action: \" + str(action))\n",
    "    pprint(\"next state:\")\n",
    "    pprint(next_state)\n",
    "    pprint(\"reward:\" + str(reward))\n",
    "    pprint(\"is terminal state: \" + str(is_terminal))\n",
    "    \n",
    "    \n",
    "env.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Model implementation\n",
    "\n",
    "The DNN models are implemented as PyTorch modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load banananav/qmodel.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BananaQModel(nn.Module):\n",
    "    \"\"\"Q Function Approximator with autoencode-like step.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Args:\n",
    "            state_size: Dimension of each state (int)\n",
    "            action_size: number of actions (int)\n",
    "        \"\"\"\n",
    "        super(BananaQModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.fc5 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        return self.fc5(x)\n",
    "\n",
    "class SimpleBananaQModel(nn.Module):\n",
    "    \"\"\"Q Function Approximator.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Args:\n",
    "            state_size: Dimension of each state (int)\n",
    "            action_size: number of actions (int)\n",
    "        \"\"\"\n",
    "        super(SimpleBananaQModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Q-learing algorithm implementation\n",
    "\n",
    "The DQN algorithm is implemented in the `DeepQLearner` class, which also takes care of the episode creation needed for the learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banananav.replaymemory import ReplayMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load -s DeepQLearner banananav/training.py\n",
    "class DeepQLearner():\n",
    "    \"\"\"Implementation of the DQN learning algorithm with experience replay.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env=None, model=BananaQModel, memory=ReplayMemory(int(3e4)),\n",
    "            batch_steps=4, batch_size=64, batch_repeat=4,\n",
    "            lr=1e-4, decay=0.001,\n",
    "            epsilon_start=1.0, epsilon_min=0.01, epsilon_decay=0.995,\n",
    "            gamma=0.99, tau=1e-3):\n",
    "        self._memory = memory\n",
    "        # Don't instantiate as default as the constructor already starts the unity environment\n",
    "        self._env = env if env is not None else BananaEnv()\n",
    "\n",
    "        self._state_size = self._env.get_state_size()\n",
    "        self._actions = self._env.get_action_size()\n",
    "\n",
    "        self._batch_steps = batch_steps\n",
    "        self._batch_size = batch_size\n",
    "        self._batch_repeat = batch_repeat\n",
    "\n",
    "        self._epsilon_start=epsilon_start\n",
    "        self._epsilon_min=epsilon_min\n",
    "        self._epsilon_decay=epsilon_decay\n",
    "        self._gamma = gamma\n",
    "        self._tau = tau\n",
    "\n",
    "        self._qnetwork_local = model(self._state_size, self._actions).to(device)\n",
    "        self._qnetwork_target = model(self._state_size, self._actions).to(device)\n",
    "        self._optimizer = optim.Adam(self._qnetwork_local.parameters(), lr=lr,\n",
    "            amsgrad=True)\n",
    "\n",
    "        self._qnetwork_local.eval()\n",
    "        self._qnetwork_target.eval()\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Store the learning result.\n",
    "\n",
    "        Store the parameters of the current Q-function approximation to the given path.\n",
    "        \"\"\"\n",
    "        torch.save(self._qnetwork_local.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"Load learning results.\n",
    "\n",
    "        Load the parameters from the given path into the current and target\n",
    "        Q-function approximator.\n",
    "        \"\"\"\n",
    "        self._qnetwork_local.load_state_dict(torch.load(path))\n",
    "        self._qnetwork_target.load_state_dict(torch.load(path))\n",
    "        self._qnetwork_local.to(device)\n",
    "        self._qnetwork_target.to(device)\n",
    "\n",
    "    def get_agent(self, epsilon=0.0):\n",
    "        \"\"\"Return an agent based on the parameters of the current Q-function approximation.\n",
    "        \"\"\"\n",
    "        return BananaAgent(self._qnetwork_local, self._env.get_action_size(),\n",
    "                epsilon=epsilon)\n",
    "\n",
    "    def train(self, num_episodes=100):\n",
    "        episodes = ( self._env.generate_episode(\n",
    "                        self.get_agent(self._get_epsilon(cnt)), train_mode=True)\n",
    "                for cnt in range(num_episodes) )\n",
    "        steps = ( (cnt, step_cnt, step_data)\n",
    "                for cnt, episode in enumerate(episodes)\n",
    "                for step_cnt, step_data in enumerate(episode) )\n",
    "\n",
    "        for episode, step, step_data in steps:\n",
    "            self._memory.add(*step_data)\n",
    "\n",
    "            if (step % self._batch_steps == 0 or self._is_terminal(step_data)) \\\n",
    "                    and self._memory.size() >= self._batch_size:\n",
    "                for i in range(1 if self._memory.size() < 1000 else self._batch_repeat):\n",
    "                    loss = self._train_from_memory()\n",
    "                    self._update_target()\n",
    "                yield loss, self._env.get_score(), self._is_terminal(step_data)\n",
    "\n",
    "    def _get_epsilon(self, cnt):\n",
    "        return max(self._epsilon_min, self._epsilon_decay ** cnt * self._epsilon_start)\n",
    "\n",
    "    def _train_from_memory(self):\n",
    "        self._qnetwork_local.train()\n",
    "\n",
    "        batch = self._memory.sample(self._batch_size)\n",
    "        loss = self._calculate_loss(*zip(*batch))\n",
    "\n",
    "        self._optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "\n",
    "        self._qnetwork_local.eval()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _calculate_loss(self, states, actions, rewards, next_states, is_terminal):\n",
    "        states, next_states, rewards, is_terminal = self._to_tensor(states, next_states, rewards, is_terminal)\n",
    "        actions = self._to_tensor(actions, dtype=torch.long)[0]\n",
    "\n",
    "        rewards = rewards.unsqueeze(1)\n",
    "        is_terminal = is_terminal.unsqueeze(1)\n",
    "        actions = actions.unsqueeze(1)\n",
    "\n",
    "        Q_target_next = self._qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        Q_target = rewards + (self._gamma * Q_target_next * (1 - is_terminal))\n",
    "        Q_predicted = self._qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        loss = F.mse_loss(Q_target, Q_predicted)\n",
    "\n",
    "        # Validate dimensions\n",
    "        assert Q_predicted.size()[0] == states.size()[0]\n",
    "        assert Q_predicted.size()[1] == 1\n",
    "        assert Q_predicted.size() == Q_target_next.size() == Q_target.size() \\\n",
    "                == rewards.size() == is_terminal.size() == actions.size()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _update_target(self):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "        \"\"\"\n",
    "        parameters = zip(self._qnetwork_target.parameters(), self._qnetwork_local.parameters())\n",
    "\n",
    "        for target_param, local_param in parameters:\n",
    "            update = self._tau * local_param.data + (1.0 - self._tau) * target_param.data\n",
    "            target_param.data.copy_(update)\n",
    "\n",
    "    def _is_terminal(self, state_data):\n",
    "        return state_data[-1]\n",
    "\n",
    "    def _get_reward(self, state_data):\n",
    "        return state_data[2]\n",
    "\n",
    "    def _to_tensor(self, *arrays, dtype=torch.float):\n",
    "        return tuple(torch.tensor(a).to(device, dtype=dtype) for a in arrays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is sub-classed by `DoubleDeepQLearner` with the modified loss calculation for the Double Q-Learning algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s DoubleDeepQLearner banananav/training.py\n",
    "class DoubleDeepQLearner(DeepQLearner):\n",
    "    \"\"\"Implementation of the Double-DQN learning algorithm with experience replay.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env=None, model=BananaQModel, memory=ReplayMemory(int(3e4)),\n",
    "            batch_steps=4, batch_size=64, batch_repeat=4,\n",
    "            lr=1e-4, decay=0.001,\n",
    "            epsilon_start=1.0, epsilon_min=0.01, epsilon_decay=0.995,\n",
    "            gamma=0.99, tau=1e-3):\n",
    "        super(DoubleDeepQLearner, self).__init__(env=env, model=model, memory=memory,\n",
    "                batch_steps=batch_steps, batch_size=batch_size, batch_repeat=batch_repeat,\n",
    "                lr=lr, decay=decay,\n",
    "                epsilon_start=epsilon_start, epsilon_min=epsilon_min, epsilon_decay=epsilon_decay,\n",
    "                gamma=gamma, tau=tau)\n",
    "\n",
    "    def _calculate_loss(self, states, actions, rewards, next_states, is_terminal):\n",
    "        states, next_states, rewards, is_terminal = self._to_tensor(states, next_states, rewards, is_terminal)\n",
    "        actions = self._to_tensor(actions, dtype=torch.long)[0]\n",
    "\n",
    "        rewards = rewards.unsqueeze(1)\n",
    "        is_terminal = is_terminal.unsqueeze(1)\n",
    "        actions = actions.unsqueeze(1)\n",
    "\n",
    "        Q_local_next_choices = self._qnetwork_local(next_states).max(1)[1].unsqueeze(1)\n",
    "        Q_target_next = self._qnetwork_target(next_states).detach().gather(1, Q_local_next_choices)\n",
    "        Q_target = rewards + (self._gamma * Q_target_next * (1 - is_terminal))\n",
    "        Q_predicted = self._qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        loss = F.mse_loss(Q_target, Q_predicted)\n",
    "\n",
    "        # Validate dimensions\n",
    "        assert Q_local_next_choices.size() == actions.size()\n",
    "        assert Q_predicted.size()[0] == states.size()[0]\n",
    "        assert Q_predicted.size()[1] == 1\n",
    "        assert Q_predicted.size() == Q_target_next.size() == Q_target.size() \\\n",
    "                == rewards.size() == is_terminal.size() == actions.size()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Execute learning\n",
    "\n",
    "Now we can put the parts above together, run the learner and \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkb/anaconda3/envs/drlnd/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/0 [------------------------------------------------------------] loss: +1.640E-03 / score: +0.000(+0/+0/+0)\n",
      "2/0 [------------------------------------------------------------] loss: +2.706E-05 / score: -0.500(-1/-1/+0))\n",
      "3/0 [------------------------------------------------------------] loss: +9.038E-05 / score: -0.667(-1/-1/+0))\n",
      "4/0 [------------------------------------------------------------] loss: +1.564E-02 / score: -0.750(-1/-1/+0))\n",
      "5/0 [------------------------------------------------------------] loss: +1.225E-05 / score: -0.600(-1/+0/+0))\n",
      "6/0 [------------------------------------------------------------] loss: +2.021E-05 / score: -0.667(-1/-1/+0))\n",
      "7/0 [------------------------------------------------------------] loss: +1.575E-02 / score: -0.429(-1/+1/+1))\n",
      "8/0 [------------------------------------------------------------] loss: +1.471E-04 / score: -0.500(-1/-1/+1))\n",
      "9/0 [------------------------------------------------------------] loss: +1.521E-02 / score: -0.444(-1/+0/+1))\n",
      "10/0 [------------------------------------------------------------] loss: +1.255E-05 / score: -0.400(-1/+0/+1)\n",
      "11/0 [------------------------------------------------------------] loss: +1.542E-02 / score: -0.364(-1/+0/+1))\n",
      "12/0 [------------------------------------------------------------] loss: +1.692E-04 / score: -0.417(-1/-1/+1))\n",
      "13/0 [------------------------------------------------------------] loss: +3.825E-05 / score: -0.077(-1/+4/+4))\n",
      "14/0 [------------------------------------------------------------] loss: +1.468E-04 / score: -0.214(-2/-2/+4))\n",
      "15/0 [------------------------------------------------------------] loss: +4.187E-05 / score: -0.133(-2/+1/+4))\n",
      "16/0 [------------------------------------------------------------] loss: +7.681E-05 / score: -0.125(-2/+0/+4))\n",
      "17/0 [------------------------------------------------------------] loss: +6.103E-05 / score: -0.118(-2/+0/+4))\n",
      "18/0 [------------------------------------------------------------] loss: +1.898E-04 / score: -0.056(-2/+1/+4))\n",
      "19/0 [------------------------------------------------------------] loss: +4.235E-05 / score: +0.053(-2/+2/+4))\n",
      "20/0 [------------------------------------------------------------] loss: +9.366E-05 / score: +0.100(-2/+1/+4))\n",
      "21/0 [------------------------------------------------------------] loss: +3.826E-05 / score: +0.095(-2/+0/+4))\n",
      "22/0 [------------------------------------------------------------] loss: +4.785E-05 / score: +0.136(-2/+1/+4))\n",
      "23/0 [------------------------------------------------------------] loss: +7.448E-05 / score: +0.087(-2/-1/+4))\n",
      "24/0 [------------------------------------------------------------] loss: +1.490E-02 / score: +0.083(-2/+0/+4))\n",
      "25/0 [------------------------------------------------------------] loss: +6.356E-05 / score: +0.000(-2/-2/+4))\n",
      "26/0 [------------------------------------------------------------] loss: +8.208E-05 / score: +0.077(-2/+2/+4))\n",
      "27/0 [------------------------------------------------------------] loss: +5.986E-05 / score: +0.037(-2/-1/+4))\n",
      "28/0 [------------------------------------------------------------] loss: +6.742E-05 / score: +0.036(-2/+0/+4))\n",
      "29/0 [------------------------------------------------------------] loss: +6.347E-05 / score: +0.034(-2/+0/+4))\n",
      "30/0 [------------------------------------------------------------] loss: +3.126E-02 / score: +0.067(-2/+1/+4))\n",
      "31/0 [------------------------------------------------------------] loss: +2.713E-02 / score: +0.097(-2/+1/+4))\n",
      "32/0 [------------------------------------------------------------] loss: +5.076E-05 / score: +0.062(-2/-1/+4))\n",
      "33/0 [------------------------------------------------------------] loss: +1.317E-04 / score: +0.000(-2/-2/+4))\n",
      "34/0 [------------------------------------------------------------] loss: +7.103E-05 / score: +0.000(-2/+0/+4))\n",
      "35/0 [------------------------------------------------------------] loss: +1.494E-02 / score: +0.000(-2/+0/+4))\n",
      "36/0 [------------------------------------------------------------] loss: +6.009E-05 / score: -0.028(-2/-1/+4))\n",
      "37/0 [------------------------------------------------------------] loss: +5.441E-05 / score: -0.054(-2/-1/+4))\n",
      "38/0 [------------------------------------------------------------] loss: +1.460E-02 / score: -0.026(-2/+1/+4))\n",
      "39/0 [------------------------------------------------------------] loss: +6.210E-05 / score: -0.026(-2/+0/+4))\n",
      "40/0 [------------------------------------------------------------] loss: +5.366E-05 / score: +0.050(-2/+3/+4))\n",
      "41/0 [------------------------------------------------------------] loss: +3.974E-04 / score: +0.049(-2/+0/+4))\n",
      "42/0 [------------------------------------------------------------] loss: +5.351E-04 / score: +0.000(-2/-2/+4))\n",
      "43/0 [------------------------------------------------------------] loss: +9.704E-05 / score: +0.000(-2/+0/+4))\n",
      "44/0 [------------------------------------------------------------] loss: +3.885E-05 / score: +0.068(-2/+3/+4))\n",
      "45/0 [------------------------------------------------------------] loss: +8.065E-05 / score: +0.089(-2/+1/+4))\n",
      "46/0 [------------------------------------------------------------] loss: +6.661E-05 / score: +0.109(-2/+1/+4))\n",
      "47/0 [------------------------------------------------------------] loss: +7.408E-05 / score: +0.191(-2/+4/+4))\n",
      "48/0 [------------------------------------------------------------] loss: +4.466E-04 / score: +0.208(-2/+1/+4))\n",
      "49/0 [------------------------------------------------------------] loss: +1.226E-04 / score: +0.204(-2/+0/+4))\n",
      "50/0 [------------------------------------------------------------] loss: +8.522E-05 / score: +0.200(-2/+0/+4))\n",
      "51/0 [------------------------------------------------------------] loss: +1.513E-04 / score: +0.235(-2/+2/+4))\n",
      "52/0 [------------------------------------------------------------] loss: +1.367E-04 / score: +0.212(-2/-1/+4))\n",
      "53/0 [------------------------------------------------------------] loss: +8.832E-05 / score: +0.226(-2/+1/+4))\n",
      "54/0 [------------------------------------------------------------] loss: +7.715E-05 / score: +0.222(-2/+0/+4))\n",
      "55/0 [------------------------------------------------------------] loss: +1.124E-04 / score: +0.218(-2/+0/+4))\n",
      "56/0 [------------------------------------------------------------] loss: +1.304E-04 / score: +0.268(-2/+3/+4))\n",
      "57/0 [------------------------------------------------------------] loss: +2.259E-04 / score: +0.263(-2/+0/+4))\n",
      "58/0 [------------------------------------------------------------] loss: +1.631E-02 / score: +0.276(-2/+1/+4))\n",
      "59/0 [------------------------------------------------------------] loss: +1.486E-02 / score: +0.339(-2/+4/+4))\n",
      "60/0 [------------------------------------------------------------] loss: +1.448E-02 / score: +0.417(-2/+5/+5))\n",
      "61/0 [------------------------------------------------------------] loss: +1.596E-02 / score: +0.393(-2/-1/+5))\n",
      "62/0 [------------------------------------------------------------] loss: +2.564E-04 / score: +0.419(-2/+2/+5))\n",
      "63/0 [------------------------------------------------------------] loss: +1.590E-02 / score: +0.444(-2/+2/+5))\n",
      "64/0 [------------------------------------------------------------] loss: +4.261E-04 / score: +0.391(-3/-3/+5))\n",
      "65/0 [------------------------------------------------------------] loss: +6.818E-05 / score: +0.369(-3/-1/+5))\n",
      "66/0 [------------------------------------------------------------] loss: +2.550E-04 / score: +0.379(-3/+1/+5))\n",
      "67/0 [------------------------------------------------------------] loss: +2.283E-04 / score: +0.388(-3/+1/+5))\n",
      "68/0 [------------------------------------------------------------] loss: +1.107E-03 / score: +0.441(-3/+4/+5))\n",
      "69/0 [------------------------------------------------------------] loss: +3.242E-04 / score: +0.464(-3/+2/+5))\n",
      "70/0 [------------------------------------------------------------] loss: +1.779E-04 / score: +0.457(-3/+0/+5))\n",
      "71/0 [------------------------------------------------------------] loss: +4.714E-04 / score: +0.493(-3/+3/+5))\n",
      "72/0 [------------------------------------------------------------] loss: +1.424E-02 / score: +0.514(-3/+2/+5))\n",
      "73/0 [------------------------------------------------------------] loss: +1.597E-02 / score: +0.534(-3/+2/+5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/0 [------------------------------------------------------------] loss: +3.228E-02 / score: +0.554(-3/+2/+5))\n",
      "75/0 [------------------------------------------------------------] loss: +8.496E-04 / score: +0.587(-3/+3/+5))\n",
      "76/0 [------------------------------------------------------------] loss: +1.632E-02 / score: +0.566(-3/-1/+5))\n",
      "77/0 [------------------------------------------------------------] loss: +1.123E-03 / score: +0.610(-3/+4/+5))\n",
      "78/0 [------------------------------------------------------------] loss: +1.452E-03 / score: +0.590(-3/-1/+5))\n",
      "79/0 [------------------------------------------------------------] loss: +1.186E-03 / score: +0.620(-3/+3/+5))\n",
      "80/0 [------------------------------------------------------------] loss: +1.730E-02 / score: +0.650(-3/+3/+5))\n",
      "81/0 [------------------------------------------------------------] loss: +1.805E-02 / score: +0.691(-3/+4/+5))\n",
      "82/0 [------------------------------------------------------------] loss: +1.391E-03 / score: +0.671(-3/-1/+5))\n",
      "83/0 [------------------------------------------------------------] loss: +8.170E-04 / score: +0.675(-3/+1/+5))\n",
      "84/0 [------------------------------------------------------------] loss: +2.341E-03 / score: +0.702(-3/+3/+5))\n",
      "85/0 [------------------------------------------------------------] loss: +2.287E-03 / score: +0.741(-3/+4/+5))\n",
      "86/0 [------------------------------------------------------------] loss: +1.934E-03 / score: +0.721(-3/-1/+5))\n",
      "87/0 [------------------------------------------------------------] loss: +4.519E-03 / score: +0.736(-3/+2/+5))\n",
      "88/0 [------------------------------------------------------------] loss: +2.597E-03 / score: +0.761(-3/+3/+5))\n",
      "89/0 [------------------------------------------------------------] loss: +1.926E-02 / score: +0.798(-3/+4/+5))\n",
      "90/0 [------------------------------------------------------------] loss: +4.980E-03 / score: +0.789(-3/+0/+5))\n",
      "91/0 [------------------------------------------------------------] loss: +4.905E-03 / score: +0.802(-3/+2/+5))\n",
      "92/0 [------------------------------------------------------------] loss: +9.228E-03 / score: +0.793(-3/+0/+5))\n",
      "93/0 [------------------------------------------------------------] loss: +1.797E-02 / score: +0.796(-3/+1/+5))\n",
      "94/0 [------------------------------------------------------------] loss: +1.334E-02 / score: +0.819(-3/+3/+5))\n",
      "95/0 [------------------------------------------------------------] loss: +3.902E-03 / score: +0.842(-3/+3/+5))\n",
      "96/0 [------------------------------------------------------------] loss: +1.397E-02 / score: +0.885(-3/+5/+5))\n",
      "97/0 [------------------------------------------------------------] loss: +2.436E-02 / score: +0.887(-3/+1/+5))\n",
      "98/0 [------------------------------------------------------------] loss: +4.602E-03 / score: +0.949(-3/+7/+7))\n",
      "99/0 [------------------------------------------------------------] loss: +6.660E-03 / score: +0.949(-3/+1/+7))\n",
      "100/0 [------------------------------------------------------------] loss: +1.317E-02 / score: +0.940(-3/+0/+7)\n",
      "101/0 [------------------------------------------------------------] loss: +5.035E-03 / score: +0.960(-3/+2/+7))\n",
      "102/0 [------------------------------------------------------------] loss: +9.444E-03 / score: +1.000(-3/+3/+7))\n",
      "103/0 [------------------------------------------------------------] loss: +2.838E-03 / score: +1.040(-3/+3/+7))\n",
      "104/0 [------------------------------------------------------------] loss: +1.574E-02 / score: +1.070(-3/+2/+7))\n",
      "105/0 [------------------------------------------------------------] loss: +3.484E-02 / score: +1.070(-3/+0/+7))\n",
      "106/0 [------------------------------------------------------------] loss: +2.000E-03 / score: +1.090(-3/+1/+7))\n",
      "107/0 [------------------------------------------------------------] loss: +7.189E-03 / score: +1.090(-3/+1/+7))\n",
      "108/0 [------------------------------------------------------------] loss: +7.937E-03 / score: +1.090(-3/-1/+7))\n",
      "109/0 [------------------------------------------------------------] loss: +7.645E-03 / score: +1.120(-3/+3/+7))\n",
      "110/0 [------------------------------------------------------------] loss: +1.461E-02 / score: +1.130(-3/+1/+7))\n",
      "111/0 [------------------------------------------------------------] loss: +1.317E-02 / score: +1.180(-3/+5/+7))\n",
      "112/0 [------------------------------------------------------------] loss: +9.111E-03 / score: +1.210(-3/+2/+7))\n",
      "113/0 [------------------------------------------------------------] loss: +1.041E-02 / score: +1.170(-3/+0/+7))\n",
      "114/0 [------------------------------------------------------------] loss: +9.396E-03 / score: +1.210(-3/+2/+7))\n",
      "115/0 [------------------------------------------------------------] loss: +1.425E-02 / score: +1.220(-3/+2/+7))\n",
      "116/0 [------------------------------------------------------------] loss: +4.993E-03 / score: +1.230(-3/+1/+7))\n",
      "117/0 [------------------------------------------------------------] loss: +5.020E-03 / score: +1.240(-3/+1/+7))\n",
      "118/0 [------------------------------------------------------------] loss: +4.551E-02 / score: +1.240(-3/+1/+7))\n",
      "119/0 [------------------------------------------------------------] loss: +5.577E-03 / score: +1.250(-3/+3/+7))\n",
      "120/0 [------------------------------------------------------------] loss: +2.006E-03 / score: +1.250(-3/+1/+7))\n",
      "121/0 [------------------------------------------------------------] loss: +4.340E-03 / score: +1.320(-3/+7/+7))\n",
      "122/0 [------------------------------------------------------------] loss: +6.145E-03 / score: +1.310(-3/+0/+7))\n",
      "123/0 [------------------------------------------------------------] loss: +1.120E-02 / score: +1.350(-3/+3/+7))\n",
      "124/0 [------------------------------------------------------------] loss: +9.534E-03 / score: +1.390(-3/+4/+7))\n",
      "125/0 [------------------------------------------------------------] loss: +7.334E-03 / score: +1.420(-3/+1/+7))\n",
      "126/0 [------------------------------------------------------------] loss: +9.812E-03 / score: +1.400(-3/+0/+7))\n",
      "127/0 [------------------------------------------------------------] loss: +2.311E-02 / score: +1.420(-3/+1/+7))\n",
      "128/0 [------------------------------------------------------------] loss: +1.631E-02 / score: +1.430(-3/+1/+7))\n",
      "129/0 [------------------------------------------------------------] loss: +1.653E-02 / score: +1.450(-3/+2/+7))\n",
      "130/0 [------------------------------------------------------------] loss: +4.566E-03 / score: +1.510(-3/+7/+7))\n",
      "131/0 [------------------------------------------------------------] loss: +2.303E-02 / score: +1.520(-3/+2/+7))\n",
      "132/0 [------------------------------------------------------------] loss: +5.735E-03 / score: +1.570(-3/+4/+7))\n",
      "133/0 [------------------------------------------------------------] loss: +1.433E-02 / score: +1.640(-3/+5/+7))\n",
      "134/0 [------------------------------------------------------------] loss: +3.353E-02 / score: +1.690(-3/+5/+7))\n",
      "135/0 [------------------------------------------------------------] loss: +2.584E-02 / score: +1.720(-3/+3/+7))\n",
      "136/0 [------------------------------------------------------------] loss: +3.385E-02 / score: +1.780(-3/+5/+7))\n",
      "137/0 [------------------------------------------------------------] loss: +1.965E-02 / score: +1.800(-3/+1/+7))\n",
      "138/0 [------------------------------------------------------------] loss: +4.569E-02 / score: +1.820(-3/+3/+7))\n",
      "139/0 [------------------------------------------------------------] loss: +3.259E-02 / score: +1.840(-3/+2/+7))\n",
      "140/0 [------------------------------------------------------------] loss: +3.407E-02 / score: +1.820(-3/+1/+7))\n",
      "141/0 [------------------------------------------------------------] loss: +2.537E-02 / score: +1.830(-3/+1/+7))\n",
      "142/0 [------------------------------------------------------------] loss: +1.376E-02 / score: +1.870(-3/+2/+7))\n",
      "143/0 [------------------------------------------------------------] loss: +1.170E-03 / score: +1.880(-3/+1/+7))\n",
      "144/0 [------------------------------------------------------------] loss: +1.245E-02 / score: +1.860(-3/+1/+7))\n",
      "145/0 [------------------------------------------------------------] loss: +1.895E-02 / score: +1.880(-3/+3/+7))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/0 [------------------------------------------------------------] loss: +2.727E-02 / score: +1.880(-3/+1/+7))\n",
      "147/0 [------------------------------------------------------------] loss: +1.537E-02 / score: +1.860(-3/+2/+7))\n",
      "148/0 [------------------------------------------------------------] loss: +3.088E-02 / score: +1.910(-3/+6/+7))\n",
      "149/0 [------------------------------------------------------------] loss: +4.609E-02 / score: +1.960(-3/+5/+7))\n",
      "150/0 [------------------------------------------------------------] loss: +3.847E-02 / score: +1.980(-3/+2/+7))\n",
      "151/0 [------------------------------------------------------------] loss: +1.006E-02 / score: +2.000(-3/+4/+7))\n",
      "152/0 [------------------------------------------------------------] loss: +2.453E-02 / score: +2.030(-3/+2/+7))\n",
      "153/0 [------------------------------------------------------------] loss: +1.132E-02 / score: +2.030(-3/+1/+7))\n",
      "154/0 [------------------------------------------------------------] loss: +1.983E-02 / score: +2.030(-3/+0/+7))\n",
      "155/0 [------------------------------------------------------------] loss: +3.082E-02 / score: +2.080(-3/+5/+7))\n",
      "156/0 [------------------------------------------------------------] loss: +1.083E-02 / score: +2.100(-3/+5/+7))\n",
      "157/0 [------------------------------------------------------------] loss: +5.302E-03 / score: +2.120(-3/+2/+7))\n",
      "158/0 [------------------------------------------------------------] loss: +2.152E-02 / score: +2.110(-3/+0/+7))\n",
      "159/0 [------------------------------------------------------------] loss: +2.318E-02 / score: +2.130(-3/+6/+7))\n",
      "160/0 [------------------------------------------------------------] loss: +2.753E-02 / score: +2.120(-3/+4/+7))\n",
      "161/0 [------------------------------------------------------------] loss: +1.958E-02 / score: +2.130(-3/+0/+7))\n",
      "162/0 [------------------------------------------------------------] loss: +8.620E-03 / score: +2.120(-3/+1/+7))\n",
      "163/0 [------------------------------------------------------------] loss: +2.638E-02 / score: +2.150(-3/+5/+7))\n",
      "164/0 [------------------------------------------------------------] loss: +2.477E-02 / score: +2.190(-1/+1/+7))\n",
      "165/0 [------------------------------------------------------------] loss: +1.833E-02 / score: +2.230(-1/+3/+7))\n",
      "166/0 [------------------------------------------------------------] loss: +3.311E-02 / score: +2.280(-1/+6/+7))\n",
      "167/0 [------------------------------------------------------------] loss: +2.536E-02 / score: +2.320(-1/+5/+7))\n",
      "168/0 [------------------------------------------------------------] loss: +1.571E-02 / score: +2.300(-1/+2/+7))\n",
      "169/0 [------------------------------------------------------------] loss: +3.604E-02 / score: +2.290(-1/+1/+7))\n",
      "170/0 [------------------------------------------------------------] loss: +2.659E-02 / score: +2.350(-1/+6/+7))\n",
      "171/0 [------------------------------------------------------------] loss: +2.416E-02 / score: +2.380(-1/+6/+7))\n",
      "172/0 [------------------------------------------------------------] loss: +2.966E-02 / score: +2.380(-1/+2/+7))\n",
      "173/0 [------------------------------------------------------------] loss: +2.307E-02 / score: +2.370(-1/+1/+7))\n",
      "174/0 [------------------------------------------------------------] loss: +1.442E-02 / score: +2.360(-1/+1/+7))\n",
      "175/0 [------------------------------------------------------------] loss: +4.588E-02 / score: +2.410(-1/+8/+8))\n",
      "176/0 [------------------------------------------------------------] loss: +2.970E-02 / score: +2.450(-1/+3/+8))\n",
      "177/0 [------------------------------------------------------------] loss: +1.224E-02 / score: +2.460(-1/+5/+8))\n",
      "178/0 [------------------------------------------------------------] loss: +1.657E-02 / score: +2.500(-1/+3/+8))\n",
      "179/0 [------------------------------------------------------------] loss: +1.472E-02 / score: +2.510(-1/+4/+8))\n",
      "180/0 [------------------------------------------------------------] loss: +3.685E-02 / score: +2.590(-1/+11/+11)\n",
      "181/0 [------------------------------------------------------------] loss: +2.771E-02 / score: +2.560(-1/+1/+11)1)\n",
      "182/0 [------------------------------------------------------------] loss: +1.822E-02 / score: +2.620(-1/+5/+11))\n",
      "183/0 [------------------------------------------------------------] loss: +1.183E-02 / score: +2.650(-1/+4/+11))\n",
      "184/0 [------------------------------------------------------------] loss: +1.327E-02 / score: +2.670(-1/+5/+11))\n",
      "185/0 [------------------------------------------------------------] loss: +3.649E-02 / score: +2.680(-1/+5/+11))\n",
      "186/0 [------------------------------------------------------------] loss: +4.588E-03 / score: +2.700(-1/+1/+11))\n",
      "187/0 [------------------------------------------------------------] loss: +1.707E-02 / score: +2.730(-1/+5/+11))\n",
      "188/0 [------------------------------------------------------------] loss: +1.314E-02 / score: +2.720(-1/+2/+11))\n",
      "189/0 [------------------------------------------------------------] loss: +2.720E-02 / score: +2.740(-1/+6/+11))\n",
      "190/0 [------------------------------------------------------------] loss: +2.035E-02 / score: +2.770(-1/+3/+11))\n",
      "191/0 [------------------------------------------------------------] loss: +6.494E-03 / score: +2.810(-1/+6/+11))\n",
      "192/0 [------------------------------------------------------------] loss: +1.441E-02 / score: +2.840(-1/+3/+11))\n",
      "193/0 [------------------------------------------------------------] loss: +1.142E-02 / score: +2.910(-1/+8/+11))\n",
      "194/0 [------------------------------------------------------------] loss: +2.565E-02 / score: +2.950(-1/+7/+11))\n",
      "195/0 [------------------------------------------------------------] loss: +1.450E-02 / score: +2.980(-1/+6/+11))\n",
      "196/0 [------------------------------------------------------------] loss: +3.066E-02 / score: +2.970(-1/+4/+11))\n",
      "197/0 [------------------------------------------------------------] loss: +1.213E-02 / score: +3.060(-1/+10/+11)\n",
      "198/0 [------------------------------------------------------------] loss: +4.885E-03 / score: +3.040(-1/+5/+11)1)\n",
      "199/0 [------------------------------------------------------------] loss: +5.736E-03 / score: +3.130(-1/+10/+11)\n",
      "200/0 [------------------------------------------------------------] loss: +4.070E-02 / score: +3.200(-1/+7/+11)1)\n",
      "201/0 [------------------------------------------------------------] loss: +2.509E-02 / score: +3.250(-1/+7/+11))\n",
      "202/0 [------------------------------------------------------------] loss: +6.409E-03 / score: +3.300(-1/+8/+11))\n",
      "203/0 [------------------------------------------------------------] loss: +5.543E-02 / score: +3.330(-1/+6/+11))\n",
      "204/0 [------------------------------------------------------------] loss: +1.272E-02 / score: +3.380(-1/+7/+11))\n",
      "205/0 [------------------------------------------------------------] loss: +2.170E-02 / score: +3.410(-1/+3/+11))\n",
      "206/0 [------------------------------------------------------------] loss: +1.723E-02 / score: +3.470(-1/+7/+11))\n",
      "207/0 [------------------------------------------------------------] loss: +1.046E-02 / score: +3.530(-1/+7/+11))\n",
      "208/0 [------------------------------------------------------------] loss: +9.635E-03 / score: +3.600(+0/+6/+11))\n",
      "209/0 [------------------------------------------------------------] loss: +5.007E-02 / score: +3.640(+0/+7/+11))\n",
      "210/0 [------------------------------------------------------------] loss: +4.385E-02 / score: +3.680(+0/+5/+11))\n",
      "211/0 [------------------------------------------------------------] loss: +1.554E-02 / score: +3.700(+0/+7/+11))\n",
      "212/0 [------------------------------------------------------------] loss: +2.538E-02 / score: +3.720(+0/+4/+11))\n",
      "213/0 [------------------------------------------------------------] loss: +7.627E-03 / score: +3.790(+0/+7/+11))\n",
      "214/0 [------------------------------------------------------------] loss: +7.151E-03 / score: +3.820(+0/+5/+11))\n",
      "215/0 [------------------------------------------------------------] loss: +3.323E-02 / score: +3.910(+0/+11/+11)\n",
      "216/0 [------------------------------------------------------------] loss: +2.567E-02 / score: +3.910(+0/+1/+11)1)\n",
      "217/0 [------------------------------------------------------------] loss: +2.457E-02 / score: +3.970(+0/+7/+11))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/0 [------------------------------------------------------------] loss: +3.894E-02 / score: +4.020(+0/+6/+11))\n",
      "219/0 [------------------------------------------------------------] loss: +1.924E-02 / score: +4.100(+0/+11/+11)\n",
      "220/0 [------------------------------------------------------------] loss: +1.765E-02 / score: +4.170(+0/+8/+11)1)\n",
      "221/0 [------------------------------------------------------------] loss: +1.959E-02 / score: +4.150(+0/+5/+11))\n",
      "222/0 [------------------------------------------------------------] loss: +1.441E-02 / score: +4.240(+0/+9/+11))\n",
      "223/0 [------------------------------------------------------------] loss: +3.485E-02 / score: +4.300(+0/+9/+11))\n",
      "224/0 [------------------------------------------------------------] loss: +3.211E-02 / score: +4.310(+0/+5/+11))\n",
      "225/0 [------------------------------------------------------------] loss: +4.236E-02 / score: +4.340(+0/+4/+11))\n",
      "226/0 [------------------------------------------------------------] loss: +2.112E-02 / score: +4.440(+0/+10/+11)\n",
      "227/0 [------------------------------------------------------------] loss: +1.412E-02 / score: +4.500(+0/+7/+11)1)\n",
      "228/0 [------------------------------------------------------------] loss: +3.019E-02 / score: +4.590(+0/+10/+11)\n",
      "229/0 [------------------------------------------------------------] loss: +2.070E-02 / score: +4.640(+0/+7/+11)1)\n",
      "230/0 [------------------------------------------------------------] loss: +3.283E-02 / score: +4.590(+0/+2/+11))\n",
      "231/0 [------------------------------------------------------------] loss: +4.230E-02 / score: +4.670(+0/+10/+11)\n",
      "232/0 [------------------------------------------------------------] loss: +9.108E-03 / score: +4.690(+0/+6/+11)1)\n",
      "233/0 [------------------------------------------------------------] loss: +2.529E-02 / score: +4.690(+0/+5/+11))\n",
      "234/0 [------------------------------------------------------------] loss: +1.395E-02 / score: +4.720(+0/+8/+11))\n",
      "235/0 [------------------------------------------------------------] loss: +2.467E-02 / score: +4.760(+0/+7/+11))\n",
      "236/0 [------------------------------------------------------------] loss: +1.591E-02 / score: +4.790(+0/+8/+11))\n",
      "237/0 [------------------------------------------------------------] loss: +1.342E-02 / score: +4.860(+0/+8/+11))\n",
      "238/0 [------------------------------------------------------------] loss: +1.215E-02 / score: +4.930(+0/+10/+11)\n",
      "239/0 [------------------------------------------------------------] loss: +4.847E-02 / score: +5.030(+0/+12/+12))\n",
      "240/0 [------------------------------------------------------------] loss: +1.647E-02 / score: +5.120(+0/+10/+12))\n",
      "241/0 [------------------------------------------------------------] loss: +8.705E-03 / score: +5.230(+0/+12/+12))\n",
      "242/0 [------------------------------------------------------------] loss: +2.177E-02 / score: +5.340(+0/+13/+13))\n",
      "243/0 [------------------------------------------------------------] loss: +1.218E-02 / score: +5.390(+0/+6/+13)3)\n",
      "244/0 [------------------------------------------------------------] loss: +2.097E-02 / score: +5.380(+0/+0/+13))\n",
      "245/0 [------------------------------------------------------------] loss: +3.903E-03 / score: +5.440(+0/+9/+13))\n",
      "246/0 [------------------------------------------------------------] loss: +6.195E-02 / score: +5.500(+0/+7/+13))\n",
      "247/0 [------------------------------------------------------------] loss: +1.488E-02 / score: +5.560(+0/+8/+13))\n",
      "248/0 [------------------------------------------------------------] loss: +1.250E-02 / score: +5.600(+0/+10/+13)\n",
      "249/0 [------------------------------------------------------------] loss: +1.432E-02 / score: +5.560(+0/+1/+13)3)\n",
      "250/0 [------------------------------------------------------------] loss: +2.508E-02 / score: +5.650(+0/+11/+13)\n",
      "251/0 [------------------------------------------------------------] loss: +2.849E-02 / score: +5.690(+0/+8/+13)3)\n",
      "252/0 [------------------------------------------------------------] loss: +1.373E-02 / score: +5.770(+0/+10/+13)\n",
      "253/0 [------------------------------------------------------------] loss: +2.105E-02 / score: +5.790(+0/+3/+13)3)\n",
      "254/0 [------------------------------------------------------------] loss: +6.103E-02 / score: +5.830(+0/+4/+13))\n",
      "255/0 [------------------------------------------------------------] loss: +5.026E-02 / score: +5.870(+0/+9/+13))\n",
      "256/0 [------------------------------------------------------------] loss: +1.920E-02 / score: +5.850(+0/+3/+13))\n",
      "257/0 [------------------------------------------------------------] loss: +2.310E-02 / score: +5.900(+0/+7/+13))\n",
      "258/0 [------------------------------------------------------------] loss: +1.868E-02 / score: +6.010(+0/+11/+13)\n",
      "259/0 [------------------------------------------------------------] loss: +7.062E-02 / score: +5.980(+0/+3/+13)3)\n",
      "260/0 [------------------------------------------------------------] loss: +6.435E-02 / score: +6.020(+0/+8/+13))\n",
      "261/0 [------------------------------------------------------------] loss: +2.267E-02 / score: +6.130(+0/+11/+13)\n",
      "262/0 [------------------------------------------------------------] loss: +1.004E-01 / score: +6.190(+0/+7/+13)3)\n",
      "263/0 [------------------------------------------------------------] loss: +1.001E-01 / score: +6.220(+0/+8/+13))\n",
      "264/0 [------------------------------------------------------------] loss: +2.496E-02 / score: +6.250(+0/+4/+13))\n",
      "265/0 [------------------------------------------------------------] loss: +7.109E-02 / score: +6.320(+0/+10/+13)\n",
      "266/0 [------------------------------------------------------------] loss: +5.843E-02 / score: +6.330(+0/+7/+13)3)\n",
      "267/0 [------------------------------------------------------------] loss: +3.467E-02 / score: +6.360(+0/+8/+13))\n",
      "268/0 [------------------------------------------------------------] loss: +6.256E-02 / score: +6.490(+0/+15/+15)\n",
      "269/0 [------------------------------------------------------------] loss: +1.065E-02 / score: +6.600(+0/+12/+15))\n",
      "270/0 [------------------------------------------------------------] loss: +2.736E-02 / score: +6.610(+0/+7/+15)5)\n",
      "271/0 [------------------------------------------------------------] loss: +2.089E-02 / score: +6.610(+0/+6/+15))\n",
      "272/0 [------------------------------------------------------------] loss: +4.348E-02 / score: +6.680(+0/+9/+15))\n",
      "273/0 [------------------------------------------------------------] loss: +1.757E-02 / score: +6.700(+0/+3/+15))\n",
      "274/0 [------------------------------------------------------------] loss: +4.810E-02 / score: +6.720(+0/+3/+15))\n",
      "275/0 [------------------------------------------------------------] loss: +7.886E-03 / score: +6.730(+0/+9/+15))\n",
      "276/0 [------------------------------------------------------------] loss: +2.252E-02 / score: +6.730(+0/+3/+15))\n",
      "277/0 [------------------------------------------------------------] loss: +6.412E-02 / score: +6.690(+0/+1/+15))\n",
      "278/0 [------------------------------------------------------------] loss: +7.449E-02 / score: +6.750(+0/+9/+15))\n",
      "279/0 [------------------------------------------------------------] loss: +1.848E-02 / score: +6.760(+0/+5/+15))\n",
      "280/0 [------------------------------------------------------------] loss: +2.583E-02 / score: +6.720(+0/+7/+15))\n",
      "281/0 [------------------------------------------------------------] loss: +2.240E-02 / score: +6.860(+0/+15/+15)\n",
      "282/0 [------------------------------------------------------------] loss: +7.212E-02 / score: +6.880(+0/+7/+15)5)\n",
      "283/0 [------------------------------------------------------------] loss: +1.970E-01 / score: +6.900(+0/+6/+15))\n",
      "284/0 [------------------------------------------------------------] loss: +1.238E-02 / score: +6.870(+0/+2/+15))\n",
      "285/0 [------------------------------------------------------------] loss: +1.423E-02 / score: +6.890(+0/+7/+15))\n",
      "286/0 [------------------------------------------------------------] loss: +1.476E-02 / score: +6.910(+0/+3/+15))\n",
      "287/0 [------------------------------------------------------------] loss: +9.260E-02 / score: +6.950(+0/+9/+15))\n",
      "288/0 [------------------------------------------------------------] loss: +2.136E-02 / score: +7.030(+0/+10/+15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/0 [------------------------------------------------------------] loss: +3.583E-02 / score: +7.060(+0/+9/+15)5)\n",
      "290/0 [------------------------------------------------------------] loss: +1.071E-01 / score: +7.110(+0/+8/+15))\n",
      "291/0 [------------------------------------------------------------] loss: +5.586E-02 / score: +7.150(+0/+10/+15)\n",
      "292/0 [------------------------------------------------------------] loss: +6.716E-02 / score: +7.270(+0/+15/+15))\n",
      "293/0 [------------------------------------------------------------] loss: +3.256E-02 / score: +7.290(+0/+10/+15))\n",
      "294/0 [------------------------------------------------------------] loss: +9.485E-02 / score: +7.300(+0/+8/+15)5)\n",
      "295/0 [------------------------------------------------------------] loss: +1.108E-02 / score: +7.340(+0/+10/+15)\n",
      "296/0 [------------------------------------------------------------] loss: +1.690E-02 / score: +7.380(+0/+8/+15)5)\n",
      "297/0 [------------------------------------------------------------] loss: +5.075E-02 / score: +7.380(+0/+10/+15)\n",
      "298/0 [------------------------------------------------------------] loss: +1.108E-02 / score: +7.400(+0/+7/+15)5)\n",
      "299/0 [------------------------------------------------------------] loss: +9.079E-02 / score: +7.420(+0/+12/+15)\n",
      "300/0 [------------------------------------------------------------] loss: +2.914E-02 / score: +7.400(+0/+5/+15)5)\n",
      "301/0 [------------------------------------------------------------] loss: +1.831E-02 / score: +7.450(+0/+12/+15)\n",
      "302/0 [------------------------------------------------------------] loss: +3.045E-02 / score: +7.490(+0/+12/+15))\n",
      "303/0 [------------------------------------------------------------] loss: +4.422E-02 / score: +7.590(+0/+16/+16))\n",
      "304/0 [------------------------------------------------------------] loss: +4.015E-02 / score: +7.630(+0/+11/+16))\n",
      "305/0 [------------------------------------------------------------] loss: +1.536E-02 / score: +7.690(+0/+9/+16)6)\n",
      "306/0 [------------------------------------------------------------] loss: +1.007E-01 / score: +7.700(+0/+8/+16))\n",
      "307/0 [------------------------------------------------------------] loss: +3.886E-02 / score: +7.680(+0/+5/+16))\n",
      "308/0 [------------------------------------------------------------] loss: +7.865E-02 / score: +7.700(+0/+8/+16))\n",
      "309/0 [------------------------------------------------------------] loss: +8.441E-02 / score: +7.760(+0/+13/+16)\n",
      "310/0 [------------------------------------------------------------] loss: +2.298E-02 / score: +7.840(+0/+13/+16))\n",
      "311/0 [------------------------------------------------------------] loss: +3.542E-02 / score: +7.920(+0/+15/+16))\n",
      "312/0 [------------------------------------------------------------] loss: +2.752E-02 / score: +8.010(+0/+13/+16))\n",
      "313/0 [------------------------------------------------------------] loss: +3.758E-02 / score: +8.040(+0/+10/+16))\n",
      "314/0 [------------------------------------------------------------] loss: +1.222E-02 / score: +8.130(+0/+14/+16))\n",
      "315/0 [------------------------------------------------------------] loss: +5.623E-03 / score: +8.060(+0/+4/+16)6)\n",
      "316/0 [------------------------------------------------------------] loss: +3.795E-02 / score: +8.180(+0/+13/+16)\n",
      "317/0 [------------------------------------------------------------] loss: +1.364E-01 / score: +8.170(+0/+6/+16)6)\n",
      "318/0 [------------------------------------------------------------] loss: +1.444E-02 / score: +8.210(+0/+10/+16)\n",
      "319/0 [------------------------------------------------------------] loss: +1.859E-02 / score: +8.230(+0/+13/+16))\n",
      "320/0 [------------------------------------------------------------] loss: +1.328E-02 / score: +8.260(+0/+11/+16))\n",
      "321/0 [------------------------------------------------------------] loss: +2.784E-02 / score: +8.270(+0/+6/+16)6)\n",
      "322/0 [------------------------------------------------------------] loss: +2.773E-02 / score: +8.270(+0/+9/+16))\n",
      "323/0 [------------------------------------------------------------] loss: +1.467E-02 / score: +8.240(+0/+6/+16))\n",
      "324/0 [------------------------------------------------------------] loss: +1.967E-02 / score: +8.280(+0/+9/+16))\n",
      "325/0 [------------------------------------------------------------] loss: +2.679E-02 / score: +8.350(+0/+11/+16)\n",
      "326/0 [------------------------------------------------------------] loss: +1.546E-02 / score: +8.360(+0/+11/+16))\n",
      "327/0 [------------------------------------------------------------] loss: +3.882E-02 / score: +8.430(+0/+14/+16))\n",
      "328/0 [------------------------------------------------------------] loss: +3.640E-02 / score: +8.490(+0/+16/+16))\n",
      "329/0 [------------------------------------------------------------] loss: +4.463E-02 / score: +8.530(+0/+11/+16))\n",
      "330/0 [------------------------------------------------------------] loss: +7.608E-02 / score: +8.570(+0/+6/+16)6)\n",
      "331/0 [------------------------------------------------------------] loss: +8.678E-02 / score: +8.520(+0/+5/+16))\n",
      "332/0 [------------------------------------------------------------] loss: +9.180E-02 / score: +8.530(+0/+7/+16))\n",
      "333/0 [------------------------------------------------------------] loss: +2.144E-02 / score: +8.620(+0/+14/+16)\n",
      "334/0 [------------------------------------------------------------] loss: +1.853E-02 / score: +8.630(+0/+9/+16)6)\n",
      "335/0 [------------------------------------------------------------] loss: +2.255E-02 / score: +8.690(+0/+13/+16)\n",
      "336/0 [------------------------------------------------------------] loss: +1.984E-02 / score: +8.680(+0/+7/+16)6)\n",
      "337/0 [------------------------------------------------------------] loss: +9.943E-03 / score: +8.690(+0/+9/+16))\n",
      "338/0 [------------------------------------------------------------] loss: +1.565E-02 / score: +8.670(+0/+8/+16))\n",
      "339/0 [------------------------------------------------------------] loss: +1.711E-02 / score: +8.710(+0/+16/+16)\n",
      "340/0 [------------------------------------------------------------] loss: +3.319E-02 / score: +8.720(+0/+11/+16))\n",
      "341/0 [------------------------------------------------------------] loss: +1.185E-01 / score: +8.810(+0/+21/+21))\n",
      "342/0 [------------------------------------------------------------] loss: +3.663E-02 / score: +8.820(+0/+14/+21))\n",
      "343/0 [------------------------------------------------------------] loss: +2.864E-02 / score: +8.890(+0/+13/+21))\n",
      "344/0 [------------------------------------------------------------] loss: +3.978E-02 / score: +8.980(+1/+9/+21)1)\n",
      "345/0 [------------------------------------------------------------] loss: +1.105E-02 / score: +8.940(+1/+5/+21))\n",
      "346/0 [------------------------------------------------------------] loss: +2.323E-02 / score: +8.930(+1/+6/+21))\n",
      "347/0 [------------------------------------------------------------] loss: +2.764E-02 / score: +9.000(+1/+15/+21)\n",
      "348/0 [------------------------------------------------------------] loss: +2.938E-02 / score: +9.000(+1/+10/+21))\n",
      "349/0 [------------------------------------------------------------] loss: +1.412E-02 / score: +9.130(+1/+14/+21))\n",
      "350/0 [------------------------------------------------------------] loss: +2.473E-02 / score: +9.140(+1/+12/+21))\n",
      "351/0 [------------------------------------------------------------] loss: +1.281E-01 / score: +9.170(+1/+11/+21))\n",
      "352/0 [------------------------------------------------------------] loss: +8.911E-02 / score: +9.230(+1/+16/+21))\n",
      "353/0 [------------------------------------------------------------] loss: +2.745E-02 / score: +9.280(+1/+8/+21)1)\n",
      "354/0 [------------------------------------------------------------] loss: +1.089E-02 / score: +9.330(+1/+9/+21))\n",
      "355/0 [------------------------------------------------------------] loss: +2.740E-02 / score: +9.350(+1/+11/+21)\n",
      "356/0 [------------------------------------------------------------] loss: +1.171E-02 / score: +9.420(+1/+10/+21))\n",
      "357/0 [------------------------------------------------------------] loss: +1.070E-01 / score: +9.490(+1/+14/+21))\n",
      "358/0 [------------------------------------------------------------] loss: +1.340E-01 / score: +9.530(+1/+15/+21))\n",
      "359/0 [------------------------------------------------------------] loss: +1.899E-02 / score: +9.670(+1/+17/+21))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/0 [------------------------------------------------------------] loss: +3.074E-02 / score: +9.640(+1/+5/+21)1)\n",
      "361/0 [------------------------------------------------------------] loss: +1.291E-02 / score: +9.620(+1/+9/+21))\n",
      "362/0 [------------------------------------------------------------] loss: +1.256E-02 / score: +9.700(+1/+15/+21)\n",
      "363/0 [------------------------------------------------------------] loss: +2.856E-02 / score: +9.650(+1/+3/+21)1)\n",
      "364/0 [------------------------------------------------------------] loss: +2.583E-02 / score: +9.700(+1/+9/+21))\n",
      "365/0 [------------------------------------------------------------] loss: +1.002E-01 / score: +9.740(+1/+14/+21)\n",
      "366/0 [------------------------------------------------------------] loss: +1.619E-02 / score: +9.770(+1/+10/+21))\n",
      "367/0 [------------------------------------------------------------] loss: +3.887E-02 / score: +9.800(+1/+11/+21))\n",
      "368/0 [------------------------------------------------------------] loss: +3.224E-02 / score: +9.760(+1/+11/+21))\n",
      "369/0 [------------------------------------------------------------] loss: +3.132E-02 / score: +9.800(+1/+16/+21))\n",
      "370/0 [------------------------------------------------------------] loss: +1.142E-02 / score: +9.870(+1/+14/+21))\n",
      "371/0 [------------------------------------------------------------] loss: +1.560E-01 / score: +9.900(+1/+9/+21)1)\n",
      "372/0 [------------------------------------------------------------] loss: +9.068E-02 / score: +9.960(+1/+15/+21)\n",
      "373/0 [------------------------------------------------------------] loss: +1.559E-02 / score: +10.040(+1/+11/+21)\n",
      "374/0 [------------------------------------------------------------] loss: +1.230E-01 / score: +10.110(+1/+10/+21))\n",
      "375/0 [------------------------------------------------------------] loss: +1.568E-02 / score: +10.090(+1/+7/+21)1)\n",
      "376/0 [------------------------------------------------------------] loss: +4.544E-02 / score: +10.070(+1/+1/+21))\n",
      "377/0 [------------------------------------------------------------] loss: +3.483E-02 / score: +10.180(+1/+12/+21)\n",
      "378/0 [------------------------------------------------------------] loss: +1.121E-02 / score: +10.220(+1/+13/+21))\n",
      "379/0 [------------------------------------------------------------] loss: +8.498E-03 / score: +10.270(+1/+10/+21))\n",
      "380/0 [------------------------------------------------------------] loss: +4.313E-02 / score: +10.260(+1/+6/+21)1)\n",
      "381/0 [------------------------------------------------------------] loss: +3.660E-02 / score: +10.230(+1/+12/+21)\n",
      "382/0 [------------------------------------------------------------] loss: +3.841E-02 / score: +10.280(+1/+12/+21))\n",
      "383/0 [------------------------------------------------------------] loss: +8.633E-03 / score: +10.360(+1/+14/+21))\n",
      "384/0 [------------------------------------------------------------] loss: +2.272E-02 / score: +10.460(+1/+12/+21))\n",
      "385/0 [------------------------------------------------------------] loss: +4.469E-02 / score: +10.460(+1/+7/+21)1)\n",
      "386/0 [------------------------------------------------------------] loss: +2.035E-02 / score: +10.530(+1/+10/+21)\n",
      "387/0 [------------------------------------------------------------] loss: +2.764E-01 / score: +10.520(+1/+8/+21)1)\n",
      "388/0 [------------------------------------------------------------] loss: +4.094E-02 / score: +10.530(+1/+11/+21)\n",
      "389/0 [------------------------------------------------------------] loss: +2.019E-02 / score: +10.550(+1/+11/+21))\n",
      "390/0 [------------------------------------------------------------] loss: +2.709E-02 / score: +10.630(+1/+16/+21))\n",
      "391/0 [------------------------------------------------------------] loss: +2.982E-02 / score: +10.730(+1/+20/+21))\n",
      "392/0 [------------------------------------------------------------] loss: +5.328E-02 / score: +10.670(+1/+9/+21)1)\n",
      "393/0 [------------------------------------------------------------] loss: +2.365E-02 / score: +10.740(+1/+17/+21)\n",
      "394/0 [------------------------------------------------------------] loss: +2.511E-02 / score: +10.730(+1/+7/+21)1)\n",
      "395/0 [------------------------------------------------------------] loss: +4.651E-02 / score: +10.750(+1/+12/+21)\n",
      "396/0 [------------------------------------------------------------] loss: +3.647E-02 / score: +10.800(+1/+13/+21))\n",
      "397/0 [------------------------------------------------------------] loss: +2.347E-02 / score: +10.840(+1/+14/+21))\n",
      "398/0 [------------------------------------------------------------] loss: +2.680E-02 / score: +10.860(+1/+9/+21)1)\n",
      "399/0 [------------------------------------------------------------] loss: +1.139E-02 / score: +10.800(+1/+6/+21))\n",
      "400/0 [------------------------------------------------------------] loss: +2.484E-02 / score: +10.870(+1/+12/+21)\n",
      "401/0 [------------------------------------------------------------] loss: +3.409E-02 / score: +10.870(+1/+12/+21))\n",
      "402/0 [------------------------------------------------------------] loss: +5.210E-02 / score: +10.930(+1/+18/+21))\n",
      "403/0 [------------------------------------------------------------] loss: +3.192E-01 / score: +10.870(+1/+10/+21))\n",
      "404/0 [------------------------------------------------------------] loss: +2.737E-02 / score: +10.880(+1/+12/+21))\n",
      "405/0 [------------------------------------------------------------] loss: +3.246E-02 / score: +10.870(+1/+8/+21)1)\n",
      "406/0 [------------------------------------------------------------] loss: +3.169E-02 / score: +10.940(+1/+15/+21)\n",
      "407/0 [------------------------------------------------------------] loss: +9.594E-02 / score: +11.040(+1/+15/+21))\n",
      "408/0 [------------------------------------------------------------] loss: +3.438E-02 / score: +11.050(+1/+9/+21)1)\n",
      "409/0 [------------------------------------------------------------] loss: +3.743E-02 / score: +11.020(+1/+10/+21)\n",
      "410/0 [------------------------------------------------------------] loss: +1.135E-01 / score: +10.960(+1/+7/+21)1)\n",
      "411/0 [------------------------------------------------------------] loss: +2.972E-02 / score: +10.880(+1/+7/+21))\n",
      "412/0 [------------------------------------------------------------] loss: +2.472E-02 / score: +10.830(+1/+8/+21))\n",
      "413/0 [------------------------------------------------------------] loss: +2.255E-02 / score: +10.800(+1/+7/+21))\n",
      "414/0 [------------------------------------------------------------] loss: +2.512E-02 / score: +10.800(+1/+14/+21)\n",
      "415/0 [------------------------------------------------------------] loss: +3.423E-02 / score: +10.870(+1/+11/+21))\n",
      "416/0 [------------------------------------------------------------] loss: +1.465E-02 / score: +10.830(+1/+9/+21)1)\n",
      "417/0 [------------------------------------------------------------] loss: +1.718E-02 / score: +10.870(+1/+10/+21)\n",
      "418/0 [------------------------------------------------------------] loss: +4.558E-02 / score: +10.820(+1/+5/+21)1)\n",
      "419/0 [------------------------------------------------------------] loss: +3.428E-02 / score: +10.760(+1/+7/+21))\n",
      "420/0 [------------------------------------------------------------] loss: +1.997E-02 / score: +10.680(+1/+3/+21))\n",
      "421/0 [------------------------------------------------------------] loss: +1.789E-02 / score: +10.710(+1/+9/+21))\n",
      "422/0 [------------------------------------------------------------] loss: +2.242E-02 / score: +10.640(+1/+2/+21))\n",
      "423/0 [------------------------------------------------------------] loss: +2.328E-02 / score: +10.690(+1/+11/+21)\n",
      "424/0 [------------------------------------------------------------] loss: +4.981E-02 / score: +10.670(+1/+7/+21)1)\n",
      "425/0 [------------------------------------------------------------] loss: +4.105E-02 / score: +10.660(+1/+10/+21)\n",
      "426/0 [------------------------------------------------------------] loss: +3.550E-02 / score: +10.690(+1/+14/+21))\n",
      "427/0 [------------------------------------------------------------] loss: +2.334E-01 / score: +10.660(+1/+11/+21))\n",
      "428/0 [------------------------------------------------------------] loss: +1.593E-02 / score: +10.620(+1/+12/+21))\n",
      "429/0 [------------------------------------------------------------] loss: +2.519E-02 / score: +10.620(+1/+11/+21))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/0 [------------------------------------------------------------] loss: +2.589E-02 / score: +10.710(+1/+15/+21))\n",
      "431/0 [------------------------------------------------------------] loss: +3.924E-02 / score: +10.740(+1/+8/+21)1)\n",
      "432/0 [------------------------------------------------------------] loss: +2.575E-02 / score: +10.770(+1/+10/+21)\n",
      "433/0 [------------------------------------------------------------] loss: +1.513E-02 / score: +10.760(+1/+13/+21))\n",
      "434/0 [------------------------------------------------------------] loss: +2.894E-02 / score: +10.780(+1/+11/+21))\n",
      "435/0 [------------------------------------------------------------] loss: +2.431E-02 / score: +10.830(+1/+18/+21))\n",
      "436/0 [------------------------------------------------------------] loss: +1.823E-02 / score: +10.920(+1/+16/+21))\n",
      "437/0 [------------------------------------------------------------] loss: +2.603E-02 / score: +11.000(+1/+17/+21))\n",
      "438/0 [------------------------------------------------------------] loss: +1.232E-01 / score: +11.030(+1/+11/+21))\n",
      "439/0 [------------------------------------------------------------] loss: +2.238E-02 / score: +10.980(+1/+11/+21))\n",
      "440/0 [------------------------------------------------------------] loss: +2.224E-02 / score: +10.990(+1/+12/+21))\n",
      "441/0 [------------------------------------------------------------] loss: +1.529E-02 / score: +10.930(+1/+15/+20))\n",
      "442/0 [------------------------------------------------------------] loss: +1.762E-02 / score: +10.820(+1/+3/+20)0)\n",
      "443/0 [------------------------------------------------------------] loss: +1.031E-02 / score: +10.740(+1/+5/+20))\n",
      "444/0 [------------------------------------------------------------] loss: +2.194E-02 / score: +10.730(+1/+8/+20))\n",
      "445/0 [------------------------------------------------------------] loss: +2.703E-02 / score: +10.850(+1/+17/+20)\n",
      "446/0 [------------------------------------------------------------] loss: +3.951E-02 / score: +10.940(+1/+15/+20))\n",
      "447/0 [------------------------------------------------------------] loss: +3.600E-02 / score: +10.940(+1/+15/+20))\n",
      "448/0 [------------------------------------------------------------] loss: +1.189E-02 / score: +10.970(+1/+13/+20))\n",
      "449/0 [------------------------------------------------------------] loss: +9.086E-03 / score: +10.930(+1/+10/+20))\n",
      "450/0 [------------------------------------------------------------] loss: +1.567E-02 / score: +10.910(+1/+10/+20))\n",
      "451/0 [------------------------------------------------------------] loss: +2.600E-02 / score: +10.880(+1/+8/+20)0)\n",
      "452/0 [------------------------------------------------------------] loss: +2.976E-02 / score: +10.890(+1/+17/+20)\n",
      "453/0 [------------------------------------------------------------] loss: +1.398E-01 / score: +10.970(+1/+16/+20))\n",
      "454/0 [------------------------------------------------------------] loss: +1.763E-01 / score: +11.020(+1/+14/+20))\n",
      "455/0 [------------------------------------------------------------] loss: +3.966E-02 / score: +11.020(+1/+11/+20))\n",
      "456/0 [------------------------------------------------------------] loss: +1.188E-02 / score: +11.060(+1/+14/+20))\n",
      "457/0 [------------------------------------------------------------] loss: +3.658E-02 / score: +11.000(+1/+8/+20)0)\n",
      "458/0 [------------------------------------------------------------] loss: +2.423E-02 / score: +10.920(+1/+7/+20))\n",
      "459/0 [------------------------------------------------------------] loss: +2.385E-02 / score: +10.890(+1/+14/+20)\n",
      "460/0 [------------------------------------------------------------] loss: +1.828E-02 / score: +11.060(+1/+22/+22))\n",
      "461/0 [------------------------------------------------------------] loss: +1.861E-02 / score: +11.090(+1/+12/+22))\n",
      "462/0 [------------------------------------------------------------] loss: +1.405E-02 / score: +11.110(+1/+17/+22))\n",
      "463/0 [------------------------------------------------------------] loss: +1.611E-02 / score: +11.210(+1/+13/+22))\n",
      "464/0 [------------------------------------------------------------] loss: +3.853E-02 / score: +11.250(+1/+13/+22))\n",
      "465/0 [------------------------------------------------------------] loss: +1.922E-02 / score: +11.200(+1/+9/+22)2)\n",
      "466/0 [------------------------------------------------------------] loss: +3.011E-02 / score: +11.310(+1/+21/+22)\n",
      "467/0 [------------------------------------------------------------] loss: +3.648E-02 / score: +11.300(+1/+10/+22))\n",
      "468/0 [------------------------------------------------------------] loss: +1.528E-01 / score: +11.330(+1/+14/+22))\n",
      "469/0 [------------------------------------------------------------] loss: +1.940E-02 / score: +11.270(+1/+10/+22))\n",
      "470/0 [------------------------------------------------------------] loss: +3.301E-01 / score: +11.260(+1/+13/+22))\n",
      "471/0 [------------------------------------------------------------] loss: +2.027E-02 / score: +11.320(+1/+15/+22))\n",
      "472/0 [------------------------------------------------------------] loss: +1.294E-02 / score: +11.340(+1/+17/+22))\n",
      "473/0 [------------------------------------------------------------] loss: +3.230E-02 / score: +11.360(+1/+13/+22))\n",
      "474/0 [------------------------------------------------------------] loss: +2.136E-02 / score: +11.390(+1/+13/+22))\n",
      "475/0 [------------------------------------------------------------] loss: +1.353E-01 / score: +11.430(+1/+11/+22))\n",
      "476/0 [------------------------------------------------------------] loss: +2.238E-02 / score: +11.570(+2/+15/+22))\n",
      "477/0 [------------------------------------------------------------] loss: +2.271E-01 / score: +11.600(+2/+15/+22))\n",
      "478/0 [------------------------------------------------------------] loss: +1.760E-02 / score: +11.590(+2/+12/+22))\n",
      "479/0 [------------------------------------------------------------] loss: +2.651E-02 / score: +11.630(+2/+14/+22))\n",
      "480/0 [------------------------------------------------------------] loss: +1.820E-02 / score: +11.710(+2/+14/+22))\n",
      "481/0 [------------------------------------------------------------] loss: +5.260E-02 / score: +11.710(+2/+12/+22))\n",
      "482/0 [------------------------------------------------------------] loss: +2.519E-02 / score: +11.740(+2/+15/+22))\n",
      "483/0 [------------------------------------------------------------] loss: +4.625E-02 / score: +11.780(+2/+18/+22))\n",
      "484/0 [------------------------------------------------------------] loss: +1.529E-02 / score: +11.780(+2/+12/+22))\n",
      "485/0 [------------------------------------------------------------] loss: +2.467E-01 / score: +11.880(+2/+17/+22))\n",
      "486/0 [------------------------------------------------------------] loss: +2.642E-01 / score: +11.930(+2/+15/+22))\n",
      "487/0 [------------------------------------------------------------] loss: +2.748E-02 / score: +11.970(+2/+12/+22))\n",
      "488/0 [------------------------------------------------------------] loss: +2.478E-02 / score: +11.980(+2/+12/+22))\n",
      "489/0 [------------------------------------------------------------] loss: +1.861E-02 / score: +12.000(+2/+13/+22))\n",
      "490/0 [------------------------------------------------------------] loss: +2.300E-02 / score: +11.990(+2/+15/+22))\n",
      "491/0 [------------------------------------------------------------] loss: +1.380E-01 / score: +11.960(+2/+17/+22))\n",
      "492/0 [------------------------------------------------------------] loss: +1.206E-02 / score: +12.010(+2/+14/+22))\n",
      "493/0 [------------------------------------------------------------] loss: +4.049E-02 / score: +12.000(+2/+16/+22))\n",
      "494/0 [------------------------------------------------------------] loss: +1.599E-02 / score: +12.110(+2/+18/+22))\n",
      "495/0 [------------------------------------------------------------] loss: +2.373E-02 / score: +12.150(+2/+16/+22))\n",
      "496/0 [------------------------------------------------------------] loss: +1.510E-01 / score: +12.180(+2/+16/+22))\n",
      "497/0 [------------------------------------------------------------] loss: +1.271E-02 / score: +12.170(+2/+13/+22))\n",
      "498/0 [------------------------------------------------------------] loss: +1.214E-01 / score: +12.220(+2/+14/+22))\n",
      "499/0 [------------------------------------------------------------] loss: +1.024E-02 / score: +12.330(+2/+17/+22))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/0 [------------------------------------------------------------] loss: +2.633E-02 / score: +12.370(+2/+16/+22))\n",
      "501/0 [------------------------------------------------------------] loss: +1.636E-02 / score: +12.430(+2/+18/+22))\n",
      "502/0 [------------------------------------------------------------] loss: +3.031E-02 / score: +12.390(+2/+14/+22))\n",
      "503/0 [------------------------------------------------------------] loss: +1.506E-02 / score: +12.430(+2/+14/+22))\n",
      "504/0 [------------------------------------------------------------] loss: +2.535E-02 / score: +12.460(+2/+15/+22))\n",
      "505/0 [------------------------------------------------------------] loss: +2.609E-01 / score: +12.530(+2/+15/+22))\n",
      "506/0 [------------------------------------------------------------] loss: +1.425E-02 / score: +12.540(+2/+16/+22))\n",
      "507/0 [------------------------------------------------------------] loss: +3.343E-02 / score: +12.560(+2/+17/+22))\n",
      "508/0 [------------------------------------------------------------] loss: +7.245E-03 / score: +12.610(+2/+14/+22))\n",
      "509/0 [------------------------------------------------------------] loss: +1.882E-02 / score: +12.630(+2/+12/+22))\n",
      "510/0 [------------------------------------------------------------] loss: +5.309E-02 / score: +12.710(+2/+15/+22))\n",
      "511/0 [------------------------------------------------------------] loss: +3.235E-02 / score: +12.810(+2/+17/+22))\n",
      "512/0 [------------------------------------------------------------] loss: +6.002E-02 / score: +12.870(+2/+14/+22))\n",
      "513/0 [------------------------------------------------------------] loss: +1.639E-01 / score: +12.950(+2/+15/+22))\n",
      "514/0 [------------------------------------------------------------] loss: +5.932E-02 / score: +12.920(+2/+11/+22))\n",
      "515/0 [------------------------------------------------------------] loss: +2.211E-02 / score: +12.960(+2/+15/+22))\n",
      "516/0 [------------------------------------------------------------] loss: +2.742E-02 / score: +13.060(+2/+19/+22))\n",
      "517/0 [------------------------------------------------------------] loss: +2.218E-02 / score: +13.090(+2/+13/+22))\n",
      "518/0 [------------------------------------------------------------] loss: +2.228E-01 / score: +13.220(+2/+18/+22))\n",
      "519/0 [------------------------------------------------------------] loss: +3.562E-02 / score: +13.330(+2/+18/+22))\n",
      "520/0 [------------------------------------------------------------] loss: +1.260E-02 / score: +13.430(+2/+13/+22))\n",
      "521/0 [------------------------------------------------------------] loss: +3.787E-02 / score: +13.450(+2/+11/+22))\n",
      "522/0 [------------------------------------------------------------] loss: +1.877E-01 / score: +13.600(+3/+17/+22))\n",
      "523/0 [------------------------------------------------------------] loss: +3.904E-01 / score: +13.660(+3/+17/+22))\n",
      "524/0 [------------------------------------------------------------] loss: +1.211E-02 / score: +13.730(+3/+14/+22))\n",
      "525/0 [------------------------------------------------------------] loss: +2.221E-02 / score: +13.760(+3/+13/+22))\n",
      "526/0 [------------------------------------------------------------] loss: +1.478E-01 / score: +13.770(+3/+15/+22))\n",
      "527/0 [------------------------------------------------------------] loss: +6.250E-03 / score: +13.820(+3/+16/+22))\n",
      "528/0 [------------------------------------------------------------] loss: +2.736E-02 / score: +13.880(+3/+18/+22))\n",
      "529/0 [------------------------------------------------------------] loss: +1.669E-02 / score: +13.950(+3/+18/+22))\n",
      "530/0 [------------------------------------------------------------] loss: +1.165E-02 / score: +13.980(+3/+18/+22))\n",
      "531/0 [------------------------------------------------------------] loss: +4.023E-01 / score: +14.050(+3/+15/+22))\n",
      "532/0 [------------------------------------------------------------] loss: +1.200E-02 / score: +14.120(+3/+17/+22))\n",
      "533/0 [------------------------------------------------------------] loss: +2.449E-01 / score: +14.130(+3/+14/+22))\n",
      "534/0 [------------------------------------------------------------] loss: +2.802E-02 / score: +14.220(+3/+20/+22))\n",
      "535/0 [------------------------------------------------------------] loss: +3.170E-02 / score: +14.230(+3/+19/+22))\n",
      "536/0 [------------------------------------------------------------] loss: +2.487E-02 / score: +14.140(+3/+7/+22)2)\n",
      "537/0 [------------------------------------------------------------] loss: +9.496E-03 / score: +14.100(+3/+13/+22)\n",
      "538/0 [------------------------------------------------------------] loss: +1.318E-02 / score: +14.120(+3/+13/+22))\n",
      "539/0 [------------------------------------------------------------] loss: +4.367E-02 / score: +14.180(+3/+17/+22))\n",
      "540/0 [------------------------------------------------------------] loss: +2.848E-02 / score: +14.120(+3/+6/+22)2)\n",
      "541/0 [------------------------------------------------------------] loss: +2.321E-02 / score: +14.100(+3/+13/+22)\n",
      "542/0 [------------------------------------------------------------] loss: +3.576E-02 / score: +14.210(+5/+14/+22))\n",
      "543/0 [------------------------------------------------------------] loss: +3.679E-01 / score: +14.330(+6/+17/+22))\n",
      "544/0 [------------------------------------------------------------] loss: +1.414E-02 / score: +14.410(+6/+16/+22))\n",
      "545/0 [------------------------------------------------------------] loss: +2.197E-02 / score: +14.410(+6/+17/+22))\n",
      "546/0 [------------------------------------------------------------] loss: +3.126E-02 / score: +14.400(+6/+14/+22))\n",
      "547/0 [------------------------------------------------------------] loss: +4.733E-02 / score: +14.380(+6/+13/+22))\n",
      "548/0 [------------------------------------------------------------] loss: +2.035E-02 / score: +14.380(+6/+13/+22))\n",
      "549/0 [------------------------------------------------------------] loss: +1.162E-02 / score: +14.410(+6/+13/+22))\n",
      "550/0 [------------------------------------------------------------] loss: +3.673E-02 / score: +14.370(+6/+6/+22)2)\n",
      "551/0 [------------------------------------------------------------] loss: +1.376E-02 / score: +14.350(+6/+6/+22))\n",
      "552/0 [------------------------------------------------------------] loss: +1.779E-01 / score: +14.320(+6/+14/+22)\n",
      "553/0 [------------------------------------------------------------] loss: +2.139E-02 / score: +14.310(+6/+15/+22))\n",
      "554/0 [------------------------------------------------------------] loss: +2.717E-02 / score: +14.330(+6/+16/+22))\n",
      "555/0 [------------------------------------------------------------] loss: +1.338E-02 / score: +14.360(+6/+14/+22))\n",
      "556/0 [------------------------------------------------------------] loss: +2.297E-01 / score: +14.350(+6/+13/+22))\n",
      "557/0 [------------------------------------------------------------] loss: +4.450E-02 / score: +14.380(+6/+11/+22))\n",
      "558/0 [------------------------------------------------------------] loss: +1.523E-02 / score: +14.470(+6/+16/+22))\n",
      "559/0 [------------------------------------------------------------] loss: +1.411E-02 / score: +14.460(+6/+13/+22))\n",
      "560/0 [------------------------------------------------------------] loss: +2.855E-02 / score: +14.380(+6/+14/+21))\n",
      "561/0 [------------------------------------------------------------] loss: +1.745E-01 / score: +14.440(+6/+18/+21))\n",
      "562/0 [------------------------------------------------------------] loss: +2.137E-02 / score: +14.400(+6/+13/+21))\n",
      "563/0 [------------------------------------------------------------] loss: +1.260E-02 / score: +14.430(+6/+16/+21))\n",
      "564/0 [------------------------------------------------------------] loss: +1.487E-02 / score: +14.460(+6/+16/+21))\n",
      "565/0 [------------------------------------------------------------] loss: +2.704E-02 / score: +14.460(+6/+9/+21)1)\n",
      "566/0 [------------------------------------------------------------] loss: +1.060E-02 / score: +14.400(+6/+15/+20)\n",
      "567/0 [------------------------------------------------------------] loss: +1.835E-02 / score: +14.410(+6/+11/+20))\n",
      "568/0 [------------------------------------------------------------] loss: +5.567E-02 / score: +14.400(+6/+13/+20))\n",
      "569/0 [------------------------------------------------------------] loss: +3.740E-02 / score: +14.420(+6/+12/+20))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/0 [------------------------------------------------------------] loss: +1.320E-02 / score: +14.440(+6/+15/+20))\n",
      "571/0 [------------------------------------------------------------] loss: +3.217E-02 / score: +14.430(+6/+14/+20))\n",
      "572/0 [------------------------------------------------------------] loss: +3.718E-02 / score: +14.350(+6/+9/+20)0)\n",
      "573/0 [------------------------------------------------------------] loss: +3.262E-02 / score: +14.350(+6/+13/+20)\n",
      "574/0 [------------------------------------------------------------] loss: +1.967E-02 / score: +14.380(+6/+16/+20))\n",
      "575/0 [------------------------------------------------------------] loss: +1.670E-02 / score: +14.430(+6/+16/+20))\n",
      "576/0 [------------------------------------------------------------] loss: +1.709E-02 / score: +14.360(+6/+8/+20)0)\n",
      "577/0 [------------------------------------------------------------] loss: +1.521E-02 / score: +14.360(+6/+15/+20)\n",
      "578/0 [------------------------------------------------------------] loss: +2.602E-02 / score: +14.370(+6/+13/+20))\n",
      "579/0 [------------------------------------------------------------] loss: +2.580E-02 / score: +14.390(+6/+16/+20))\n",
      "580/0 [------------------------------------------------------------] loss: +2.462E-02 / score: +14.380(+6/+13/+20))\n",
      "581/0 [------------------------------------------------------------] loss: +3.343E-02 / score: +14.440(+6/+18/+20))\n",
      "582/0 [------------------------------------------------------------] loss: +2.151E-02 / score: +14.410(+6/+12/+20))\n",
      "583/0 [------------------------------------------------------------] loss: +1.309E-02 / score: +14.350(+6/+12/+20))\n",
      "584/0 [------------------------------------------------------------] loss: +2.837E-02 / score: +14.390(+6/+16/+20))\n",
      "585/0 [------------------------------------------------------------] loss: +4.146E-02 / score: +14.330(+6/+11/+20))\n",
      "586/0 [------------------------------------------------------------] loss: +2.199E-01 / score: +14.320(+6/+14/+20))\n",
      "587/0 [------------------------------------------------------------] loss: +2.080E-01 / score: +14.320(+6/+12/+20))\n",
      "588/0 [------------------------------------------------------------] loss: +2.947E-02 / score: +14.330(+6/+13/+20))\n",
      "589/0 [------------------------------------------------------------] loss: +9.746E-03 / score: +14.390(+6/+19/+20))\n",
      "590/0 [------------------------------------------------------------] loss: +2.948E-01 / score: +14.360(+6/+12/+20))\n",
      "591/0 [------------------------------------------------------------] loss: +3.334E-02 / score: +14.340(+6/+15/+20))\n",
      "592/0 [------------------------------------------------------------] loss: +2.021E-01 / score: +14.390(+6/+19/+20))\n",
      "593/0 [------------------------------------------------------------] loss: +1.631E-01 / score: +14.370(+6/+14/+20))\n",
      "594/0 [------------------------------------------------------------] loss: +1.927E-02 / score: +14.320(+6/+13/+20))\n",
      "595/0 [------------------------------------------------------------] loss: +3.082E-02 / score: +14.240(+6/+8/+20)0)\n",
      "596/0 [------------------------------------------------------------] loss: +2.657E-01 / score: +14.290(+6/+21/+21)\n",
      "597/0 [------------------------------------------------------------] loss: +3.470E-02 / score: +14.300(+6/+14/+21))\n",
      "598/0 [------------------------------------------------------------] loss: +1.826E-02 / score: +14.370(+6/+21/+21))\n",
      "599/0 [------------------------------------------------------------] loss: +1.432E-02 / score: +14.350(+6/+15/+21))\n",
      "600/0 [------------------------------------------------------------] loss: +2.489E-02 / score: +14.370(+6/+18/+21))\n",
      "601/0 [------------------------------------------------------------] loss: +4.199E-02 / score: +14.350(+6/+16/+21))\n",
      "602/0 [------------------------------------------------------------] loss: +3.959E-02 / score: +14.320(+6/+11/+21))\n",
      "603/0 [------------------------------------------------------------] loss: +3.541E-02 / score: +14.350(+6/+17/+21))\n",
      "604/0 [------------------------------------------------------------] loss: +2.600E-02 / score: +14.380(+6/+18/+21))\n",
      "605/0 [------------------------------------------------------------] loss: +7.760E-03 / score: +14.370(+6/+14/+21))\n",
      "606/0 [------------------------------------------------------------] loss: +4.039E-01 / score: +14.360(+6/+15/+21))\n",
      "607/0 [------------------------------------------------------------] loss: +5.752E-02 / score: +14.300(+6/+11/+21))\n",
      "608/0 [------------------------------------------------------------] loss: +2.234E-01 / score: +14.250(+6/+9/+21)1)\n",
      "609/0 [------------------------------------------------------------] loss: +9.854E-03 / score: +14.270(+6/+14/+21)\n",
      "610/0 [------------------------------------------------------------] loss: +4.583E-02 / score: +14.290(+6/+17/+21))\n",
      "611/0 [------------------------------------------------------------] loss: +9.520E-03 / score: +14.280(+6/+16/+21))\n",
      "612/0 [------------------------------------------------------------] loss: +3.581E-02 / score: +14.270(+6/+13/+21))\n",
      "613/0 [------------------------------------------------------------] loss: +2.726E-01 / score: +14.290(+6/+17/+21))\n",
      "614/0 [------------------------------------------------------------] loss: +1.674E-02 / score: +14.370(+6/+19/+21))\n",
      "615/0 [------------------------------------------------------------] loss: +9.060E-03 / score: +14.390(+6/+17/+21))\n",
      "616/0 [------------------------------------------------------------] loss: +2.152E-01 / score: +14.330(+6/+13/+21))\n",
      "617/0 [------------------------------------------------------------] loss: +3.596E-02 / score: +14.350(+6/+15/+21))\n",
      "618/0 [------------------------------------------------------------] loss: +1.212E-02 / score: +14.300(+6/+13/+21))\n",
      "619/0 [------------------------------------------------------------] loss: +2.368E-02 / score: +14.310(+6/+19/+21))\n",
      "620/0 [------------------------------------------------------------] loss: +1.132E-02 / score: +14.280(+6/+10/+21))\n",
      "621/0 [------------------------------------------------------------] loss: +9.685E-03 / score: +14.340(+6/+17/+21))\n",
      "622/0 [------------------------------------------------------------] loss: +8.881E-03 / score: +14.300(+6/+13/+21))\n",
      "623/0 [------------------------------------------------------------] loss: +8.928E-03 / score: +14.250(+6/+12/+21))\n",
      "624/0 [------------------------------------------------------------] loss: +2.048E-02 / score: +14.280(+6/+17/+21))\n",
      "625/0 [------------------------------------------------------------] loss: +1.878E-02 / score: +14.320(+6/+17/+21))\n",
      "626/0 [------------------------------------------------------------] loss: +9.457E-03 / score: +14.320(+6/+15/+21))\n",
      "627/0 [------------------------------------------------------------] loss: +1.060E-02 / score: +14.280(+6/+12/+21))\n",
      "628/0 [------------------------------------------------------------] loss: +1.017E-02 / score: +14.200(+6/+10/+21))\n",
      "629/0 [------------------------------------------------------------] loss: +2.370E-02 / score: +14.150(+6/+13/+21))\n",
      "630/0 [------------------------------------------------------------] loss: +1.159E-02 / score: +14.140(+6/+17/+21))\n",
      "631/0 [------------------------------------------------------------] loss: +3.176E-02 / score: +14.170(+6/+18/+21))\n",
      "632/0 [------------------------------------------------------------] loss: +9.964E-03 / score: +14.120(+6/+12/+21))\n",
      "633/0 [------------------------------------------------------------] loss: +2.614E-01 / score: +14.110(+6/+13/+21))\n",
      "634/0 [------------------------------------------------------------] loss: +1.302E-02 / score: +14.040(+6/+13/+21))\n",
      "635/0 [------------------------------------------------------------] loss: +1.491E-02 / score: +14.010(+6/+16/+21))\n",
      "636/0 [------------------------------------------------------------] loss: +1.803E-01 / score: +14.070(+6/+13/+21))\n",
      "637/0 [------------------------------------------------------------] loss: +1.043E-02 / score: +14.100(+6/+16/+21))\n",
      "638/0 [------------------------------------------------------------] loss: +2.844E-02 / score: +14.130(+6/+16/+21))\n",
      "639/0 [------------------------------------------------------------] loss: +1.720E-02 / score: +14.060(+6/+10/+21))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/0 [------------------------------------------------------------] loss: +1.905E-02 / score: +14.110(+6/+11/+21))\n",
      "641/0 [------------------------------------------------------------] loss: +8.718E-03 / score: +14.130(+6/+15/+21))\n",
      "642/0 [------------------------------------------------------------] loss: +1.581E-02 / score: +14.110(+6/+12/+21))\n",
      "643/0 [------------------------------------------------------------] loss: +4.281E-02 / score: +14.030(+6/+9/+21)1)\n",
      "644/0 [------------------------------------------------------------] loss: +4.721E-02 / score: +13.980(+6/+11/+21)\n",
      "645/0 [------------------------------------------------------------] loss: +1.976E-02 / score: +13.910(+6/+10/+21))\n",
      "646/0 [------------------------------------------------------------] loss: +3.213E-02 / score: +14.000(+6/+23/+23))\n",
      "647/0 [------------------------------------------------------------] loss: +3.101E-02 / score: +13.990(+6/+12/+23))\n",
      "648/0 [------------------------------------------------------------] loss: +4.314E-02 / score: +14.010(+6/+15/+23))\n",
      "649/0 [------------------------------------------------------------] loss: +3.942E-02 / score: +13.970(+6/+9/+23)3)\n",
      "650/0 [------------------------------------------------------------] loss: +2.446E-01 / score: +14.100(+6/+19/+23)\n",
      "651/0 [------------------------------------------------------------] loss: +2.877E-01 / score: +14.210(+8/+17/+23))\n",
      "652/0 [------------------------------------------------------------] loss: +2.802E-01 / score: +14.230(+8/+16/+23))\n",
      "653/0 [------------------------------------------------------------] loss: +2.980E-02 / score: +14.190(+8/+11/+23))\n",
      "654/0 [------------------------------------------------------------] loss: +3.137E-02 / score: +14.170(+8/+14/+23))\n",
      "655/0 [------------------------------------------------------------] loss: +1.909E-02 / score: +14.200(+8/+17/+23))\n",
      "656/0 [------------------------------------------------------------] loss: +3.633E-02 / score: +14.240(+8/+17/+23))\n",
      "657/0 [------------------------------------------------------------] loss: +9.805E-03 / score: +14.240(+8/+11/+23))\n",
      "658/0 [------------------------------------------------------------] loss: +1.560E-02 / score: +14.210(+8/+13/+23))\n",
      "659/0 [------------------------------------------------------------] loss: +3.797E-02 / score: +14.170(+8/+9/+23)3)\n",
      "660/0 [------------------------------------------------------------] loss: +1.438E-02 / score: +14.190(+8/+16/+23)\n",
      "661/0 [------------------------------------------------------------] loss: +1.693E-02 / score: +14.140(+8/+13/+23))\n",
      "662/0 [------------------------------------------------------------] loss: +1.434E-02 / score: +14.170(+8/+16/+23))\n",
      "663/0 [------------------------------------------------------------] loss: +3.795E-02 / score: +14.200(+8/+19/+23))\n",
      "664/0 [------------------------------------------------------------] loss: +3.968E-03 / score: +14.240(+8/+20/+23))\n",
      "665/0 [------------------------------------------------------------] loss: +2.694E-02 / score: +14.320(+8/+17/+23))\n",
      "666/0 [------------------------------------------------------------] loss: +3.599E-02 / score: +14.350(+8/+18/+23))\n",
      "667/0 [------------------------------------------------------------] loss: +2.977E-01 / score: +14.380(+8/+14/+23))\n",
      "668/0 [------------------------------------------------------------] loss: +3.160E-02 / score: +14.410(+8/+16/+23))\n",
      "669/0 [------------------------------------------------------------] loss: +1.140E-02 / score: +14.440(+8/+15/+23))\n",
      "670/0 [------------------------------------------------------------] loss: +1.490E-02 / score: +14.420(+8/+13/+23))\n",
      "671/0 [------------------------------------------------------------] loss: +1.040E-02 / score: +14.430(+8/+15/+23))\n",
      "672/0 [------------------------------------------------------------] loss: +2.229E-01 / score: +14.420(+8/+8/+23)3)\n",
      "673/0 [------------------------------------------------------------] loss: +1.133E-02 / score: +14.420(+8/+13/+23)\n",
      "674/0 [------------------------------------------------------------] loss: +2.853E-01 / score: +14.450(+8/+19/+23))\n",
      "675/0 [------------------------------------------------------------] loss: +6.120E-01 / score: +14.420(+8/+13/+23))\n",
      "676/0 [------------------------------------------------------------] loss: +1.752E-02 / score: +14.470(+8/+13/+23))\n",
      "677/0 [------------------------------------------------------------] loss: +1.428E-02 / score: +14.490(+8/+17/+23))\n",
      "678/0 [------------------------------------------------------------] loss: +3.370E-02 / score: +14.470(+8/+11/+23))\n",
      "679/0 [------------------------------------------------------------] loss: +9.976E-03 / score: +14.490(+8/+18/+23))\n",
      "680/0 [------------------------------------------------------------] loss: +3.133E-02 / score: +14.500(+8/+14/+23))\n",
      "681/0 [------------------------------------------------------------] loss: +6.532E-02 / score: +14.540(+8/+22/+23))\n",
      "682/0 [------------------------------------------------------------] loss: +2.903E-02 / score: +14.570(+8/+15/+23))\n",
      "683/0 [------------------------------------------------------------] loss: +3.412E-02 / score: +14.660(+8/+21/+23))\n",
      "684/0 [------------------------------------------------------------] loss: +3.999E-02 / score: +14.660(+8/+16/+23))\n",
      "685/0 [------------------------------------------------------------] loss: +2.478E-02 / score: +14.690(+8/+14/+23))\n",
      "686/0 [------------------------------------------------------------] loss: +2.482E-02 / score: +14.710(+8/+16/+23))\n",
      "687/0 [------------------------------------------------------------] loss: +2.413E-01 / score: +14.730(+8/+14/+23))\n",
      "688/0 [------------------------------------------------------------] loss: +4.858E-02 / score: +14.740(+8/+14/+23))\n",
      "689/0 [------------------------------------------------------------] loss: +3.439E-01 / score: +14.700(+8/+15/+23))\n",
      "690/0 [------------------------------------------------------------] loss: +5.193E-02 / score: +14.690(+8/+11/+23))\n",
      "691/0 [------------------------------------------------------------] loss: +9.838E-03 / score: +14.720(+8/+18/+23))\n",
      "692/0 [------------------------------------------------------------] loss: +2.453E-01 / score: +14.660(+8/+13/+23))\n",
      "693/0 [------------------------------------------------------------] loss: +2.033E-02 / score: +14.580(+6/+6/+23)3)\n",
      "694/0 [------------------------------------------------------------] loss: +3.201E-02 / score: +14.650(+6/+20/+23)\n",
      "695/0 [------------------------------------------------------------] loss: +2.130E-01 / score: +14.700(+6/+13/+23))\n",
      "696/0 [------------------------------------------------------------] loss: +3.524E-02 / score: +14.630(+6/+14/+23))\n",
      "697/0 [------------------------------------------------------------] loss: +1.561E-02 / score: +14.580(+6/+9/+23)3)\n",
      "698/0 [------------------------------------------------------------] loss: +1.742E-02 / score: +14.520(+6/+15/+23)\n",
      "699/0 [------------------------------------------------------------] loss: +2.556E-02 / score: +14.530(+6/+16/+23))\n",
      "700/0 [------------------------------------------------------------] loss: +1.880E-01 / score: +14.500(+6/+15/+23))\n",
      "701/0 [------------------------------------------------------------] loss: +1.380E-02 / score: +14.490(+6/+15/+23))\n",
      "702/0 [------------------------------------------------------------] loss: +3.204E-01 / score: +14.500(+6/+12/+23))\n",
      "703/0 [------------------------------------------------------------] loss: +2.492E-02 / score: +14.480(+6/+15/+23))\n",
      "704/0 [------------------------------------------------------------] loss: +1.388E-02 / score: +14.380(+6/+8/+23)3)\n",
      "705/0 [------------------------------------------------------------] loss: +1.222E-02 / score: +14.360(+6/+12/+23)\n",
      "706/0 [------------------------------------------------------------] loss: +4.153E-02 / score: +14.350(+6/+14/+23))\n",
      "707/0 [------------------------------------------------------------] loss: +2.359E-02 / score: +14.430(+6/+19/+23))\n",
      "708/0 [------------------------------------------------------------] loss: +2.086E-02 / score: +14.440(+6/+10/+23))\n",
      "709/0 [------------------------------------------------------------] loss: +4.713E-01 / score: +14.410(+6/+11/+23))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/0 [------------------------------------------------------------] loss: +3.269E-02 / score: +14.410(+6/+17/+23))\n",
      "711/0 [------------------------------------------------------------] loss: +2.857E-02 / score: +14.470(+6/+22/+23))\n",
      "712/0 [------------------------------------------------------------] loss: +1.939E-02 / score: +14.520(+6/+18/+23))\n",
      "713/0 [------------------------------------------------------------] loss: +1.402E-02 / score: +14.480(+6/+13/+23))\n",
      "714/0 [------------------------------------------------------------] loss: +8.679E-03 / score: +14.400(+6/+11/+23))\n",
      "715/0 [------------------------------------------------------------] loss: +2.028E-01 / score: +14.440(+6/+21/+23))\n",
      "716/0 [------------------------------------------------------------] loss: +3.845E-02 / score: +14.420(+6/+11/+23))\n",
      "717/0 [------------------------------------------------------------] loss: +9.129E-03 / score: +14.300(+3/+3/+23)3)\n",
      "718/0 [------------------------------------------------------------] loss: +3.166E-01 / score: +14.340(+3/+17/+23)\n",
      "719/0 [------------------------------------------------------------] loss: +2.815E-02 / score: +14.270(+3/+12/+23))\n",
      "720/0 [------------------------------------------------------------] loss: +2.147E-02 / score: +14.320(+3/+15/+23))\n",
      "721/0 [------------------------------------------------------------] loss: +2.261E-02 / score: +14.300(+3/+15/+23))\n",
      "722/0 [------------------------------------------------------------] loss: +1.921E-02 / score: +14.370(+3/+20/+23))\n",
      "723/0 [------------------------------------------------------------] loss: +8.458E-03 / score: +14.390(+3/+14/+23))\n",
      "724/0 [------------------------------------------------------------] loss: +1.593E-02 / score: +14.360(+3/+14/+23))\n",
      "725/0 [------------------------------------------------------------] loss: +1.420E-02 / score: +14.300(+3/+11/+23))\n",
      "726/0 [------------------------------------------------------------] loss: +2.268E-02 / score: +14.310(+3/+16/+23))\n",
      "727/0 [------------------------------------------------------------] loss: +1.005E-02 / score: +14.320(+3/+13/+23))\n",
      "728/0 [------------------------------------------------------------] loss: +3.108E-02 / score: +14.330(+3/+11/+23))\n",
      "729/0 [------------------------------------------------------------] loss: +2.930E-02 / score: +14.350(+3/+15/+23))\n",
      "730/0 [------------------------------------------------------------] loss: +3.128E-02 / score: +14.350(+3/+17/+23))\n",
      "731/0 [------------------------------------------------------------] loss: +3.188E-02 / score: +14.330(+3/+16/+23))\n",
      "732/0 [------------------------------------------------------------] loss: +1.139E-02 / score: +14.310(+3/+10/+23))\n",
      "733/0 [------------------------------------------------------------] loss: +2.134E-02 / score: +14.310(+3/+13/+23))\n",
      "734/0 [------------------------------------------------------------] loss: +1.057E-02 / score: +14.300(+3/+12/+23))\n",
      "735/0 [------------------------------------------------------------] loss: +2.589E-02 / score: +14.260(+3/+12/+23))\n",
      "736/0 [------------------------------------------------------------] loss: +3.270E-01 / score: +14.310(+3/+18/+23))\n",
      "737/0 [------------------------------------------------------------] loss: +1.726E-02 / score: +14.330(+3/+18/+23))\n",
      "738/0 [------------------------------------------------------------] loss: +5.857E-02 / score: +14.280(+3/+11/+23))\n",
      "739/0 [------------------------------------------------------------] loss: +2.970E-02 / score: +14.370(+3/+19/+23))\n",
      "740/0 [------------------------------------------------------------] loss: +2.404E-01 / score: +14.350(+3/+9/+23)3)\n",
      "741/0 [------------------------------------------------------------] loss: +1.470E-02 / score: +14.370(+3/+17/+23)\n",
      "742/0 [------------------------------------------------------------] loss: +5.051E-02 / score: +14.430(+3/+18/+23))\n",
      "743/0 [------------------------------------------------------------] loss: +7.272E-03 / score: +14.480(+3/+14/+23))\n",
      "744/0 [------------------------------------------------------------] loss: +3.346E-02 / score: +14.550(+3/+18/+23))\n",
      "745/0 [------------------------------------------------------------] loss: +1.859E-01 / score: +14.590(+3/+14/+23))\n",
      "746/0 [------------------------------------------------------------] loss: +8.697E-03 / score: +14.490(+3/+13/+22))\n",
      "747/0 [------------------------------------------------------------] loss: +7.613E-03 / score: +14.540(+3/+17/+22))\n",
      "748/0 [------------------------------------------------------------] loss: +1.408E-02 / score: +14.460(+3/+7/+22)2)\n",
      "749/0 [------------------------------------------------------------] loss: +2.011E-01 / score: +14.490(+3/+12/+22)\n",
      "750/0 [------------------------------------------------------------] loss: +2.874E-02 / score: +14.450(+3/+15/+22))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from banananav.util import print_progress, plot\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "env.terminate()\n",
    "\n",
    "## Select DeepQLearner or DoubleDeepQLearner here, using\n",
    "## BananaQModel or SimpleBananaQModel\n",
    "learner = DeepQLearner(env=env, model=BananaQModel)\n",
    "\n",
    "scores = ()\n",
    "losses = ()\n",
    "\n",
    "episode_cnt = 0\n",
    "episode_step = 0\n",
    "episode_losses = ()\n",
    "for cnt, data in enumerate(learner.train(750)):\n",
    "    episode_step += 1\n",
    "    loss, score, terminal = data\n",
    "    episode_losses += (loss.item(), )\n",
    "\n",
    "    if terminal:\n",
    "        scores += (score, )\n",
    "        losses += (np.mean(episode_losses), )\n",
    "        episode_losses = ()\n",
    "        episode_cnt += 1\n",
    "        episode_step = 0\n",
    "\n",
    "    print_progress(episode_cnt, episode_step, loss, scores)\n",
    "    if terminal:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can plot the scores of each episode and the average loss during each episode. The plots contain multiple graphs averaged over different window sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4FUUXh99JD4FAIKElgYTelSIgiKIIgopYQEGsqPh9iCIqCH6o2LArSFGxoEhTUREUCyqiSK8qhFBCrymEhED6fn/Mbu7ezd6SkAaZ93l49u7s7OzuBX577pkz5whN01AoFApF5cCnvG9AoVAoFGWHEn2FQqGoRCjRVygUikqEEn2FQqGoRCjRVygUikqEEn2FQqGoRCjRVygUikqEEn2FQqGoRCjRVygUikqEX3nfgJXw8HAtJiamvG9DoVAozis2btyYpGlahKd+FU70Y2Ji2LBhQ3nfhkKhUJxXCCH2e9NPuXcUCoWiEqFEX6FQKCoRSvQVCoWiEqFEX6FQKCoRSvQVCoWiEqFEX6FQKCoRSvQVCoWiEqFEX6FQKIpCejrMm1fed1FslOgrFApFURg+HIYOhU2byvtOioUSfYVCoSgKBw/K7Zkz5XsfxUSJvkKhUBSF/Hy5FaJ876OYKNFXKBSKoqBpcqtEX6FQKCoBlUH0hRB9hRDxQojdQohxNscvF0JsEkLkCiEGWo7dLYTYpf+5u6RuXKFQKMqFC130hRC+wHSgH9AKGCKEaGXpdgC4B5hnObcm8CzQBegMPCuECDv321YoFIpy4kIXfaRY79Y0LUHTtGxgATDA3EHTtH2apv0N5FvOvQZYpmlaiqZpJ4FlQN8SuG+FQqEoHwzR9zk/vePe3HUkcNC0f0hv84ZzOVehUCgqHq4s/ZQUR2RPBaZCvKqEEMOFEBuEEBsSExPL+3YUCkVFQtPggw/kStiKgCH6Zo4ehVq14KWXyv5+iog3on8YiDbtR+lt3uDVuZqmzdQ0rZOmaZ0iIjyWeFQoFJWJP/+Uq2Afeqi870RiZ+kf1mVt0aKyv58i4o3orweaCiFihRABwGBgsZfj/wT0EUKE6RO4ffQ2hUKh8I6MDLmtKF4AO9Ev7uRuXByUcU1wj4XRNU3LFUKMRIq1L/CxpmnbhBDPAxs0TVsshLgE+AYIA/oLIZ7TNK21pmkpQogXkC8OgOc1TUsppWdRKBSK0sedwBdV9Fu1ch6zDPAo+gCapi0FllranjF9Xo903did+zHw8Tnco0KhUFQcDIF+6SVYuNC57TygQkzkKhQKRYUmIQHWrJGfDYH/6ivHcW/cOzk5MGKEnPQtR7yy9BUKhaJS07ix3Gqa+7BMd6K/ZAm8+66cm/jyy5K9vyKgLH2FQnF+UFFcKHb34c295eTIbTkv6lKir1AoFEXBncC7s/Rzc+XWr3wdLEr0FQpFxWbZMrmtCLluUlMd4m3GG0vfOM/Xt2TvqYgo0VcoFBWbt98u2fF27ZIvkK1b5b6mwTvvwOnTns8NC5PnGxj+fW8mcpWlr1AoFOXAN9/I7Zw5crt0KYwaBY89VvSxDCEviuj7+xf9OiWIEn2FQnF+UFITuVaBNmrdphRj3WhenvO+p5BNUJa+QqFQlClW0T+XuQKrpe9NXyX6CoVC4QUlNZFbkkVQimLpG32V6CsUCoUXlJZ751zGV5a+QqFQVHBK0r1TFEtfib5CoVCUA8rSVygUikpEcSx9V30MS1/F6SsUCkUJYLagy3Mi15VQG0JudfPYoUI2FQqFwgNm0S/PiVxXqRMMsTdW5rpLpubO0hfC8VIoZZToKxSKisu5Cv2aNTBunP2xorh3XIl+bi6cPQvvv+95LE8hm96kgSgBlOgrFIqKy7mK/qWXwquv2o9ZFPeOO0t/wgRHBS13GJa8q7Hc5ekvQZToKxSKiktJCaF5HONzSbh3cnPhxAnHvjcTud7cYymiRF+hUFRcSmoi105wS8q9Y2b5ctflED2FdyrRVygUFzz5+TByJOzYYX+8pCZyzeJcnIlcVxO0eXmFz7MrhThnDnz0kfzsStyV6CsUigueHTtg+nS4+Wb74yUlhGbRd+XeMbNunTy+e7fc99bSB/uXxwcfuD/uaqxSQIm+QqEoPzwJcEmFac6cCdWqOcfTuxP9Tz+V259+kltPIZtmsrPhrbdch2CWs+iX7yoBhUJRufEUSVMU0V+1CoKDoX37wsfGjJHb7GzXK3LdFTx3Z+lb733KFDh8WLaPHl34HONF9+OPzu3eLPAqAZSlr1Aozp2EhOKJliGqrnzmRRH97t2hQwfIzHRUx7Ibz5s0DNY2k+inB8BXLUED+2dOS3PeWsczrt+vn/N5yr2jUCjOCxISoHFjePbZop/ryb1THJ/+Y4/JOYLVqwsf27TpnBOuPX8FDLwNlscCffo4yi4aGOO6unfl01coFOc1Roji8uVFP7ck3TsGe/fKrV35wx49ijam0dd0To5u9Pe6W7f2vTjH1tK3Mn9+mUTwKNFXKBQlQ3EEujRE38CV5Wwd0xv3jsmNE2Dy6Izt7eb6RY3HnzRJTjiXMkr0FQqFe7Kz4fXX5bak8eTTL47lawi2p+gZqz/e3QvGdB8pwSD0rm90BzHRxfVdjefuOocPuz5WQngl+kKIvkKIeCHEbiFEoexFQohAIcTn+vG1QogYvd1fCPGpEOIfIUScEGJ8yd6+QqEodWbMgLFjYfLkkh/bU3bK0rT0vYnXNzC9IFKCoc0J2Pi+4/AZf5tziurTd3dOCeJR9IUQvsB0oB/QChgihGhl6XYfcFLTtCbA24CR4WgQEKhpWlugI/Cg8UJQKBTnCUYUil0WyC1bzk2oSjNO35Olb1zb3TWsfYHkYKh5Vgq/wfEQ0zl2lv6RI47P7r6vMgjb9MbS7wzs1jQtQdO0bGABMMDSZwCgr2ZgIdBLCCGQ8xwhQgg/IBjIBtJQKBTnD65EcehQGRP/wgvnPrZh6cfHwyOPeCfIBtnZ8jyDH36QW1eWvjG2teqVFxZ4li9srQtNUqRvf8IKefhYVVNfq+ivXQs7dzqOnzkDPXvaX6cMIni8Ef1I4KBp/5DeZttH07Rc4BRQC/kCyACOAgeANzRNs5lSVygU5x3z5sntunVy6040hYCXXircbrX0r78epk6VY6amevcrYtQoaNGicLsrS98Q1vx8mXb5/fcL97GZyM31gaCn4VQQ9N4jm2+Ok1tb0TfufdMm57FWr4YVK+zvrYJY+udCZyAPqA/EAo8LIRpZOwkhhgshNgghNiQmJpbyLSkUihLFkzAbL4MJE1yfK4QseGLkurn0UggL887SdxUq6spqNle7GjcOli51vk+7e8/P51Coo7lZstzWjYgFLKJvPTcry7nd3fdVEXz6wGEg2rQfpbfZ9tFdOdWBZOB24EdN03I0TTsB/AV0sl5A07SZmqZ10jStU0RERNGfQqFQlD7FXUDljQ9bCCn0VrwxAl3dlytL37hmUazq/Hz21nDsRutO6ojcAIQGx+1E33juzEz767u7t1LEG9FfDzQVQsQKIQKAwcBiS5/FwN3654HAb5qmaUiXzlUAQogQoCvgIoeqQqGokNhZwGYh9yRU3oi+q+idM2fcjw2ufw1Y3SoGZveOK2zcO3tv61OwW0u/LT8fP8LPeLD0raJf0SdydR/9SOAnIA74QtO0bUKI54UQN+jdPgJqCSF2A48BRljndKCqEGIb8uUxS9O0v0v6IRQKRSlit4DK7DrxJFTeWLZCQGBg4ePnMrE5e7b7a1rF1+7l8e67csVxfj7Hfc8C8ORKKPgmfH2pe9rDRK7VvePOZVUGou9Vlk1N05YCSy1tz5g+ZyLDM63nnbZrVygU5zETJsicMwau3CgG3op+dLTDp+/NucWlKO6d+Hi44QbIzydZZBKcA6/8Yjqui/6RaqY2q+ifh+4dhUJRmTFb+pomo3CuuKJwv1OnClu14J3I+fhA3bpFO7e4FNWnv38/5OWR7JNJuNXb5OtL7EnYV8PmvPPVvaNQKCopBw9C167Ok6nuXBNxcfbx5+5EznDf+PjIIieujtvdW1yc63HdYYzpbr7A7MrKyID8fJJEZoEvvwA/P2JTITEETgdYjhnPfT66dxQKRSXk7bflwqK1ax1tniJ11qwp3Oate8eun6tzGzSQ2+Ks2DXGtK4wdjWW/nJIFmdtLf3G+sqjuHC45Aie3TvnQcimQqFQSDErjiiVhuh7yfEQmH0RJITZjOmt6AM5PrBNJNLopOWAry8994FPPnzfTG+zLs5S7h2FQlEhef99Ga3ijuKIvrchm7m54O9vf7yYjLwW7r4JGo8yNRruHbtcQgaWF8CS5pBGFtfusvTz9SXiDESlwXM9YVuE6dziLM5Soq9QKMqM//wHRoxwfbykLf3MzMKWfnCwd+d6wXfNYFctmwOuRP/nn2HPHtvrLmwF9ajGdTaiD3BUn46450bTucZ3ZZ2X2L7d9U0r0VcoFOVCaqr06VspjijZnXPkiBT4adPk/v79sHJl4Vh9b65n45ZZGwn9b5fJ0QD880xVroy6AJmZaECvu+BLI29wy5awdaujGphOYhWISfPBz/rO00XfRx98QyTk5VlCWG0mo7N85R+DfCHr7qaIzEJ9Sxol+gqFojB2xTxK0tI3smIaE7879IX6aZYkvJ5Ef9ky5wyWOubFUpcelCUOv2+mi7sh+tnZnAyG3xrBrbfqnXNy4OKL4euvncZLqgLhDWySuumin2UKiVnaQHfn2KRlBoivBbXHQOTjcDJIzjv80VDW3b2s6Z/un7cEUKKvUCgKY5cWISnJ4f4oCnYvCuvkpkFRLX3zIjETKSYv0a3b5Lb/7VLctWxdlLOy2KNP8Pp5uExi7RDCY6xlRCgQ/Sf+cjQdDrakeTA9Q44PtHgY0oIguQo0fQTqjoF/a8vjzx5q7P5GSgAVsqlQKApjJ/pTpsg/NuT6wM+Noe9uG0vSTrjtFnEBBAU5W/tm18j27TB9Ojz0kNtbB5wyYpqLnQAc9slgfjeoL07he0q2hbhZVKwBST6ZhFcJL3xQF/3XlsGzK6Da0yFsrScY8+BQNl1xBWkbN3Jp375kdu5MXIMGbGraBDgFWg4c+orkqo1A+PJw9Z+h9tXUTSj9colK9BUKRWF8fT33MTGlCzxxDby/BIZbD5pF/7vvZM78U6fsB/KzSJL53IMHYeRIj6KfJ+Cblo79VpZEnduDTzO2J0Aaj6+SbaeCpI890Ob9lFwFskQedULqFDqWEhLCqq5dCczJYWd0NFw2ivcuk8d88vOJys5marduBf0bHN7NgeAUqNkZmo12DFTvegDe7BaPzVrnEkWJvkJxPpCYCLVrwxdfwKAySGflKuulC77TY9RnXWwj+mb3Tv/+skDKSWvAu471ZWP3K8FNPH2WL1xzJ2yuB4P/gcdXQ7105z77ghyupWWm6h5P9IHnl0OYxfO0ob7cdqjXwXELwMZmzbjmjjtICQoqaPfJzaTW3mW89MUq+jaMIfrD+ezt04dt6emcqlqV78JWcKB1DsM2+/HxFc0gKwnq9AEtD07vZubPteHBB10+X0mgRF+hOB8wJjqnTCkb0S/CStc84RDGNdGQnpVOtUBTSgWrcKemehT9VdEwvhf8kHuWKkW4t0UtYEUM9I+HeV/p2TBDQ/nl0zSu1pO/r6npWFb7d114YCMsaAPTusBnF0HqK85jrosEoUGn+o5SIE8++CCvDx5M+Nmz/PL44+xo0IBf27cnaNtr/BGVwfDLoGr+BtKZT2xiIrFbtrAtAu7Qf6T45OdCmh66eWAOAI1SoO5b8ZQ2aiJXoTgfMNwenjJalhRFiNLZXwNOB8J1ehBNfHK8rFM7fbpssIq+EJBuMb91NF8fNOCqu+GPGNiUtY9MPxh4K+w0Yu5dTO4eqA7D+0PDVPhmgSn9cfXq9NoLuc9BjbOwvpbzfEKzZFnzFqSbJ9k0CbysETx7JbQknCD/EN4aNIjRI0bwxq230nPzZtYvWUKvTZt4aNEivn72WRolZXBYn0847ZNLZq5jLUKS6e1199bC97/nHSDcZt6ghFGir1CcDxgrVe0SkCUkFJ4YnTIFJk8u/vVatvTcB9gTBt3uk5+v2Ce3O5J2wLXXSv872It0RobteDNansZnoiMEclvOYTbUh69awZ036Z1cRP40HC2jYsb/Cb7mHwM1ZApMXw3qnYb4Gs7fYbNkeOlXx/4WPbY/xwf63CU/XxbclUs2buTxESOYPGgQ7RISWDpuHDFnzzqNdddW6H7AsZ/80dSC5z/l8AJx2QH4fZZj/4sv9A+uqoCVIEr0FYrzAUP0rZZ+RgY0bgz33efc/uijMHo0xcbLRVhvdHOUCuyiB54knExwdPjPf+CSS5xPEsKl6D/XJtlpf0fuMXz1Hx0FOeutz2qhxwFLQ/XqBR/Dz8iYfTPtjkO/3ZD4mtzfXE9u99SU25HrAzjU9B52nz3L1ClT+H7cOP4YNYrg7OxCcxDNkmHlxzDlB7mf+vTYghe1EUYap69HC9LfPR2PwCBjkW4R51KKg/LpKxTnE1bRN6JgfvmlcN8S5K9ouOw+aJkI26c72mubtDsyDepn+LA3da+j8f337Qd0kfcmzd/ZrbQ/L6UgZbGR6oBvv3Xqk+EPy/Tw9u4HCkfrmFM2m7Nk+uZDno90ByWHhhJ65gxRp3L5vUkovtWbMvaemyGkPtOuiAHgf1FRjFy0yHlsF1FOLZLkNjWIgheoIfrGxLIh+tXMP9KU6CsUCsBheVtF33Av2JUaNJOWBs88Ay+/XDi/jRcM0lesxkU4t6eaXBYRZyA2I4B9qfvcD+bG0jd7ZWqfhv3VUkjXHy3P0MPgYMeqWuC9TjJcFODuLTaDmqJrzPnwd70j/ewbmzWj5+TJZAQHE5qcwPdhDfjeR5fG/Gzu+PE7GrZtz1M9ehQe24Xo19A9UKlBECdSiG8hRd83H0J1kW93XLqVnO5Zib5CoQBci75hMZuEzZYXX5R+/kaN4JFHinTpf2ubrGwg2xcC9Ns5EeJor5YFMZlBrNy+yv2A+flOlv7BUIhMl1FAOT4O2b86AX5ql+pUnOTz1nBbovMLbn2k43NDu/D/AMcAhqUfmOtHcu1GTBk4kLm9ewNwxZYtnPLPZEv2Dji1FZLXMP73s0z6JQdeecVe4D2I/vD+UDX7JDvDZf6fWmccE8wCeMqadUGJvkKhAFyLvhEF48nSNyzjYiRMi7MElCQHywlRkC+DLodgyTwpYrF7U1kQJVfoFkpOZpCXV2DpJ1WBBo/B46tg1BrQTPOYbU/APM445dEZPAgW70pn9jzHZO2meo7j3Q46Xyrbz49tdevSuEoVQs+cIeIMEBhBdsfXuKRXDACPfPUVw374gYv27CFPgN+zjvOf/83Dl2NdTKZjiP6RUIf7JsfXOT2ELUr0FQoF4BBra/SOIfpmS79TJ0oSw4Xz9o8wuq9coWqIfkIY9NwnXTsAManSDbO1DnQ8ajsc9O1b8PGgHt74fke4RZ/M/Oxr6HwYNupivs3iUprX9CwPR0LXQ3AqUKZPvmEH3BwHVbMhXwg2NG/O5IEDWdS9O2eDgvC/7joaHj9OUmgVqBKAhuCdd94h9uhRrjdV+/LV4Lu5cP1QuV/w4nK1NsCFpV/TFNSTbnof53pa6KxEX6FQAJ7dO4aln58PGzd6Hi89Xa78nDxZrvQ1Ywn/NOLLm+uTk4n6fpavzHFjriZ18TG5Hdsbfp3t+TaMHDmnAx2f2x2XUTDGdY1kZLdsl6GbAGn6427Tjw3fCNftgv116nDdyy+zLTZWjrVnDyOTk9mVkMBv7dsj8nNIzT5C+M75PPzNNtt7qnnWttkeF5a+Xz58+o0s4GLm1n89jKdEX6EoB2rUkGGBb75Z3nfiwJN7x7D03VWDMtA0CNUVNizMsYjKICrKaTcxBKpmSTEGWNwcqmdJt4UmINYk+h2PwmOr4K1uMqrGLpHZ3hrS/TP7InjrUke7IfpRer61hqlyu7kehJ2FzxYFcOeuetw4KIMlPdrz3l2XkZ1zDNpE8+ALDalxJotjNWuS6+vLa++9R/9Vq2hx8KDM1aNHEWnAk73hjuAuLr8eaxoGl1St6jRfYKW+zfqzTxcVbnOiDOL0legrFFZOnYK33jo/RN8QeUN8XKx0LUAISDbFwtstdEpKKvioIdMQRGT6EJmeT6fDMPlS+Wf1h7KPtVi4ETKZVAVCbCZWbxrsKG5i5tXLIDhXEJYpXSn1ToO/5kOOgLxW/yPkh55ouiU8zfSyICuRyD3HWdeqDc0PHOCDlBR6PPQQfP65PG4SZoHMiMmQRoCp4LuJ2JNwVQJM/N3UaHXvvPceXH01zJtnOwZhYXR+eQrEydVd4/+UL8kgm7V1TijRVygUgGvRP6MrrifRN4uWeRWpq7z2Ogerw18N4OnNVYE0bt0mq0OBI3LHahnX0odPCbaPprETfJCLvMKyBEK/Vx8NGuRXY0/ttqQ1uIoeW7dyOjiQzVX+YdjyrYz+7TAftTzKu91gzSRBin8AtdLSYMUKMIdXWuvugtt0B4F5Xrimhg51b+n7+hJ66538fNlYwvYeo9MRy/HYWNi7t/B5SvQVCgXgEH2rxWkIuOEL9mTpW/ucde/ANiJ3eiVWA9IYvQbiw+GjDrBdn2ANM4Zo2hR27SrwiScXypTmHIdv0O2AnID9uQloaGQEBeGTn8+6li0JqV4b2jxF0JkUlo0Zg29eDv7PQMxuaLMPjvSsSmRobUSL6tTavFkOaBVOO9GvUkW6xHJyilcC0pjAdSX6+t9H7zP14MixwseLkNCupFGir1CcD7gSJkO0jageb0S/INELHi19Q9hbnpQi55cP/XZJ0R9/tTxWyNLXf3yM6Q2bTQtyN9aDu0wTmw1TYejf0GcPtE6EiLHQXruciG/Gcday7qD/z28TaPqV88xVMOEP6e9vV6cd1MsGQ/St2Im+n5+cuzl5sniib7xkPYi+y4nZ4pSdLCGU6CsU5wOGMFmtWEP0DUH0RvSfe87x2YPo/9gEYk5C7XSHSNW2LKYN+/lP+PlXmC19Ioalv6UerK8Pl+iujed6wnY92ubtH+GB+BBCTjoGm/VbWx56ahy+efn0Wb+e23/9lffbZ7G6dhJd9h0vdG/Hq8KuwNPcWbcDBLoQfLAXfV9fOYmdnl44Wd3ll8v5gHqmBQBWy9xb0a+AKNFXKIrC6dNw773wzjtSFDZvhujo0k+J68oaNXz6p07B8uXeTeSaMQTPxt2wOkq6XO7ZjNP6gChL7fLASy+DSy+DTz4BoE4GXHRM+u5/aiLdPH13O+LuAa7ZDSEBVcnzOctH117LmlatmNWvHzHJyax54AHq6Pn2v60BBEHd3OiCcwdug4WtHaGcjcIaQVCc62e0E2ZD9I9Yne3AiBFQ18XEg4G3ou/KjVOO7h2vXkdCiL5CiHghxG4hxDib44FCiM/142uFEDGmY+2EEKuFENuEEP8IITysF1coKjDz58PChTKPDUCHDtDFdfif1+TkwIwZ9qmTwbN7Z9UquOoqiItzPt6uncxtb4iM1Ydv7NuMf1BPTvnwOpzuyzw5+8Fi0wm6y8JHg+/0oJanr4J+d0DEGLk6FQDhz+mwxlw/fjyh333Hg48/zqx+/Ri4YgVbOncuEHyQKR8AqppkY7Ae695bT3scFRrlPg2FK/dOWJh9nH3VqoXbrBiibh27dWvn464ogwlbV3i09IUQvsB0oDdwCFgvhFisadp2U7f7gJOapjURQgwGXgVuE0L4AXOAOzVN2yqEqAWUURUIhaIYFMfXmpDguY8n3n0XRo2S6RIefRTWroXmzQtywRfclyv3joEp3BKAf/6Rue0ffljuJ1pSUBrj2oi+sRK3zmnAx/Hf1keDa3fKlbD3zjDl2TF9d84LnHxICgFq96K5X18SYtrQ+fIAqmRlccuKFfTesIE+GzZQ+9ZbEdHR8hn1l1RTPbq0jnAIcQ2LR6qQ6Bvfkb+/fJm6cu/UqOG96FtF3LiG1dKPiLDvb8VNfH9p4417pzOwW9O0BAAhxAJgAGAW/QHARP3zQmCaEEIAfYC/NU3bCqBpmnOybIWiouHtpF5J/zw33DLHj0vx7NpV/oIwUgSYffqpqTJHvBCFRd+UfdIWq+gb4mXz3EZIZo1MYMYb8MADBccWz5cLs3yndHWcYBL94BwgpBE0eQRCW0J+NvhVJT0xkZGLviUiNZU7k5KI+vlnx/lGRIzpu335V7hqL3SNdawathV9u8yhJ0/KsebPL3wsIgKGDZMpK6x1B0JCnPdvuMHx0rRiFW/jGbwV/Xr14KirfBWlgzfunUjAnMbokN5m20fTtFzgFFALaAZoQoifhBCbhBBj7S4ghBguhNgghNiQaP1HqVCUJcWJ5DBYtMi7FbF2GGkUsrIck7JrTYuH7rjDcX9hYTBpktz3VvQNIU1NdW43xMny3CnB0jUDUCUHGDjQaeWur6bnpTH/8tDH+LNtW/7z2GPQ6SOo2hTOHALhx6MpO9gzdChvzZjB+HnziLLeu41QBuVC/504JZQzi/4PJ/oQ6Bdob+mHhEir3c7SHzBAusMefbTwMaulP2NG4ReBgVX0rVE7rowD43nuvtv+eClS2lPMfsBlwFB9e5MQope1k6ZpMzVN66RpWqeIiAjrYYWi7PBW9IVwdgXt3Ak33SStR0888khhN40hWllZrv36ZubIYtqeRP/vOrAmCkjRi8Ca8tgvaQbXttzEP5++VsittbeG47MAacG6sV53ZGTQ49lnaTR3Lpe/8w4z+/cn6MQmWv4wDDbeB3/dwB2NYwgyLy6zulYMK9nO320SdSN6aMAOuCY7utDxQphFv1kz+ay1arnubwi8cR8ukqoBri19d+eYz6tTx32/UsAb985hINq0H6W32fU5pPvxqwPJyF8Ff2ialgQghFgKdAB+RaGoiBTFvWPua4Q+btUrXh87Bj/+CPfcU/jcqVMLtxmW3/z5cuGQGTvr3bieVfQt4Yfdh8lkZsdfn0dtKPglkh4AN9wu+5xY9SQb+t/vdJ6RB6eAgACXQrYkKYlbtm0jp2VLoo8f563p0+m7bh3NDx7ER9MQEwEth3rVLQ4Y77BIAAAgAElEQVQCq+i7s45N7ptq2ZD1gsxPL4br9+RO9M3C/OmnnidRDUvfmFtw56pxZenb/bqwO68cRN8bS3890FQIESuECAAGA4stfRYDxu+UgcBvmqZpwE9AWyFEFf1lcAXOcwEKRfmRkyNj1s0umaJM5JotciN00tj27y9DO48Xji+3xRD9kyfhjTecj9lVmTLE3RpjfsaRCCfLVwo+wD+GSzw9nTwhXe0GiVUo9LK7cYjcjoi9TebqCQy0Fb83Dhzghn//JTowkIMPPMCBwYMZvXAhLQ8cwEcX79d/htd+hvqhHkTfnXVsEfWAPP0XiHFP7qqBGQIcEyPnSjxRFEvfLO7+/o778eSxMP6+TfV7ywqPoq/76EciBTwO+ELTtG1CiOeFEDfo3T4CagkhdgOPAeP0c08CbyFfHFuATZqmfV/yj6FQFIO5c2HiREf4JRTNvWMWfWMi9tAh+fmw/mPY6BMXB3v2OI9hfsG4sybt5gkMS9/0KyC+Fogev7I8Bm66DYKednQ/bFju6emcCIETVSE0E576Aw7UgMRZ0wr6njVp8bROz0DNmrb3OO3GGxmbkMCgiAj+veQSolzMxz2xCsasorDIW61hd9+BqyIxxjm33OL5XGveIiuGhW9Y4Yboe2vp79njeEEY6ao9+fTPZQ6pmHi1OEvTtKXAUkvbM6bPmcAgF+fOQYZtKhQVC8OCNq9KLa57x7woavXqwv1btSo8/sGDMqTy+uvdX9dL0Z/TTm4nd4XFLeTnyDQp+K92h7u2yvs0XgCzv5HJ0SZdDms/ep7r9XGM1AtffgFisMPKTfPz41DDhizr1In3r7+euJgYrqxRg09atCDY19fzd2cW/cGDZZbKxSangdmnbxVLV+4bQ5Dr1ZMJzN58s/C6CcNd5iHPEJs2OdciMMZ2Z+kbz9S8uVykZ5xjuG08iX5WFvTqBb+Wnce74q4VVihKG0OkzP+pi2J52Vn6IF00Boct01///a/jc9eu0g2kaa4nbw8cgCVLnJpOB8BJH92to4t+noCvW8qm75qZLrdbzshurw2XDYPk3DSO6PVuI9OhsT6/e9DkwzdWurY5Afj4oGkaHx45QpP69Wn9ySc8OnIk1c6e5bX33uPndu2oYnx/nlxj5u/5k0/kKmIzXvr0bc8B6b6ZOrWwSBsWvCfRb9pUvowMvLH0jb93Yz2F8WvCWpjGivELITsbfvnFfd8SRqVhUFRezlX0XVn6Zj9+ly7wwQeO/ZkzHZ+P6dkXc3Jcux4uuQROnABk2cAcX+g/BFKC88kwzg0OZm6zs2yvDW/+VZUZLU+zR/fIPHo8lqZfbua2QTJF8sN9tYIVtfXTZSSMT75z4fN/a0NgLjRJAXx8mHv8OA/s3En33FzGv/ce9ZOTGbhiBb75+bBggeNET6JvtvT9/R3Pb1AEn34B3uS4MXz0nkTfijei3749dO8u03KA49ejUaTGlaV/553yuyvh0pbeoERfUXkxRKqkLX1dpAswLWqyZceOQpZ+fC1Zf7bfbsdYbR5yPi0zN5Og7GyoXZtN9Q5QJRtGLzvNxbuh192w4EsIqVWNQWvhNt35+mssBOUJuh/QqJcuJ0PrZFBg/QPERcjSiNn+gbyWns5zhw7RLTSUFTt34rtwoevn8CT6ZvH08ZGLohIS5Ety5Ur34loSol9UDNE3C3ft2s5/v8HB8t4NjH8/nqJ3rr223PLvKPeOovJSHEvfHO5nFuqjR6W41KlTWPQ9cdFFhUS/xcNw7R2Q6S+vl21jBG9P3C7dAxERxIVDyyQp4lfthUNvwq3bgOBgzAGKJ6rCgeoavRIoaK+f7iz6x6pCeE4NbnjpJf6Xmspl1auzpG1bfD3Fnvfp4/64NVSyXj2Zx8iIYCltS7+o/PGHTI1hDqHdvl2+pF1hvPg8iX45okRfUXkpSffOpk1w8cVygi47u+hWnEn0U0369nlnKTi7dHdNm+MwUl+ouzNxB+Tnk1ivOitioMshx3mRuhVv+MK7mtfUA7H9hpAvBHENGhCRGVwg+hoQ3/VRlt++kF87dmRWRAS/XnwxNc3hiK4wyhO6w25RlPFdVTRLv1MnWTje/LKqVUtO2rrCW0u/HFHuHUXlxfgPahaO4sbpx8ej3XwT28/so7WLF8eCNvBbLMxcYnPQNNaKho7mJ7plMHAd7NfnCWcugYuPwbQuuugDf9TLJstPj86xolupKz+WuXJ63AtrGvjxz3WjqNN6KEkhIfjmZuObvJ52nepyJDyc09Wr03z7b3w6bSFdzJOMVoE1MkparuWWv/+GXbuc2wzRd2fpewrZdIen5GabNsk/JYFV9MsxhbIrlOgrKi/FsfTNLwWz6Gdm8nn1QwwZcJhFe3cxwDJJqQFDBsrPr/8M1S1rqoyxMvzh8Wsg6hS88wPcPFgWMnmyt+zW4BQE50LsKR9WHpC+5J/CkvHLg4ts1oHlh4SQGBbGvrp1+bNtWwaknSGw4928lXiWtmlpPD53LvO6NuKfVt3YUdOfyKREkpMXcM+8BXSJw1lUzd/Trl3QuLHr7+nPP53r1BrUry//mPEmNPJcLH1PK3Dbt5d/SgJv3DthYSVzrWKiRF9RefFW9PPzZax8aKhzrVpz36wsNgXIJLKLT65lgGWI17o7Pv9dB3ocsHTQRf+XRrCnJnw/F7ofAKHBwNsc3erqIftD4wN4sfpy9oTBR8E76LdLJiczs6VxY4b078+O228v9Egvx8Yybvx4WLOGmjvhwf4QP1nOHbR4GOoai4Ctk68G/v7uxfSyy1wfs+KptCB4F7LpiQYNvO9bXDy5d1xFaS1eDPv3l849WVCir6i8eBu9M2ECvPwyfPmls3Vv/pyTw04/GQu5zSZEe1xvx+cd4a5Ff20U+OZDz30yu+UzK2BSD+nSmblEZrcEaJ0oBXd+W8gXGk/9Kds1YGb//izu1o2lXbtSNzOTl2fOpHZqKlds3Yp/bi5ZP/xA04YNC1wPXfW5gGWN9cyZQAcj268r0S/JIiDeWPquxN1b0d+3r2xSHngSfbv8/SDXa5QRSvQVlY/Dh2XWSTufvp3of/aZ3A4aBG+/LT8LUajvLiEXZa2NgrG94dnfpXCP7us83F67X/dffcWhUHi7K1y+X09n3KgRE39P4OkVsnCJCAgA5GKs6FSpzvPbQCB+dDySy5nAQB4bMYL3b5DZUZ6aM4fRjRoRbs0nb5R21F96bY9D7Elp7QNUz4TWRgCSK9G3ywdUXLyx9F1ZyN6KfsOGnvuUBFb3TgX06avoHUXlIypKlhH01r1j91KwrKLNF7CHFGpnSjvq9e4wqz2cDAajzsgTf8kVsOa0xQY5O3cQ/Rhk+sND6/RGfYGPr6ZH4jz5ZEH/6BR5H9trQ6O6N9L39beouXgx799wAyMWLSKrd29e+ugjwu0sTksEjQCG/u3YvznO8YvCpXXvylXy/PP2mUXdUZR0B67OrShYLf0PPoArrii/+7FBWfqKysu5iD44if6RapBFLgOPhjMjVpYsfPhaaK+7SXrsh+d+hy115aIrg5RgmRfH7O65zPgcaslvbLqP+idzET7BaFE3Exd7P6cSExn822/cs3w5Pdetc5xj9oULAb//7ghhNFmhzU017aaZs2yZvxvD2r72WtdhkE8/bd/uDk+W/tSpcOWVzm1BQTL/UEUTfaul37Wr/M7LsSaulQr2jSkUJcTcuVKc3OFtyKZZ+Ayht7h3dutx9DecqMkwU/Tf8li5nfKDdNnEpsK6KHi2p2yf3BVeuwxG6S6gRbctoo7hOalmWjF15ZXk+/iwrkUL+r3yChd/+DGiy3yIvZ/uGcfYe/vtfPLqq/RcuRLmzXOcZw6jrFEDLr/c9qvoHw9X7IN/ZuiuJQPzd2Mkdyvp+q6eLP2RIwv7yI3IIXd59MuD8yBOX4m+4sLkjjvghx/c9zG7aqxtZuws/dRUJ0t/j269N8uswkeL4a+P5L4Rcx+TCnz6KbF6Lrbne8oJ3S115X6C/tLo17Sf41qG6N99N0d/+IFOHTrQ5d13+bFLF3ZFRhJ6Yjv8PYavc/IJMO7F39958VDnzvbPYXnu6lnw+yd6kjVXz17aou/Oajdbyl98IUtJjh0LDz3k+pzywPj3UY6Fzz2hRF9xYeNuIs2w6s1C70n0DeH76ivYv58sX1lAfHsEBAp/onOkZd1QL0X7ewxU8wmmxvCHITCQdqZY+i9bFfbvB/gGQKQsNpIXGMiuyEie7diRJmvXsiM4mOdmzSKlf3+yrrmGWz9/ivbbN1A7JELGmRsZIjt0kCmbs7KgZUv753DHe+/ZJxszCra4WihVXFxZ+m3ayF9sVgYNku6lV1+teJb+eZCGQfn0FRc22dlSpFauhHffdUTigEPgzS4dO9E3i5GpMhX799N4lEyb0CoRLglugp+P/C9V7zREZEBiCMSEN0E8/Q4sWsS1u+DVZfD0lbCwlWOlLchoH54FbfFils2dy6O9ehGnT4oOqlWLl5Yto+ns2QX9J/+o5+QZGlR4RWmbNnJrfulZRdX6QgwPh6QkZ6u6LCx943pWv/f69c6i3qYNDB1astcuac4D944SfcWFTVaWFP2hQ2Vu+pdechwz/oMWxdI3iX4e+QUFSdZHwrjQ1uArZ0R9NLhxB3zQEZrUbCI7BQQggLF/yfquj+l+/Em/wJB/pQtof2Ym9/j48Hv//jTIzmbqlCm0b9aM7q++WshdFZwr/xi/DGwxC6kn0Te7WYxCJnYvgJKOd3eVR98qnP/8U7LXLQ3OA9FX7h3FhY3hkoiJkdvtphLNZks/OVkuwLIrZmL+JWAS/ZQ3X3Tq1r1GOydhnfyjTG/8Tj8917rJLXJznOO8QduhXoY/U2+6iS4bN7I5PZ1pTZuya9UqRi5aRHdPPm93om/GjU/f6bgQ8Ndf8Mgjzi+KO++UC9Wee86763mLcV3rJLqnrJ4VEeXeUSjKGUP0jbjyvXsLH8vLg+HD4euvYcyYwmPolZfSAiHUtCgpyRQNefUeuLrzxeDjyK1eJQdu2waERskGk1uk4SkYsxJodSMvDG/Bso4dORoezkUBAcxv1YqWISEwZIisu/rUU/IkQxz9/Z0XK3nrY7eKvjUHjLlcYdeuhYuIBwTACy94d62i4Er0z0dcWfovv+wcjVWOKNFXXNgYwm4IS5Yp05lRezY/Xxbz0NlYT7pNWhnHzp7l9xi48h74Nn4vC26B2/6FML1M7S+fQq+9wM15XmWKPFGjBlNuuYWvrryShMhIap46xVWbNzP0wQe5sV49R//mzZ3nIAyCghyiP3Wql18EhUV//nyoW7fw8bKOfb8QRd+6mGzcuLK/Fxco0Vecnxw7BhERrkXWx0eKSFISXHqpwxo2W8hpaXKbny9DMAHS0+nyAOT5QEZaMlWqy5QFn93kA+QzoLmcMJ3fFl7Ua1mHX3Qp7F0tLWQ3or/Z15dnX3yRtS1bklS9Oldt3syEDRu485138OvSBSZOdP/MhuspOFhW6goKkjHs3mK9N6N4t4HZvVOWuKuNe75hl8+pgqF8+orzj8REWXXJcHvYYVhazz0n+x/Ss4rZiX5eHiQnc7QqJMdvJk//X7HujdEFXeOiCocGTuglc9a0eHs2TJoE119v+589Nz+fF/fto3N6OmtbtqRrXBxrHnqIZWPGcO9ff+GXnw8dO3p+bkP0jRdYDZt8Dna8qM89eLLgS1r0d++WFcU8cSFZ+rH6ajxXaSMqAEr0FecfyXrOgEWLXPcx/tNZF2jZif4rr7A2NJ36T8Cd9dcWHF6y9jO21oG1kfBPjSyu2e04dfgGuX1oHQQ2aATjx0vBt4h+Qr16XLZ5M0/v28fAKlWIu+cevp0wgUvi42UHY45AnzdwiyH6Rhijt6J/441y663ol5R7p3FjZ/eRK4yXjCH65VAsvMT48Uc5N+TN32c5UXFfRwrFrl3QrBl8+y3omSOBwiJh5fhx53h6M3aiDyxtKrc/6NtqWfBWN/lHkseNO+B01QBqnNWY+kMOvfbCgB3YFhrJ9PdncffuPPzww2SfPcuCVq24LTvbuYA6OOYViiL6xoSw2f/vDm9dDqXl3mnQABo18nxd4z5XrpR5dc5H6tSBm24q77twixJ9RcXFSBy2YIGz6Bvi58oHPHy46zHNon/iBLk+cOdNsKCtZYjNPrzZ1fml0u44rJwTIBcx5e2Thcct7KhVi28HD2bKLbdwNDycpgcPsrh9e1qEhEg3k4Gfn3yOOnXk+gF3VagMjOc2qnK1aOH5HHD8Irj0Uvf9Skv0PRUHsYp+YGDJr/pVFKBEX1FxcSU+hhXoytJ3kev9dABUycku8GkeqQaRjzuOdzwq2FhPIzQTRq+B/dVg+Eboc5c83uYEkHXaZS3YJUlJDBw4kGxfX67YsoWZb75Jn7//JuDOO2UH80pWQ/QfekimOr7uOvtnMWOI/kUXwW+/wW23ue9vEB0tV+y2alX42IIFjvQNxi8BFb1zQaN8+oqKj9WiN8IuzSJx++1u3T6fXgTVnoLrqjjmATZavCOvbZJ55lskQWRqPl9+Cb0dkZyEGtGeKSmwcaPTufOPH+fmbdu4KCWFvYMH8/vo0Vy/Zg0B5heX2XqNjpbbsDA5AeyNdW2Ift++0jVVlDzt7dvbW8/mF4erdAiljRL9MkWJvqLi4kp8DNHfvx+GDZOfjepQc+fC8uVO3XfWgnt0N+uPgQfweRbERHhWT9G+ewqcbvc53bQoBv8Dn33jfLm7WwzmhYsckTwEBkLTptCrFztWruSeuDhuj4ujW2govyxbRsxxU1Y1cxSH2dKfNAlmzSpamTxzJs3SWOhT3iGbSvTLBCX6ivLHWmTc7rgZ8yTfrFnOx+64w2n3VCB01F3807+HltnV0XRN21xP5sCJTYWQGhEEVQtj/lfQDOfKUp/c9CkTLjH5gfz8yKtalY8++4yLcnOZe+IET0RH81O7doQawnX//XJrFnWz2yQkRFaYKorAGqJfWjHgxirSsnbvGMViKlrGzAsUr/52hRB9hRDxQojdQohCS8uEEIFCiM/142uFEDGW4w2EEKeFEE+UzG0rLii6dStaXLN5Va0H5reF04Hw/hIYsR6eS2ztdLxhqkyORtWqDl+9UUMW5ErKgIAC14gGzL7ySlqsW8f98fG0CQnh706deL1xY4LMIZuhoTLlw0cf2d9YceK4DdEvrRjwDz6A//zHedK8LBg7Vq4lePDBsr1uJcWj6AshfIHpQD/kyvQhQgjrjNB9wElN05oAbwOvWo6/BXioaKGotKxZ433fnBw5+egFO2vBY9fIBVTDNsu2607U4KJjMo0C6KmJQYq+MdEZEeEYpLV8SeQGBLDk0ku5a/x47h41imAfH75s1YoNHTvKPDkGhuj7+sokb67SEBfHWi9t0W/TRqafLusCIEFB8L//VejCIxcS3vzr6Qzs1jQtAUAIsQAYAJjSFTIAmKh/XghME0IITdM0IcSNwF7APqRCoXCF4frQNNi2TW5XrYLPP3fu5yLL5CP94Kw/LP8E/HSvS5XDJ9jyLaQHwOdt4LHVeudq1WTa5fbt5UTtSj1xWlAQv548yX07drB/0iT8c3IYtXgxb775Jr52rhlDzD0Jc3GE2xBFc93bkkSJbqXAG/dOJHDQtH9Ib7Pto2laLnAKqCWEqAo8CbjNxSqEGC6E2CCE2JBojmVWVC6sbhtDVL/4Qlqhbdvai+WRI4Wa1teHn5pA9CmZ0bKADXIpbbVsyH0ORhkLcKtWlT7tIUMK3DuZ/v48FhrKtX//jZ8QfP3006Rddx2TP/zQXvDBc71Xg+JY+pMmwZNPeh+qqVDYUNozNhOBtzVNO+2uk6ZpMzVN66RpWqcI809rReUiJcVzH0vK2of7Qa+7CnebppeGXTzf9VC+5vlh04rYA0FBvDR0KM1nz+btgABur1OH1R06cNPKlQTl5LhPDGaIfmlY+jVqwCuvVOhc7YqKjzf/8g4D0ab9KL3Nrs8hIYQfUB1IBroAA4UQrwE1gHwhRKamadPO+c4VFx4pKdJnP2eOzGVjF9Fjity5/F74Uy88/kg/eEefNfqwA8y+GC46Bhcf8/LaugjHZWRwVWgox+6/n0vi4vikalWutK589SYbZGlY+qXFd9+pFbCVCG9Efz3QVAgRixT3wcDtlj6LgbuB1cBA4DdN0zSgh9FBCDEROK0EX+HEL784Pp84IUMut2yRESR2Vax0F9C6SIfgA0ztAhP+gIOh8IAefPL+Ev3gb7/JHDduolIOZGby6O7dfJuURFVg4/DhdNi1C/74o3Bnb0S/NCz90sKb1cCKCwaP//I0TcsVQowEfgJ8gY81TdsmhHge2KBp2mLgI+AzIcRuIAX5YlAoPNO7t+Pzvn1S+EH67/v1K9w/M5MTIdDlAbk74zuZHuHyYVDHVPSqz27oYvwevfJKl5fXgLlXX81D69eTp2mMb9CAR44epfauXbJDjx42J7kRfeOYJ1GvSJa+olLhlbmhadpSYKml7RnT50xgkIcxJhbj/hSViYQE58lcU1rk5GB48XJYnfQyw3Rvy4dbG3Lfhv1kWFzc4/+El371cK2QEA6EhHDz88+zsXlzuoeEMLtlSxoFB8PJk7KPqyRo3oi+EnVFBaUC/cZUVDqs4nngAGRn23YdPBB+aQyQQlpXaBTWiGH7QoH9hOTAgbfgs4tkXdpH1kJBbM3ffxcaK8vfn/duvpmXbrqJLH9/Zr7xBsOWLHFE5Bihi65CGN2JvlGBy0VSNhYulAnOoqJcj6FQlCJK9BXlw6lThUX14EE4e9apKdMPvm1uCL4kLgImtLkdkbe4oC06DZ76E/jrL/jqK3jrLXmgrSln8h9/sHPVKu5q2pS1NWty5aZNTJk2jbZ79zqnQ7DmrTf45Re4+mr3or9dX77SubP98VtucU7vrFCUMUr0FWXLZ5/Bv//Ca69JgTazfDlZvtD2YRi1Bq7bBbGPOg7PXAwL2kDjk/Dk+Cchz5IZbcIEmdKhXTuH6OvkaRrPREbyWteuVPHxYUHjxtwWFSVdONYCJkYOmGbNnNsNIXcn+tOnw8cfy/THCkUFRIm+ouzQNLjLFFS/dm2hLqujYVctGHkd+C9xPnbbNnhgk74TULVwSGf9+nJriWM/mJnJsPh4fjl5knvq1uXl2FjqGiGKTZoUvs+WLeHLL+Gaa5zbjXHdiX7nzq6tfIWiAqBEX1F2WIubPPaY0+6PTaCfKUnmg3qCyqRXIS3QlM/ewBrSOWSI3JpEf/nJk9y6fTuZ+fm836wZw40XgycGDizcFhgIzZvDM88UPqZQnCeo1MqKssOY5LRBA0b1lZ+rmcR99GqodVamP2b6dOeTzPnX337bURbQxwcNeGvQIHpv3Uq4vz/rO3TwXvBdIQTs2CELtigU5ynK0leUDSkpjmpRNlw2DHaGwzW74bnlEJIDgbnQ1JyZwXq+4d4ZO1aWHdTJzs9n1KOP8t6AAdwcHs4nLVpQrSIthlIoyhH1P0FReoSFyYVRX3/t5C7RkGmPmyXL0Moz/rCqgTw252sIP+NivJo1nfcN985DDxW4dLaePs398fFsGDCAh3NzmdK6NaKsK0EpFBUY5d5RlA6aJt0533wDr79eUMJwbSQ0exhaPAw+E2WK4yV6kMz8hbrgjxhhP2b16nJr5MIxLH0/P87m5TE+IYGOGzZwIDOTha1b887VVyvBVygsKEtfUfKkpcFPPzn2x44t+HjlPTLHvUHoU3LbLAluitMbraGSBi1bwqhR8g/IKk8TJ7LWz487Nmxg99mzDKtbl9cbN6amykSpUNgiNG+SR5UhnTp10jboOc8V5ynXXw/ff1+oOakKROj6/9QfsCYKfmsk98cmNefV9mPlZOkdd9ivhrX8W83Jy+N/e/cy+fBhIgMD+ah5c64KCyvpp1EozguEEBs1TevkqZ+y9BUlz8aNhZqOVYU2utdm4/vQ4SjkC0isIjNkPtj+chg2rPBYM2fKqllTpjg1/336NHfFxbE1I4N76tbljcaNqaWse4XCI0r0FSVHerosBm6x0t/pAqP0hJk3Vr2EDkfXA7IgeZ0MePE3oGMN+zEf0NNpTp5c0LQyNZX+//5LkI8P37RuzY2q8I5C4TVqIldRctx8s0w/cOBAQdN3zRyC//Ei+LrxU/bnejHheio3lxE7d3L5li2E+fmxun17JfgKRRFRlr7i3MnPl0VKfnXOZ/xAf/iwIzRNlrH3g2euQqSl2Y9hqogFwAcfyJBPne+TkxkeH8+x7GxGRUXxQkwMVVXsvUJRZNT/GsW5c8st8PvvThOtSVWk4AP8+qnMgklgoOs882cswfn33w9Aem4uj+3Zw4dHj9I2JIRFbdpwSWhoyT+DQlFJUKKvOHcWLSrUNOMSud36ri74IF8KdnVvobDoA3+kpnLPjh3sy8zkyehonouNJdBHeSQVinNBib7i3LAkPUsPgNtvge+aQ/94aHdcP3DttdCmjaxXa4cpj35SdjbjEhL4+NgxYoOC+OPii7mshouJXoVCUSSU2aTwjvfek+ULNU1Ouk6aJNvT0526TessBf+uLXKFLYsWwQsvyLj9wEDnJGkAM2bIrW7pf5WYSOv165l9/DiPRkWxtVMnJfgKRQmiFmcpIDFRxsM/9ZTrKBqjvX59OHJEftY0We2qgUycs7g5DLwVrk6ApU9shmPHoG9f53GysuC++6BTJ1n4/Ngx6NmTE337MvKNN/gyMZEOVasyq0UL2lmLmygUCpeoxVkK77nvPliyRCZH69ZNtq1cKbNa/vqrc6IzQ/BBRuz8+y8a8H4nmNgTYk/CrEXAnIvtrxUYCHPmOPbT0tjUtCnX/fe/pCQlMSk2ljHR0fgp371CUSoo0VdAcrLcaposTP7f/8qSf56oWxcyMljWGP57PQTkwo9z5IIrry6bk8OzAQG89+67RObksL5jR2XdKxSljBWwFWQAABWDSURBVBJ9hSOixscHXn7Zo+CPvBY+bw2djmRwSxwsbCULnxx7A6rc9x84edLt+fmaxvtHjjAuIYH0vDweiIhgYtOm1AsOLqknUigULlCir3CI/oYNMHGi2657a8B0vQTsj03lH4CnV0CVHODdd92evyMjgwd27mTlqVNcHRbG5CZNaB0Scm73r1AovEaJvsIh+n/+6bbb6ijoJtdMMecraJ4sc+GHZsHo97ZAPdflCLPy83n9wAFe2L+fEF9fZjVvzt1166p89wpFGaNEX+EQ/aVL0YC/GkDLRJn6uEUSNDopK1yNv1p2+3gRDP0HeOopOhmhm61ag4u0CD+lpDBq1y7iz57l1ogI3mnalDp2qZMVCkWpo0Rf4RD9jAymd4aHr3U+3P4o7AiXxU8m/QL3btEPREY6OtkI/pb0dMYmJLDs5EmaBAeztG1b+tWqVTrPoFAovEKJfmXl9Gm5sGrqVLJ2bGNhW2nZT+vi6HLvZvgrGjbXc7Tdk9EE2C3z2z/wgFNBcoNDmZlM2LuX2cePE+bnx5uNG/NQZKRKoaBQVAC8En0hRF9gCuALfKhp2iuW44HAbKAjkAzcpmnaPiFEb+AVIADIBsZomuZiHb6i1MnIAEtIpAY8ezW8epnc773Pl8++zOPj9vDYamndN3kERq+Gkeug+uovYNcuuPVWecKaNZCfT25+PitOneKzY8f4PDERTdN4Ijqapxo0oIYqbqJQVBg8ir4QwheYDvQGDgHrhRCLNU3bbup2H3BS07QmQojBwKvAbUAS0F/TtCNCiDbAT0AkirIhP1/mxgkIkC6cTz8tOJTpB5vrSj/9ihiolw7/zICaPoGIjDOMXyn7BebB8dfBNygYHh8NF18M7dsXjJPWsSNzjx/nudWrOZ6TQ1VfX+6qU4fxDRoQo0IwFYoKhzeWfmdgt6ZpCQBCiAXAAMAs+gOAifrnhcA0IYTQNG2zqc82IFgIEahpWtY533llY906WLECxozx/pxHH4WpU2Xc/ciRBfltUoKh952wqT745cMLPZ9nRL9nqHkWqF7YKvfVgEaN4KWXAMjOz+f75GRmHz/O98nJ5Ggal1evzoyoKPrWrEkVV+mTFQpFueON6EcCB037h4AurvpompYrhDgF1EJa+ga3AJuU4HvBwIHQpAm8YvKiddG/8gcegAULICkJJkxwP87UqXKr1579pZEMsZx9EaQGyyyYL5/uQuvnnoazz8i+MTGwdWuhobTcXNalpTH72DEWnDhBSm4udfz9GRkZyYDwcC6vXl2FXyoU5wFlMpErhGiNdPn0cXF8ODAcoIGevKtS89VXcmuIvrmq1LJlMk0CuBb9uDiIigIgT8CLl8O8trAzXB5udQJm3TKbG9d/DtOny8aDB2WunSefhNtvl23z5nEgLIw5c+Yw+7rriN+0iSAfH24MD+euOnXoHRamcuQoFOcZ3oj+YSDatB+lt9n1OSSE8AOqIyd0EUJEAd8Ad2matsfuApqmzQRmgsyyWZQHuOAwZz2dNQuGDIHtJk/auHGsjYQj1eDGlSsRPXrIftWqSRfM1q1w770AnPWDB/vDZxdBZJqcjO2xH278fg+iUSP47k7HuFFR0u/v44N2++0s7dqVN1u2ZHlqKtx/P5fv2MGYnj0ZGBFBdVWmUKE4b/Hmf+96oKkQIhYp7oOB2y19FgN3A6uBgcBvmqZpQogawPfAOE3T/iq5276AyTBlKxs2DPbuhWbNANj19Ajm/jmDST0gxxee/2QYE4ADj95Lph9s6RiJ/8HD1G4AbU7AHcNq8H3tVPqLFnw9eQd++UCHDtCwoe2lNSFYlJjImJUr2ZOTQ2xmJs/XrcsdV15J7KBB8J//lP7zKxSKUsWj6Os++pHIyBtf4GNN07YJIZ4HNmiathj4CPhMCLEbSEG+GABGAk2AZ4QQutOYPpqmnSjpB7lgSEx02j0y+QWqjhrD1B4wwXcG9ITWJyAkG56J3sWCEbC9ttHb+gMslWn9pvHQJSPAdxLceWdB7nsrG9PTeWz3bv44dYo2ISHMbtyYwbVr4+/jIyeR69WzPU+hUJxfqCIqFY21a6FrVwBe6w5P9nYcGtC0P+89uIS6p2XI5d03Qnw4XHwMIi/uQZf5f3I8BM74w6kg6D7zB3o16+viQpL03FyeTEjg3SNHiPD35/mYGO6vV0/56hWK8wxVROV8JDu7QPC/awbjroZrd8KemhCUC/OeWkCVoTIjZVAufL5QP2/PHlnZaucEmDdPtv3vf+BB8H9KSWF4fDwHs7J4NCqKiTExyl+vUFzgqP/hFYEWLWQM/cGDaMD9N8AnF0OH/Dos/OI4Phr4aOD/bhXHOcuWQe/e0LSpnMAFmDsXatWSoZpDhri8XEpODqN372b28eO0qFKFv9q359Lq1Uv3GRUKRYVA/YYvLzQNjh6Vn+PjZcgkMLcdfNwB7k1vzNIRfxGcK1fF+q9dL/sGBsrtpZfC0KEwf77zuG+8AX/8Aa1b2152SVISrdevZ96JE/yvQQM2d+yoBF+hqEQoS7+8+PVXaam/9RYAuT7wZSu450bolFeH997YgZ+P6a/HSH2wfj38+COEhDjXmjUICIAePQo1p+TkMGr3buYcP067kBCWtm1L+2rVSuPJFApFBUaJfnmRkCC3EyeS6Qc3DoafmkCDMwH8NHG7Q/C/+w5++QWM1AZt28o/ReD75GTuj48nKSeHZxo25H8NGxKgJmoVikqJit4pD3JzwZR58oH+8GFHeCnoOv7z34+oGVqnRC6TmpPDkwkJzDx6lLYhIXzaooWy7hWKCxQVvVORWb684OOLl0vBH9v4Lp6641M3J3mPpmksOHGC0bt3k5iTwxPR0bwQE0OQSoSmUFR6lOiXNYcPwy23APB6N3j6KriB5jw3+P0SGX7P2bP8d+dOlp08Sadq1Vjarh0dlHWvUCh0lOiXNd99B+nprI2EsX1gYMx1zB7yBUF+Qec0bE5+Pm8cPMjz+/fjLwRTmzThv5GR+KrMlwqFwoQS/bJk1iyYMQMNeLObTKUwa8gCggOqeDzVHVvS0xkWH8/m06e5OTycd5o2JdII7VQoFAoTSvTLitzcgrz26yLhy9Ywpsa1VA2o6uFE12Tl5/PCvn28evAgtfz8+Kp1a26OiCipO1YoFBcgSvTLiuTkgo/vdIFA30D+9+C8Yg+3+tQp7ouPJ+7MGe6uU4e3mjShpqpFq1AoPKBEv6z4f3v3HhxVecZx/PuQGxBIgCRINAESBUIcMCCl3LxUBIFBLIVWBLwziKJV6VhEHR111EoVqx1EqXgZq1xEpJQZKyrYKlYQlUsAAykBkyDXQIAIJOy+/eN9AyESswnZ7HH3+czs5N1zzp7zSw48e/Y9Z8/r7p75wR2DebvtMh7qdx+JTev+Tdgyn4+HCgp4vqiItLg43u/WjSFJSQ2dVikVprToN5Zrr+VwLExMX0tWyywevPTBOq/iv6WljN+8mW3HjnHHuefyp8xMWuoN0pRSdaAVI9iMgd27YdMmpg2DwuN7WTlucZ2u1jnh9/NsUREPFRSQHhfHJzk5XNaqVRBDK6XClRb9YNqwAS67DA4cYENbmNULJudMpG9634BXse7IESbk5bHm8GFGJSfzSpcutNK+e6VUPWnRDxa/H554Ag4cYF9zGD4W4pvEMfVXNQxmXs0xn4/Hd+xgemEhraOjmZedze9SUhC97l4pdRa06AfD4sUwYQLs38+BnCyuHH2EPUeLWB5zM2kJabW+/N8HDzIxL48tR49yU7t2PHP++STp0b1SqgFo0Q+GkSMBOBILw/oVsNkY/pl8J31vm/6TLyupqGCau0FaRtOmLOvenUFt2jRGYqVUhNCiXxcbNsBzz8Hs2fDGG9CvH3TtauetXAlvvgk5OQBUNIFxv4EvU8p5Z9S7DO46ssbVHvX5+GtxMU999x2HTpzgD2lpPJqRQbzeIE0p1cC06Afq4EHo3t22b7nFdt+AvToHYNIkyM0FILetHfJwVRo80mcqI2so+Ed9Pl7ftYsnduyguLycYW3a8FRmJt1b1P9bukop9VPCr+ivWAGrV8PUqaem+f32Z30GDvH57GPBglPTxo7l4wxYngG3b19P2thJsH07AIuz4IaRdkzbvyfezNjBT/5olXvLy5lZXMzMnTvZV1FB34QE3s7O5lK9DFMpFWThN4hK5dUtfv+pdu/eUFQEO3eevmxBgb3V8YABNa9v1Cj4/HO7zMKFbGsNS7rAvUPs7BgftDsCnfdDWQx8kQ7dEjszt+3tXDjm96e90VT4/dybn8+cXbs45vdzdVIS96WnMyAxUa/KUUqdFR1EpbgYSkqgQwc7rmx1xkBmpm1/9hn073+qq2bbtlOvW7QIgIpFC7lnGLzY2y7S/zt4bAXM6QFbk+CrVDgWDXd/AU8u+YbmMT++c+a3P/zAzJ07GZmczJMZGWTFxwfjN1dKqRqFb9FPT6eiCXyTCp2bQn4bKLsknd0Hiijv2pkRg+/CxNn5HYcPoHTI5cTvP8wFN02BceNgyhSYMYPSOPisPTx0BaxNhZGFLbh+5RGGtOtPs4KVXFFgN1f+7HSIiiK2XxmcoeADHPH5AJiYmqoFXykVEuHVveP3nxpAHJg0HF6u4cNOi+PgawJHq1z+Lgae/TqF8pK9xPjhvENw32AodPdFm74M7vukHGbMgMmT7fmDESPszAD+jh+VlDBo/Xr+k5PDJdp/r5RqQJHZvePuZFlpbTtofRTuWmX73MujoFMJ7GsO72VBi3PSaZ9bCEDaIXirO0y5+PR1ZDZJ4oWl+7lwL1zxyOt2QPPKk8RXXw133QVDhwYU7wd3Qrm5XoqplAqR8Cr6hYWnPS1tGcOVJfE8Ov4ZGD/efgowBubM4dfPPANPLbVX5TzyCABjcuHTDpDYIpnjB/extU8nfjt3PU3nXQyX9IIbb/zxNl94IeB4Za57J74+VxEppVQDCK/qU1n016yBkhIOpaWQMHwU3HorxMVBdLQ9Up80CfLzISsLHngAtmwBY4i6bRKXR51Pj4kP06cIri9OtnfD3LjRfhnrLJ0s+nqkr5QKkYCKvogMEZE8EckXkfvPMD9OROa7+atEpGOVedPc9DwRuarhop9BUZH9mZ4OrVtTeqyUxLhaBiqJjoZOnWx71iz7ZuC+VXvy+v4Got07SqlQq7Xoi0gUMBMYCmQD14lIdrXFbgUOGGMuAJ4DnnavzQbGABcCQ4AX3fqCo7AQYmMhJQWf30dZRVm9RqfioosgKQkef7xB42n3jlIq1AKpPr2BfGPMNmNMOTAPuKbaMtcAlf0fC4GBYr9tdA0wzxhz3BhTAOS79QVHYSGkpYEIh44fAiAhLqHu60lIgH37YNCgBo1X5vPRBIjToq+UCpFATuSeB1Q9Q1oE/LKmZYwxJ0SkFEhy07+o9trz6p32J7z76WLGjbkKxg6Bf83FYKDXa/y5/Fz+tnp1MDZZZ7vKy2keFaXfvlVKhYwnrt4RkYnARID27dvXax2tmrUkuSwPmjeH2GYARMVE0S2hNc1q+LJUY8uOj+cXLVuGOoZSKoIFUvSLgfQqz9PctDMtUyQi0UAisD/A12KMmQ3MBvvlrEDDVzWw10CKeg2sz0uVUipiBNK5/CXQSUQyRCQWe2J2SbVllgCVF7GPBpYb+1XfJcAYd3VPBtAJ8EZfi1JKRaBaj/RdH/2dwAdAFPCqMWajiDwGrDHGLAHmAG+KSD5Qgn1jwC23ANgEnAAmG2N8QfpdlFJK1SK87r2jlFIRKtB77+i1g0opFUG06CulVATRoq+UUhFEi75SSkUQLfpKKRVBPHf1jojsBXacxSqSgX0NFCcYvJ4PvJ/R6/lAMzYEr+cDb2XsYIxJqW0hzxX9syUiawK5bClUvJ4PvJ/R6/lAMzYEr+eDn0fG6rR7RymlIogWfaWUiiDhWPRnhzpALbyeD7yf0ev5QDM2BK/ng59HxtOEXZ++UkqpmoXjkb5SSqkahE3Rr23w9kbM8aqI7BGR3CrT2ojIhyKy1f1s7aaLiLzgMq8XkZ6NkC9dRFaIyCYR2Sgid3swY1MRWS0i61zGR930DBFZ5bLMd7f6xt26e76bvkpEOgY7o9tulIh8IyJLPZpvu4hsEJG1IrLGTfPMfnbbbSUiC0XkWxHZLCJ9vZJRRLq4v13l45CI3OOVfPVmjPnZP7C3fP4fkAnEAuuA7BBluRToCeRWmTYduN+17weedu1hwPuAAH2AVY2QLxXo6dotgS3YAe+9lFGAFq4dA6xy214AjHHTXwJud+07gJdcewwwv5H29RTgbWCpe+61fNuB5GrTPLOf3XbfACa4dizQymsZ3bajgF1ABy/mq9PvEuoADbRD+gIfVHk+DZgWwjwdqxX9PCDVtVOBPNd+GbjuTMs1YtZ/AIO8mhFoDnyNHZd5HxBdfZ9jx3ro69rRbjkJcq404GPgCmCp+4/umXxuW2cq+p7Zz9gR9gqq/y28lLHKtgYDK72ary6PcOneOdPg7UEZgL2ezjHGfO/au4BzXDukuV03Qw/skbSnMrquk7XAHuBD7Ce5g8aYE2fIcTKjm18KJAU54l+APwJ+9zzJY/kADLBMRL4SOw41eGs/ZwB7gddcN9krIhLvsYyVxgBzXduL+QIWLkX/Z8PYQ4CQXzIlIi2Ad4F7jDGHqs7zQkZjjM8Yk4M9ou4NZIUyT1UiMhzYY4z5KtRZajHAGNMTGApMFpFLq870wH6OxnaFzjLG9ADKsN0lJ3kgI+7czAjgnerzvJCvrsKl6Ac0AHsI7RaRVAD3c4+bHpLcIhKDLfhvGWMWeTFjJWPMQWAFtruklYhUDvFZNcfJjG5+IrA/iLH6AyNEZDswD9vF87yH8gFgjCl2P/cA72HfPL20n4uAImPMKvd8IfZNwEsZwb5pfm2M2e2eey1fnYRL0Q9k8PZQqjpw/I3YfvTK6Te4s/59gNIqHxuDQkQEO6bxZmPMDI9mTBGRVq7dDHvOYTO2+I+uIWNl9tHAcncEFhTGmGnGmDRjTEfsv7XlxphxXskHICLxItKyso3tk87FQ/vZGLMLKBSRLm7SQOx42p7J6FzHqa6dyhxeylc3oT6p0FAP7JnzLdi+3wdDmGMu8D1QgT2SuRXbf/sxsBX4CGjjlhVgpsu8AejVCPkGYD+OrgfWuscwj2XsDnzjMuYCD7vpmcBqIB/7UTvOTW/qnue7+ZmNuL8v59TVO57J57Ksc4+Nlf8nvLSf3XZzgDVuXy8GWnspIxCP/VSWWGWaZ/LV56HfyFVKqQgSLt07SimlAqBFXymlIogWfaWUiiBa9JVSKoJo0VdKqQiiRV8ppSKIFn2llIogWvSVUiqC/B+Po5h2P3P1VgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(scores)\n",
    "plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us run the agent with the learned Q-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkb/anaconda3/envs/drlnd/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== step: 0\n",
      "score:    0.0\n",
      "=== step: 1\n",
      "score:    0.0\n",
      "=== step: 2\n",
      "score:    0.0\n",
      "=== step: 3\n",
      "score:    0.0\n",
      "=== step: 4\n",
      "score:    0.0\n",
      "=== step: 5\n",
      "score:    0.0\n",
      "=== step: 6\n",
      "score:    0.0\n",
      "=== step: 7\n",
      "score:    0.0\n",
      "=== step: 8\n",
      "score:    0.0\n",
      "=== step: 9\n",
      "score:    0.0\n",
      "=== step: 10\n",
      "score:    0.0\n",
      "=== step: 11\n",
      "score:    0.0\n",
      "=== step: 12\n",
      "score:    0.0\n",
      "=== step: 13\n",
      "score:    0.0\n",
      "=== step: 14\n",
      "score:    0.0\n",
      "=== step: 15\n",
      "score:    0.0\n",
      "=== step: 16\n",
      "score:    0.0\n",
      "=== step: 17\n",
      "score:    0.0\n",
      "=== step: 18\n",
      "score:    0.0\n",
      "=== step: 19\n",
      "score:    0.0\n",
      "=== step: 20\n",
      "score:    0.0\n",
      "=== step: 21\n",
      "score:    0.0\n",
      "=== step: 22\n",
      "score:    0.0\n",
      "=== step: 23\n",
      "score:    0.0\n",
      "=== step: 24\n",
      "score:    0.0\n",
      "=== step: 25\n",
      "score:    1.0\n",
      "=== step: 26\n",
      "score:    1.0\n",
      "=== step: 27\n",
      "score:    1.0\n",
      "=== step: 28\n",
      "score:    1.0\n",
      "=== step: 29\n",
      "score:    1.0\n",
      "=== step: 30\n",
      "score:    1.0\n",
      "=== step: 31\n",
      "score:    1.0\n",
      "=== step: 32\n",
      "score:    1.0\n",
      "=== step: 33\n",
      "score:    1.0\n",
      "=== step: 34\n",
      "score:    1.0\n",
      "=== step: 35\n",
      "score:    2.0\n",
      "=== step: 36\n",
      "score:    2.0\n",
      "=== step: 37\n",
      "score:    2.0\n",
      "=== step: 38\n",
      "score:    2.0\n",
      "=== step: 39\n",
      "score:    2.0\n",
      "=== step: 40\n",
      "score:    2.0\n",
      "=== step: 41\n",
      "score:    2.0\n",
      "=== step: 42\n",
      "score:    2.0\n",
      "=== step: 43\n",
      "score:    2.0\n",
      "=== step: 44\n",
      "score:    2.0\n",
      "=== step: 45\n",
      "score:    2.0\n",
      "=== step: 46\n",
      "score:    2.0\n",
      "=== step: 47\n",
      "score:    2.0\n",
      "=== step: 48\n",
      "score:    2.0\n",
      "=== step: 49\n",
      "score:    2.0\n",
      "=== step: 50\n",
      "score:    2.0\n",
      "=== step: 51\n",
      "score:    2.0\n",
      "=== step: 52\n",
      "score:    2.0\n",
      "=== step: 53\n",
      "score:    2.0\n",
      "=== step: 54\n",
      "score:    2.0\n",
      "=== step: 55\n",
      "score:    2.0\n",
      "=== step: 56\n",
      "score:    2.0\n",
      "=== step: 57\n",
      "score:    2.0\n",
      "=== step: 58\n",
      "score:    2.0\n",
      "=== step: 59\n",
      "score:    2.0\n",
      "=== step: 60\n",
      "score:    2.0\n",
      "=== step: 61\n",
      "score:    2.0\n",
      "=== step: 62\n",
      "score:    2.0\n",
      "=== step: 63\n",
      "score:    3.0\n",
      "=== step: 64\n",
      "score:    3.0\n",
      "=== step: 65\n",
      "score:    3.0\n",
      "=== step: 66\n",
      "score:    3.0\n",
      "=== step: 67\n",
      "score:    3.0\n",
      "=== step: 68\n",
      "score:    3.0\n",
      "=== step: 69\n",
      "score:    3.0\n",
      "=== step: 70\n",
      "score:    3.0\n",
      "=== step: 71\n",
      "score:    3.0\n",
      "=== step: 72\n",
      "score:    3.0\n",
      "=== step: 73\n",
      "score:    3.0\n",
      "=== step: 74\n",
      "score:    3.0\n",
      "=== step: 75\n",
      "score:    3.0\n",
      "=== step: 76\n",
      "score:    3.0\n",
      "=== step: 77\n",
      "score:    4.0\n",
      "=== step: 78\n",
      "score:    4.0\n",
      "=== step: 79\n",
      "score:    4.0\n",
      "=== step: 80\n",
      "score:    4.0\n",
      "=== step: 81\n",
      "score:    4.0\n",
      "=== step: 82\n",
      "score:    4.0\n",
      "=== step: 83\n",
      "score:    4.0\n",
      "=== step: 84\n",
      "score:    4.0\n",
      "=== step: 85\n",
      "score:    4.0\n",
      "=== step: 86\n",
      "score:    4.0\n",
      "=== step: 87\n",
      "score:    4.0\n",
      "=== step: 88\n",
      "score:    4.0\n",
      "=== step: 89\n",
      "score:    4.0\n",
      "=== step: 90\n",
      "score:    4.0\n",
      "=== step: 91\n",
      "score:    4.0\n",
      "=== step: 92\n",
      "score:    4.0\n",
      "=== step: 93\n",
      "score:    4.0\n",
      "=== step: 94\n",
      "score:    4.0\n",
      "=== step: 95\n",
      "score:    4.0\n",
      "=== step: 96\n",
      "score:    4.0\n",
      "=== step: 97\n",
      "score:    4.0\n",
      "=== step: 98\n",
      "score:    4.0\n",
      "=== step: 99\n",
      "score:    4.0\n",
      "=== step: 100\n",
      "score:    5.0\n",
      "=== step: 101\n",
      "score:    5.0\n",
      "=== step: 102\n",
      "score:    5.0\n",
      "=== step: 103\n",
      "score:    5.0\n",
      "=== step: 104\n",
      "score:    5.0\n",
      "=== step: 105\n",
      "score:    5.0\n",
      "=== step: 106\n",
      "score:    5.0\n",
      "=== step: 107\n",
      "score:    5.0\n",
      "=== step: 108\n",
      "score:    5.0\n",
      "=== step: 109\n",
      "score:    6.0\n",
      "=== step: 110\n",
      "score:    6.0\n",
      "=== step: 111\n",
      "score:    6.0\n",
      "=== step: 112\n",
      "score:    6.0\n",
      "=== step: 113\n",
      "score:    6.0\n",
      "=== step: 114\n",
      "score:    6.0\n",
      "=== step: 115\n",
      "score:    6.0\n",
      "=== step: 116\n",
      "score:    6.0\n",
      "=== step: 117\n",
      "score:    6.0\n",
      "=== step: 118\n",
      "score:    6.0\n",
      "=== step: 119\n",
      "score:    6.0\n",
      "=== step: 120\n",
      "score:    6.0\n",
      "=== step: 121\n",
      "score:    6.0\n",
      "=== step: 122\n",
      "score:    6.0\n",
      "=== step: 123\n",
      "score:    6.0\n",
      "=== step: 124\n",
      "score:    6.0\n",
      "=== step: 125\n",
      "score:    7.0\n",
      "=== step: 126\n",
      "score:    7.0\n",
      "=== step: 127\n",
      "score:    7.0\n",
      "=== step: 128\n",
      "score:    7.0\n",
      "=== step: 129\n",
      "score:    7.0\n",
      "=== step: 130\n",
      "score:    7.0\n",
      "=== step: 131\n",
      "score:    7.0\n",
      "=== step: 132\n",
      "score:    7.0\n",
      "=== step: 133\n",
      "score:    7.0\n",
      "=== step: 134\n",
      "score:    7.0\n",
      "=== step: 135\n",
      "score:    7.0\n",
      "=== step: 136\n",
      "score:    7.0\n",
      "=== step: 137\n",
      "score:    7.0\n",
      "=== step: 138\n",
      "score:    7.0\n",
      "=== step: 139\n",
      "score:    7.0\n",
      "=== step: 140\n",
      "score:    7.0\n",
      "=== step: 141\n",
      "score:    7.0\n",
      "=== step: 142\n",
      "score:    7.0\n",
      "=== step: 143\n",
      "score:    7.0\n",
      "=== step: 144\n",
      "score:    7.0\n",
      "=== step: 145\n",
      "score:    7.0\n",
      "=== step: 146\n",
      "score:    7.0\n",
      "=== step: 147\n",
      "score:    7.0\n",
      "=== step: 148\n",
      "score:    7.0\n",
      "=== step: 149\n",
      "score:    7.0\n",
      "=== step: 150\n",
      "score:    8.0\n",
      "=== step: 151\n",
      "score:    9.0\n",
      "=== step: 152\n",
      "score:    9.0\n",
      "=== step: 153\n",
      "score:    9.0\n",
      "=== step: 154\n",
      "score:    9.0\n",
      "=== step: 155\n",
      "score:    9.0\n",
      "=== step: 156\n",
      "score:    10.0\n",
      "=== step: 157\n",
      "score:    10.0\n",
      "=== step: 158\n",
      "score:    10.0\n",
      "=== step: 159\n",
      "score:    10.0\n",
      "=== step: 160\n",
      "score:    10.0\n",
      "=== step: 161\n",
      "score:    10.0\n",
      "=== step: 162\n",
      "score:    10.0\n",
      "=== step: 163\n",
      "score:    10.0\n",
      "=== step: 164\n",
      "score:    10.0\n",
      "=== step: 165\n",
      "score:    10.0\n",
      "=== step: 166\n",
      "score:    10.0\n",
      "=== step: 167\n",
      "score:    10.0\n",
      "=== step: 168\n",
      "score:    10.0\n",
      "=== step: 169\n",
      "score:    10.0\n",
      "=== step: 170\n",
      "score:    10.0\n",
      "=== step: 171\n",
      "score:    10.0\n",
      "=== step: 172\n",
      "score:    10.0\n",
      "=== step: 173\n",
      "score:    10.0\n",
      "=== step: 174\n",
      "score:    10.0\n",
      "=== step: 175\n",
      "score:    10.0\n",
      "=== step: 176\n",
      "score:    10.0\n",
      "=== step: 177\n",
      "score:    10.0\n",
      "=== step: 178\n",
      "score:    10.0\n",
      "=== step: 179\n",
      "score:    10.0\n",
      "=== step: 180\n",
      "score:    10.0\n",
      "=== step: 181\n",
      "score:    10.0\n",
      "=== step: 182\n",
      "score:    10.0\n",
      "=== step: 183\n",
      "score:    10.0\n",
      "=== step: 184\n",
      "score:    10.0\n",
      "=== step: 185\n",
      "score:    10.0\n",
      "=== step: 186\n",
      "score:    10.0\n",
      "=== step: 187\n",
      "score:    10.0\n",
      "=== step: 188\n",
      "score:    10.0\n",
      "=== step: 189\n",
      "score:    10.0\n",
      "=== step: 190\n",
      "score:    10.0\n",
      "=== step: 191\n",
      "score:    10.0\n",
      "=== step: 192\n",
      "score:    10.0\n",
      "=== step: 193\n",
      "score:    10.0\n",
      "=== step: 194\n",
      "score:    10.0\n",
      "=== step: 195\n",
      "score:    10.0\n",
      "=== step: 196\n",
      "score:    10.0\n",
      "=== step: 197\n",
      "score:    10.0\n",
      "=== step: 198\n",
      "score:    11.0\n",
      "=== step: 199\n",
      "score:    11.0\n",
      "=== step: 200\n",
      "score:    11.0\n",
      "=== step: 201\n",
      "score:    11.0\n",
      "=== step: 202\n",
      "score:    11.0\n",
      "=== step: 203\n",
      "score:    11.0\n",
      "=== step: 204\n",
      "score:    11.0\n",
      "=== step: 205\n",
      "score:    11.0\n",
      "=== step: 206\n",
      "score:    11.0\n",
      "=== step: 207\n",
      "score:    11.0\n",
      "=== step: 208\n",
      "score:    11.0\n",
      "=== step: 209\n",
      "score:    11.0\n",
      "=== step: 210\n",
      "score:    11.0\n",
      "=== step: 211\n",
      "score:    11.0\n",
      "=== step: 212\n",
      "score:    11.0\n",
      "=== step: 213\n",
      "score:    11.0\n",
      "=== step: 214\n",
      "score:    11.0\n",
      "=== step: 215\n",
      "score:    11.0\n",
      "=== step: 216\n",
      "score:    11.0\n",
      "=== step: 217\n",
      "score:    11.0\n",
      "=== step: 218\n",
      "score:    11.0\n",
      "=== step: 219\n",
      "score:    11.0\n",
      "=== step: 220\n",
      "score:    11.0\n",
      "=== step: 221\n",
      "score:    11.0\n",
      "=== step: 222\n",
      "score:    11.0\n",
      "=== step: 223\n",
      "score:    12.0\n",
      "=== step: 224\n",
      "score:    13.0\n",
      "=== step: 225\n",
      "score:    13.0\n",
      "=== step: 226\n",
      "score:    13.0\n",
      "=== step: 227\n",
      "score:    13.0\n",
      "=== step: 228\n",
      "score:    13.0\n",
      "=== step: 229\n",
      "score:    13.0\n",
      "=== step: 230\n",
      "score:    13.0\n",
      "=== step: 231\n",
      "score:    13.0\n",
      "=== step: 232\n",
      "score:    13.0\n",
      "=== step: 233\n",
      "score:    13.0\n",
      "=== step: 234\n",
      "score:    13.0\n",
      "=== step: 235\n",
      "score:    13.0\n",
      "=== step: 236\n",
      "score:    13.0\n",
      "=== step: 237\n",
      "score:    13.0\n",
      "=== step: 238\n",
      "score:    13.0\n",
      "=== step: 239\n",
      "score:    13.0\n",
      "=== step: 240\n",
      "score:    13.0\n",
      "=== step: 241\n",
      "score:    13.0\n",
      "=== step: 242\n",
      "score:    13.0\n",
      "=== step: 243\n",
      "score:    13.0\n",
      "=== step: 244\n",
      "score:    13.0\n",
      "=== step: 245\n",
      "score:    13.0\n",
      "=== step: 246\n",
      "score:    13.0\n",
      "=== step: 247\n",
      "score:    13.0\n",
      "=== step: 248\n",
      "score:    13.0\n",
      "=== step: 249\n",
      "score:    13.0\n",
      "=== step: 250\n",
      "score:    14.0\n",
      "=== step: 251\n",
      "score:    14.0\n",
      "=== step: 252\n",
      "score:    14.0\n",
      "=== step: 253\n",
      "score:    14.0\n",
      "=== step: 254\n",
      "score:    14.0\n",
      "=== step: 255\n",
      "score:    14.0\n",
      "=== step: 256\n",
      "score:    14.0\n",
      "=== step: 257\n",
      "score:    14.0\n",
      "=== step: 258\n",
      "score:    14.0\n",
      "=== step: 259\n",
      "score:    14.0\n",
      "=== step: 260\n",
      "score:    14.0\n",
      "=== step: 261\n",
      "score:    15.0\n",
      "=== step: 262\n",
      "score:    15.0\n",
      "=== step: 263\n",
      "score:    15.0\n",
      "=== step: 264\n",
      "score:    15.0\n",
      "=== step: 265\n",
      "score:    15.0\n",
      "=== step: 266\n",
      "score:    15.0\n",
      "=== step: 267\n",
      "score:    15.0\n",
      "=== step: 268\n",
      "score:    15.0\n",
      "=== step: 269\n",
      "score:    15.0\n",
      "=== step: 270\n",
      "score:    15.0\n",
      "=== step: 271\n",
      "score:    15.0\n",
      "=== step: 272\n",
      "score:    15.0\n",
      "=== step: 273\n",
      "score:    16.0\n",
      "=== step: 274\n",
      "score:    16.0\n",
      "=== step: 275\n",
      "score:    16.0\n",
      "=== step: 276\n",
      "score:    16.0\n",
      "=== step: 277\n",
      "score:    16.0\n",
      "=== step: 278\n",
      "score:    16.0\n",
      "=== step: 279\n",
      "score:    16.0\n",
      "=== step: 280\n",
      "score:    16.0\n",
      "=== step: 281\n",
      "score:    16.0\n",
      "=== step: 282\n",
      "score:    16.0\n",
      "=== step: 283\n",
      "score:    16.0\n",
      "=== step: 284\n",
      "score:    16.0\n",
      "=== step: 285\n",
      "score:    16.0\n",
      "=== step: 286\n",
      "score:    16.0\n",
      "=== step: 287\n",
      "score:    16.0\n",
      "=== step: 288\n",
      "score:    16.0\n",
      "=== step: 289\n",
      "score:    16.0\n",
      "=== step: 290\n",
      "score:    17.0\n",
      "=== step: 291\n",
      "score:    17.0\n",
      "=== step: 292\n",
      "score:    17.0\n",
      "=== step: 293\n",
      "score:    17.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== step: 294\n",
      "score:    17.0\n",
      "=== step: 295\n",
      "score:    17.0\n",
      "=== step: 296\n",
      "score:    17.0\n",
      "=== step: 297\n",
      "score:    18.0\n",
      "=== step: 298\n",
      "score:    18.0\n",
      "=== step: 299\n",
      "score:    18.0\n"
     ]
    }
   ],
   "source": [
    "replay_agent = learner.get_agent()\n",
    "episode = env.generate_episode(replay_agent)\n",
    "for count, step_data in enumerate(episode):\n",
    "    print(\"=== step: \" + str(count))\n",
    "    print(\"score:    \" + str(env.get_score()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
